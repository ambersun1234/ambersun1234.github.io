<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="https://ambersuncreates.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ambersuncreates.com/" rel="alternate" type="text/html" /><updated>2026-02-21T17:17:11+08:00</updated><id>https://ambersuncreates.com/feed.xml</id><title type="html">Shawn Hsu</title><subtitle>This website is a personal study blog of Shawn Hsu. I am a software engineer who is interested in backend, cloud native and blockchain.</subtitle><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><entry><title type="html">資料庫 - 機率型資料結構 Bloom Filter 在 Cache 中的應用</title><link href="https://ambersuncreates.com/database/database-filter/" rel="alternate" type="text/html" title="資料庫 - 機率型資料結構 Bloom Filter 在 Cache 中的應用" /><published>2026-01-19T00:00:00+08:00</published><updated>2026-02-06T01:19:17+08:00</updated><id>https://ambersuncreates.com/database/database-filter</id><content type="html" xml:base="https://ambersuncreates.com/database/database-filter/"><![CDATA[<h1 id="cache-issues">Cache Issues</h1>
<p>就像我們在 <a href="../../database/database-cache">資料庫 - Cache Strategies 與常見的 Solutions | Shawn Hsu</a> 當中提到的<br />
如果碰到惡意攻擊，查詢不在 cache 也不在 database 裡面的資料，那麼所有的請求都會直接到 database，然後又會直接被打爆<br />
所以其實在這種狀況底下，直接讓請求到 database 是不好的選項</p>

<p>當然除了你對它設計 rate limit，阻擋某個 IP 過來的請求<br />
可是這樣也不是一個太好的選項，雖然會動</p>

<p>是不是用一個可以快速查詢的方式，就可以將所有不在 cache 也不在 database 裡面的請求，直接快速返回呢？<br />
顯而易見的，使用 <a href="#hash-function">Hash Function</a> 來實作是一個很好的選項</p>

<h1 id="probabilistic-data-structure">Probabilistic Data Structure</h1>
<p>這種要求就會需要用到機率型資料結構<br />
這些資料結構能夠提供 “概略的” 統計資料，比方說</p>
<ul>
  <li>這個資料存不存在</li>
  <li>某某資料的數量是多少</li>
</ul>

<p>等等的</p>

<p>相比於傳統的資料結構，雖然能夠統計出最完整的資料，不過效率上會慢非常多<br />
這也是為什麼機率型資料結構受到歡迎的原因，犧牲一點的準確性，換取極高的效率</p>

<h2 id="hash-function">Hash Function</h2>
<p>要怎麼快速的，比如說查詢資料存不存在<br />
最直覺的作法肯定是將資料本身做個 hash<br />
查詢的時候，就做一樣過 hash function 得出結果，然後看看有沒有這個資料就可以了</p>

<p>所以其實機率型資料結構的實作，就是依靠 hash function 來達成的</p>

<h2 id="why-not-hash-table-only">Why not Hash Table only?</h2>
<p>碰撞問題在算 hash 的時候是很常會遇到的問題<br />
以下的實作方法雖然本質上都是使用 <a href="#hash-function">Hash Function</a> 來實作<br />
但是為什麼不單純只算一次，而是比如說</p>

<ul>
  <li><a href="#bloom-filter">Bloom Filter</a>: 採用 <strong>多次 hash</strong> 的作法</li>
  <li><a href="#cuckoo-filter">Cuckoo Filter</a>: 採用 <strong>雙 hash</strong> 的作法</li>
</ul>

<p>等多次的算法，目的為何？<br />
其實說白了就是要降低碰撞的概率，降低誤判的機率<br />
機率型結構同時滿足，”空間換時間” 以及 “準確率換時間” 的特性</p>

<p>所以單純的一次 hash 實務上是不太會使用的</p>

<h1 id="different-types-of-probabilistic-data-structure">Different Types of Probabilistic Data Structure</h1>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Probabilistic Data Structure</th>
      <th style="text-align: left">Insertion</th>
      <th style="text-align: left">Query</th>
      <th style="text-align: left">Deletion</th>
      <th style="text-align: left">Modification</th>
      <th style="text-align: left">Space Utilization</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="#bloom-filter">Bloom Filter</a></td>
      <td style="text-align: left">$O(K)$</td>
      <td style="text-align: left">$O(K)$</td>
      <td style="text-align: left">:x:</td>
      <td style="text-align: left">:heavy_check_mark:</td>
      <td style="text-align: left">Very Low</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#scalable-bloom-filter">Scalable Bloom Filter</a></td>
      <td style="text-align: left">$O(K)$</td>
      <td style="text-align: left">$O(K * L)$</td>
      <td style="text-align: left">:x:</td>
      <td style="text-align: left">:heavy_check_mark:</td>
      <td style="text-align: left">Low</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#cuckoo-filter">Cuckoo Filter</a></td>
      <td style="text-align: left">$O(1)$</td>
      <td style="text-align: left">$O(1)$</td>
      <td style="text-align: left">:heavy_check_mark:</td>
      <td style="text-align: left">:heavy_check_mark:</td>
      <td style="text-align: left">Medium</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#xor-filter">XOR Filter</a></td>
      <td style="text-align: left">$O(1)$</td>
      <td style="text-align: left">$O(1)$</td>
      <td style="text-align: left">:x:</td>
      <td style="text-align: left">:x:</td>
      <td style="text-align: left">High</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#binary-fuse-filter">Binary Fuse Filter</a></td>
      <td style="text-align: left">$O(1)$</td>
      <td style="text-align: left">$O(1)$</td>
      <td style="text-align: left">:x:</td>
      <td style="text-align: left">:x:</td>
      <td style="text-align: left">Very High</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>每筆資料所需空間: <a href="#bloom-filter">Bloom Filter</a> &gt; <a href="#scalable-bloom-filter">Scalable Bloom Filter</a> &gt; <a href="#cuckoo-filter">Cuckoo Filter</a> &gt; <a href="#xor-filter">XOR Filter</a> &gt; <a href="#binary-fuse-filter">Binary Fuse Filter</a></p>
</blockquote>

<h2 id="bloom-filter">Bloom Filter</h2>
<p><a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom Filter</a> 是一種機率型資料結構，可以快速判斷資料是否存在<br />
當資料不存在時，可以快速返回結果，避免無謂的查詢</p>

<p>基本的概念是，透過一個巨大的 bit array，將同一筆資料做 <strong>多次 hash</strong>，然後將結果存到 array 裡面<br />
以下圖來說就是三次 hash</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Bloom_filter.svg/960px-Bloom_filter.svg.png" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom Filter</a></p>
</blockquote>

<p>假設你做了三次 hash，那麼 hash 出來的結果會被寫入三個不同的位置，不是 0 就是 1<br />
那他要怎麼做查詢呢？<br />
將輸入也做同樣的三次 hash，如果相對位置上的資料都是 <code class="language-plaintext highlighter-rouge">1</code>，那這筆資料 <strong>“應該”</strong> 是存在的</p>

<p>為什麼是應該呢？<br />
因為，hash function 會有碰撞的問題嘛<br />
有可能不同的輸入，hash 出來的結果是相同的<br />
而採用 <strong>多次 hash</strong> 的作法，可以降低碰撞的機率<br />
但並不是完全可以避免</p>

<p>只有算出來的東西 <code class="language-plaintext highlighter-rouge">全部都是 1</code>，那這筆資料可能是存在的(i.e. <code class="language-plaintext highlighter-rouge">false positive</code>，因為同一個位置有可能有其他資料 map 到這裡)<br />
那如果有一個位置是 <code class="language-plaintext highlighter-rouge">0</code>，那這筆資料就絕對不存在(比如說上圖的 <em>w</em>)</p>

<hr />

<p>那會不會有一種狀況是，Bloom Filter 的資料滿了呢？<br />
會的吧？ 那到時候是不是整條 bit array 的內容都幾乎是 1 了呢？</p>

<p>在這樣的情況下，Bloom Filter 的準確性就會下降，就是你丟啥進去它都是 true 了<br />
那能不能考慮將資料刪除呢？ 不行，因為有可能同一個位置有多筆資料 map 到同一個位置<br />
強制把它清 0 會讓其他原本準確的資料也一起被清掉<br />
所以 <a href="#bloom-filter">Bloom Filter</a> <strong><em>不支援刪除</em></strong></p>

<h3 id="better-bloom-filter">Better Bloom Filter</h3>
<p>不過，多次 hash 實務上也是有缺點的，就是慢<br />
所以 <a href="https://www.eecs.harvard.edu/~michaelm/postscripts/tr-02-05.pdf">Building a Better Bloom Filter</a> 這篇論文提出了一些改進的方式<br />
簡單講就是透過計算兩次的 hash 結果之後，利用以上結果把剩下的全部推論出來</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">bit_vector</span><span class="p">[</span><span class="n">hash1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">bit_vector</span><span class="p">[</span><span class="n">hash2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">bit_vector</span><span class="p">[</span><span class="n">hash1</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">hash2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>而這牽扯到一個數學問題，如果你的 bit_vector 的長度與 hash2 的結果有公因數<br />
那你可能會很快的將 Bloom Filter 全部塞滿</p>

<p>就是說，假設陣列大小是 <code class="language-plaintext highlighter-rouge">10</code><br />
hash2 的結果是 <code class="language-plaintext highlighter-rouge">2</code><br />
那你之後步進的結果就是 <code class="language-plaintext highlighter-rouge">2, 4, 6, 8, 0, 2, 4, 6, 8, ...</code><br />
等於說你有很大的機率會重複，這樣誤判率上升，對吧</p>

<p>與其去限制 hash2 不如控制陣列的大小<br />
既然重點是 <strong>互質</strong>，將陣列大小設定為質數不就好了？<br />
這也是為什麼工程上通常會設定 <code class="language-plaintext highlighter-rouge">100003</code> 而不是 <code class="language-plaintext highlighter-rouge">100000</code></p>

<h3 id="scalablestackable-bloom-filter">Scalable(Stackable) Bloom Filter</h3>
<p><a href="#bloom-filter">Bloom Filter</a> 是沒辦法做刪除的，而且也沒有辦法擴展<br />
也就是說，在一開始的時候 bit array 的大小就要事先決定好<br />
但是這樣就不好用了阿？ 所以一個變種 Scalable Bloom Filter 就出現了</p>

<p>既然一個 Filter 不夠，那就再加一個<br />
而新增的這一層通常會比原本的大一倍，為了不夠然後又繼續加層數</p>

<p>這樣下去，查詢的時間除了原本的 hash 次數，還要再加上層數(L)<br />
所以是 $O(K \times L)$<br />
寫入的部份因為只需要寫入最新的那一層(因為舊的那層滿了嘛)，所以是 $O(K)$</p>

<blockquote>
  <p>如果我重複寫入相同的資料呢？<br />
會需要先檢查，確定不存在再寫嗎？<br />
實務上通常不這樣做，因為新的層數會是先前的一倍大，多幾個 bit 的資料影響不大<br />
而且先查再寫會大幅度的增加 overhead(因為查詢是 $O(K \times L)$)</p>
</blockquote>

<h2 id="cuckoo-filter">Cuckoo Filter</h2>
<p><code class="language-plaintext highlighter-rouge">Cuckoo Filter</code> 不同於 <a href="#bloom-filter">Bloom Filter</a>，它採用 <strong>雙 hash</strong> 的作法，計算出資料的 fingerprint<br />
然後在相對應的位置上標記<br />
而這種作法，也會出現 false positive 的問題(i.e. 相同 fingerprint)</p>

<p>計算 fingerprint 的好處在於，能夠做到 <strong><em>刪除的功能</em></strong><br />
因為我儲存的是資料的 fingerprint，而不是資料模糊之後的結果(<a href="#bloom-filter">Bloom Filter</a> 儲存的是去特徵化後的結果映射)<br />
我能夠定位到唯一的資料，然後刪除它<br />
不過，hash 的原罪就是會碰撞，有沒有可能 fingerprint 也相同呢？<br />
所以對於刪除 <strong>你只能刪除某個，你確定有加入過的資料</strong></p>

<p>那我有多個加入過的資料，然後 fingerprint 也相同呢？<br />
這就要講回到 <strong>雙 hash</strong> 的作法了(i.e. <em>cuckoo hashing</em>)<br />
兩種 hash function 分別長這樣</p>

<ul>
  <li>$h_1(x) = \text{hash}(x)$</li>
  <li>$h_2(x) = h_1(x) \oplus \text{hash}(\text{fingerprint}(x))$</li>
</ul>

<blockquote>
  <p>fingerprint 也可以讓整個 filter 的 size 變得更緊湊<br />
原因在於判斷存在與否僅須看兩個位置，就算旁邊資料是滿的，也不影響判斷<br />
而 <a href="#bloom-filter">Bloom Filter</a> 資料如果塞太滿，會導致誤判的機率上升(就像課本上畫滿重點，整本都是重點，整本也都不是重點)</p>
</blockquote>

<p>由於 $\oplus$(xor) 的特性，你只要知道其中一個 hash 值，你就能夠推導出另一個<br />
那為什麼要算兩個 hash，原因也是要處理碰撞的問題<br />
如果發現 $h_1$ 已經被佔領了，它就會嘗試將資料放到 $h_2$ 的位置上<br />
那如果兩個位置都滿了呢？<br />
cuckoo hashing 的作法會是將舊的資料踢掉，因為你可以算另一個 hash 嘛<br />
所以就一直找下去，如果一直都是滿的就一直踢，直到有空位<br />
當然不太會一直無限找下去啦，所以通常會設定個 threshold，超過就放棄<br />
也就是說 <strong>insert 是有可能會失敗的</strong></p>

<p><img src="https://i0.wp.com/codecapsule.com/wp-content/uploads/2013/07/cuckoo_preview.jpg?w=720&amp;ssl=1" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://codecapsule.com/2013/07/20/cuckoo-hashing/">Cuckoo Hashing</a></p>
</blockquote>

<h2 id="xor-filter">XOR Filter</h2>
<p><code class="language-plaintext highlighter-rouge">XOR Filter</code> 的作法則是將儲存的資料變成是 “片段的 fingerprint” 資料<br />
並且只有固定三個片段，然後將這三個片段進行 XOR 運算<br />
得出來的結果，再與 fingerprint 進行比對<br />
如果兩個長的一樣，那這筆資料應該存在</p>

\[h_1(p_1) \oplus h_2(p_2) \oplus h_3(p_3) = \text{fingerprint(input)}\]

<p>本質也還是算 hash，所以片段的 fingerprint 也會有碰撞的問題<br />
所以 <a href="#xor-filter">XOR Filter</a> 也會有 false positive 的問題</p>

<blockquote>
  <p>都是算 fingerprint，why not <a href="#cuckoo-filter">Cuckoo Filter</a>?<br />
就還是回到 <a href="#why-not-hash-table-only">Why not Hash Table only?</a> 的問題<br />
還是空間最大化利用以及準確率換時間的 trade offs</p>
</blockquote>

<p>他的出現旨在取代 Bloom Filter，因為以下各種原因</p>
<ol>
  <li><a href="#xor-filter">XOR Filter</a> 比 <a href="#bloom-filter">Bloom Filter</a> 更快
    <ul>
      <li>3 + 1 次 hash 比 n 次 hash 快</li>
    </ul>
  </li>
  <li><a href="#xor-filter">XOR Filter</a> 所需空間比 <a href="#bloom-filter">Bloom Filter</a> 更小
    <ul>
      <li>Bloom Filter 塞太滿，誤判機率會上升</li>
    </ul>
  </li>
</ol>

<p>不過他有一個大缺點<br />
要先知道所有儲存資料，你才能開始構件 XOR Filter<br />
因為它本質上是在解方程式，上述的數學式你也看到了<br />
它需要找到 3 個不同的 hash function，使得所有數值填入之後計算出來的等式是成立的<br />
換句話說，<a href="#xor-filter">XOR Filter</a> 沒辦法 <strong>動態新增資料</strong></p>

<p>本質上就是先找到 Degree 1 slot 然後一層一層解析<br />
一個 slot 如果有兩個資料映射到同一個位置，那就不能拆<br />
就是要找到所謂的突破口</p>

<p>很抽象？</p>

\[x + y = 10 \\
y + z = 15 \\
x + z = 11\]

<p>單純看 $x + y = 10$ 你可以很簡單的說出答案，可是這個答案他是與其他等式有相依性的<br />
部份解不一定等於全局解<br />
況且它本質上還是 hash function 你更難猜</p>

<blockquote>
  <p>上述作法稱為 <code class="language-plaintext highlighter-rouge">peeling</code></p>
</blockquote>

<p>所以它就沒用了嗎？<br />
其實有些系統是 read heavy 的，將 <a href="#xor-filter">XOR Filter</a> 應用在此種狀況可以獲得很好的效果</p>

<h3 id="binary-fuse-filter">Binary Fuse Filter</h3>
<p>你會發現 <a href="#xor-filter">XOR Filter</a> 的 peeling 過程其實挺容易失敗的<br />
找到共同解沒有這麼簡單，尤其資料量大的時候，萬一失敗它就要重新設定 hash</p>

<p>那既然問題是資料量大的時候，容易失敗<br />
那麼把資料分組不就解決了，所以現在是 <em>分組 也 分片段</em></p>
<ul>
  <li>分組: 將整個 array 切成多個大小相同的小 array 且互不重疊，稱為 <strong><em>segment</em></strong></li>
  <li>分片段: 將輸入資料切成 3 個片段(3 次 hash)</li>
</ul>

<p>而目的是</p>

<ul>
  <li>分組: 為了解決 peeling 失敗</li>
  <li>分片段: 犧牲部份準確率換取時間</li>
</ul>

<blockquote>
  <p>如果你不分組，那基本等於 <a href="#xor-filter">XOR Filter</a></p>
</blockquote>

<p>為了要讓 <a href="#binary-fuse-filter">Binary Fuse Filter</a> 跑得又快又好<br />
其中一個特殊要求是，3 組 hash function 的結果，<strong><em>必須座落於相鄰的 segment 中</em></strong><br />
也就是說</p>

<ol>
  <li>當你算出第一個 hash 結果，找到它應該放在哪個 segment 之後，假設位置 <code class="language-plaintext highlighter-rouge">i</code></li>
  <li>第二個 hash 結果必須放在 <code class="language-plaintext highlighter-rouge">i + 1</code> 的 segment 中</li>
  <li>第三個 hash 結果必須放在 <code class="language-plaintext highlighter-rouge">i + 2</code> 的 segment 中</li>
</ol>

<blockquote>
  <p>如果都放在同一個 segment，那就是小號的 <a href="#xor-filter">XOR Filter</a></p>
</blockquote>

<p>這樣的好處是</p>
<ul>
  <li>解決了資料量大可能會出現的 peeling 失敗問題</li>
  <li>查詢時間更快速，因為 3 次 hash 結果在記憶體中是相鄰的，可以提高 cache hit rate</li>
  <li>peeling 建構過程更順利，只要找到 degree 1 slot 就能夠大幅度提昇找到全局解的機率(因為相鄰，所以找到一個，就可以往後繼續找(燒)，所以才叫 <code class="language-plaintext highlighter-rouge">fuse</code>)</li>
</ul>

<blockquote>
  <p>有關 cache 可以參考 <a href="../../database/database-cache">資料庫 - Cache Strategies 與常見的 Solutions | Shawn Hsu</a></p>
</blockquote>

<h1 id="redis-example">Redis Example</h1>
<p>那就來試一下</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>docker run <span class="nt">-itd</span> <span class="nt">-p</span> 6379:6379 <span class="nt">-p</span> 8001:8001 <span class="nt">--name</span> redis redis/redis-stack
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> redis sh
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>你可以造訪 <code class="language-plaintext highlighter-rouge">localhost:8001</code>，這個是 Redis Insight 的 GUI</p>
</blockquote>

<h2 id="bloom-filter-1">Bloom Filter</h2>
<p>那其實我想試試它撞到會發生什麼事情<br />
所以 <a href="#bloom-filter">Bloom Filter</a> 的錯誤率我會設定成 0.5<br />
然後大小開 10 筆，這樣就比較容易撞到</p>

<p><img src="/assets/img/posts/bf.png" alt="" /></p>

<p>可看到說，我沒有新增 <code class="language-plaintext highlighter-rouge">dog</code> 這筆資料，但它卻說存在<br />
這就是 false positive 的問題(當然也是因為我錯誤率設定很高，所以很容易復現)</p>

<blockquote>
  <p>有關 Bloom Filter 的指令可以參考 <a href="https://redis.io/docs/latest/commands/bf.add/">BF</a></p>
</blockquote>

<h2 id="cuckoo-filter-1">Cuckoo Filter</h2>
<p>而 <a href="#cuckoo-filter">Cuckoo Filter</a> 的操作也類似</p>

<p><img src="/assets/img/posts/cf.png" alt="" /></p>

<p>注意到，拿這個範例去跟 <a href="#bloom-filter-1">Bloom Filter</a> 做比較是沒有意義的<br />
因為他們的錯誤率設定不同，大小也不同，所以不能這樣看</p>

<blockquote>
  <p>有關 Cuckoo Filter 的指令可以參考 <a href="https://redis.io/docs/latest/commands/cf.add/">CF</a></p>
</blockquote>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://redis.io/docs/latest/develop/data-types/probabilistic/">Probabilistic</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filter</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Cuckoo_filter">Cuckoo filter</a></li>
  <li><a href="https://redis.io/docs/latest/develop/data-types/probabilistic/bloom-filter/">Bloom filter</a></li>
  <li><a href="https://redis.io/docs/latest/develop/data-types/probabilistic/cuckoo-filter/">Cuckoo filter</a></li>
  <li><a href="https://redis.io/blog/bloom-filter/">Bloom Filter Datatype for Redis</a></li>
  <li><a href="https://medium.com/@Kadai/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E5%A4%A7%E4%BE%BF%E7%95%B6-bloom-filter-58b0320a346d">資料結構大便當：Bloom Filter</a></li>
  <li><a href="https://arxiv.org/pdf/2201.01174">Binary Fuse Filters: Fast and Smaller Than Xor Filters</a></li>
  <li><a href="https://stackoverflow.com/questions/73410580/what-is-a-binary-fuse-filter">What is a binary fuse filter?</a></li>
  <li><a href="https://stackoverflow.com/questions/73410580/what-is-a-binary-fuse-filter">What is an XOR filter?</a></li>
  <li><a href="https://stackoverflow.com/questions/70963247/bloom-filters-with-the-kirsch-mitzenmacher-optimization">Bloom Filters with the Kirsch Mitzenmacher optimization</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="database" /><category term="redis" /><category term="redis-stack" /><category term="bloom filter" /><category term="cuckoo filter" /><category term="hash function" /><category term="false positive" /><category term="scalable bloom filter" /><category term="cuckoo hashing" /><category term="probabilistic data structure" /><category term="data structure" /><category term="cache" /><category term="cache penetration" /><category term="cache avalanche" /><category term="cache hotspot invalid" /><category term="xor filter" /><category term="binary fuse filter" /><category term="peeling" /><summary type="html"><![CDATA[我們常用空間換時間，但很多時候這樣還是不夠的。透過機率型資料結構，犧牲些微準確性，獲取極大的性能提昇在某些場景下是非常必要的，本文會介紹機率型資料結構的基本概念，以及在 Redis 中的實作方式]]></summary></entry><entry><title type="html">多開 Goroutine 的效能瓶頸以及 Garbage Collection 對其的影響</title><link href="https://ambersuncreates.com/random/golang-gc/" rel="alternate" type="text/html" title="多開 Goroutine 的效能瓶頸以及 Garbage Collection 對其的影響" /><published>2026-01-15T00:00:00+08:00</published><updated>2026-01-15T01:00:33+08:00</updated><id>https://ambersuncreates.com/random/golang-gc</id><content type="html" xml:base="https://ambersuncreates.com/random/golang-gc/"><![CDATA[<h1 id="preface">Preface</h1>
<p>Goroutine 作為 Golang 的一大特色<br />
其輕量且快速的特性，使得其的開銷相比 process 以及 thread 要來的低上許多<br />
因此人們往往會將 Goroutine 用在非同步的操作上，比如說 I/O 或者是 CPU-bound 的操作<br />
用以達到併發的效果</p>

<blockquote>
  <p>有關 Goroutine 的介紹可以參考 <a href="../../random/golang-goroutine">Goroutine 與 Golang Runtime Scheduler | Shawn Hsu</a></p>
</blockquote>

<p>Goroutine 本身屬於 coroutine，縱使他的開銷相對較低，也還是會有一定的成本<br />
比如說 Golang Runtime Scheduler 必須要管理這些 Goroutine 進行任務調度<br />
頻繁的 context switch 會導致 scheduler 本身都在處理調度任務，反而實際的任務根本沒在執行</p>

<p>這些種種的問題都是我們在開發時需要注意的地方<br />
而本篇文章將會詳細的探討 Goroutine 本身的開銷以及 Garbage Collection 是如何處理這些 Goroutine 的</p>

<h1 id="stack-vs-heap-allocation">Stack vs. Heap Allocation</h1>
<p>有哪些東西是不會被 GC 處理的?<br />
non-pointer 的 value 是不需要被 GC 處理的(slice 那些除外)<br />
因為在 compile time 的時候就可以決定他的生命週期了<br />
這種資料位於 stack 上，普遍被稱為 <code class="language-plaintext highlighter-rouge">stack allocation</code></p>

<p>針對那些動態的記憶體存取，比方說根據使用者的輸入決定記憶體大小<br />
或者是指標類型的，因為你不太能確定這塊記憶體會被怎麼用以及哪時候可以安全的被回收<br />
這種動態的記憶體存取就是 GC 需要主動介入的</p>

<h1 id="introduction-to-garbage-collection">Introduction to Garbage Collection</h1>
<p>以前在學 C 語言的時候，或多或少可能都聽過 <code class="language-plaintext highlighter-rouge">malloc 完要記得 free</code> 這句話<br />
這是因為在 C 語言中，記憶體的管理是由開發者自己來負責的<br />
如果你忘記 free 掉你 malloc 的記憶體，就會造成 memory leak</p>

<p>阿 人類就很懶惰嘛，所以就想說能不能有一個機制來幫我們管理記憶體<br />
Garbage Collection 就是這樣一個機制，它會自動幫你管理記憶體<br />
當你沒有要使用記憶體的時候，GC 會自動幫你回收這些記憶體(所以你可以用完就丟著，有人會幫你收拾)</p>

<blockquote>
  <p>local variable 不需要讓 GC 處理，因為 compile time 就可以決定他的生命週期了<br />
需要 GC 通常是你不知道哪時候不會用到，可以被回收，比如說 slice</p>
</blockquote>

<p>GC 有很多種實作，比如 <a href="#reference-counting">Reference Counting</a> 以及 <a href="#mark-and-sweep">Mark and Sweep</a></p>

<h2 id="gc-mechanism">GC Mechanism</h2>
<h3 id="reference-counting">Reference Counting</h3>
<p>怎麼定義這塊記憶體可以被回收？ 最簡單的想法就是看他有沒有正在被使用<br />
假設這塊記憶體正在被 2 個人使用，那想當然不要回收它是比較正確的<br />
這種作法被稱為 <code class="language-plaintext highlighter-rouge">reference counting</code></p>

<p>當你把每個變數的 reference count 都記錄下來<br />
當 reference count 為 0 的時候，就可以把這塊記憶體回收了</p>

<h3 id="mark-and-sweep">Mark and Sweep</h3>
<p><code class="language-plaintext highlighter-rouge">Mark and Sweep</code> 是另一種 GC 的實作方式<br />
他是 <code class="language-plaintext highlighter-rouge">Tracing GC</code> 的一種，這種方式會建立一個 <strong>依賴關係圖</strong>(稱為 <code class="language-plaintext highlighter-rouge">object graph</code>)<br />
這個關係圖會紀錄每一個 object 彼此使用的關係，所以你可以很輕易的觀察哪些資源正在被使用<br />
之後就可以透過這張關係圖去區分說哪些資源是可以被回收的</p>

<p>你需要兩個步驟執行它</p>
<ol>
  <li>建立 object graph(i.e. <code class="language-plaintext highlighter-rouge">scanning</code>)</li>
  <li>掃描 object graph 並回收不需要的記憶體(i.e. <code class="language-plaintext highlighter-rouge">mark and sweep</code>)</li>
</ol>

<p>具體一點來說，GC 會走訪整個 object graph(從 root 開始)</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">mark</code>
    <ul>
      <li>每一個走到的 object 它都會標記一下，表示這個 object 是活著的(i.e. <code class="language-plaintext highlighter-rouge">live</code>)</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">sweep</code>
    <ul>
      <li>全部都標完之後，那些沒有被標記到的 object 就可以被回收了</li>
    </ul>
  </li>
</ol>

<p>這個就是 <code class="language-plaintext highlighter-rouge">mark and sweep</code> 的概念</p>

<p><img src="/assets/img/posts/mark_and_sweep.gif" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://go.dev/blog/greenteagc">The Green Tea Garbage Collector</a></p>
</blockquote>

<h4 id="cyclic-reference">Cyclic Reference</h4>
<p>你會想，建立 object graph 不就是 <a href="#reference-counting">Reference Counting</a>？<br />
不一樣！ 因為 <a href="#reference-counting">Reference Counting</a> 沒辦法區分出 <strong><em>循環引用的問題</em></strong><br />
cycle import 的情況下，reference count 會永遠不會歸零，所以這塊記憶體永遠不會被回收<br />
但是 <a href="#mark-and-sweep">Mark and Sweep</a> 不會</p>

<p>因為 object graph 其實是有 root 節點的，這些 root 節點可以是 <code class="language-plaintext highlighter-rouge">local/global variables</code><br />
從 root 節點往下找所有 object 使用情況，如果遇到 <strong>循環引用</strong> 但是它沒辦法從 root 節點走到，那它還是會被回收<br />
所以 <a href="#mark-and-sweep">Mark and Sweep</a> 可以正確的回收這些循環引用的記憶體</p>

<h2 id="moving-vs-non-moving-gc">Moving vs Non-moving GC</h2>
<p>各位不曉得還記不記得所謂的 Fragmentation 問題<br />
你動態分配的記憶體 free 掉之後，就會這邊一塊那邊一塊的<br />
等到你真的需要一塊很大的連續記憶體的時候，你就沒辦法操作</p>

<p>這種情況是所謂的 <code class="language-plaintext highlighter-rouge">External Fragmentation</code></p>

<p><img src="https://inside.java/images/blog/compact-forwarding/heapgc_defrag.png" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://inside.java/2020/06/25/compact-forwarding/">Compact Forwarding Information</a></p>
</blockquote>

<p>GC 同樣也會面臨到相同的挑戰，既然記憶體是分散的<br />
你是不是能手動把它整理在一起(就是每一塊記憶體都是緊緊貼著彼此的)，這樣碎裂化的問題就可以得到緩解？<br />
這種方式稱為 <code class="language-plaintext highlighter-rouge">Moving GC</code></p>

<p>具體來說怎麼做呢？<br />
GC 會幫記憶體搬家，但是呢 所有使用到相同記憶體的地方都要更新(很合理嘛不然東西會錯掉)<br />
為了確保你不會存取到錯誤的記憶體，在這個階段你的程式會被暫停</p>

<p>舊的記憶體位置放所謂的 <code class="language-plaintext highlighter-rouge">forwarding pointer</code>，這個 pointer 指向新的記憶體位置<br />
GC 會走訪整個 object graph，當碰到 forwarding pointer 的時候它就會更新成新的記憶體位置<br />
到最後所有相對應的 reference 都會被更新</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>object -&gt; old memory location
object -&gt; forwarding pointer -&gt; new memory location
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="garbage-collection-trade-offs">Garbage Collection Trade-offs</h1>
<p>在上計算機組織的時候，有一個概念是 <strong>要讓常跑的東西跑得快</strong>，這樣整體效能就會有很大的提昇<br />
對於 Garbage Collection 來說，也是一樣的道理</p>

<p>GC 需要不間斷的運行，才能確保最高的記憶體利用效率<br />
但是一直執行垃圾回收，對你本身的 application 來說也是會有一定的影響的<br />
比如說你的程式會被暫停，這樣的話你的程式就會變得很慢</p>

<p>垃圾回收機制本身會有哪些開銷呢？</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">type</th>
      <th style="text-align: left">description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">CPU time</td>
      <td style="text-align: left">能夠影響 CPU time 的會是 <code class="language-plaintext highlighter-rouge">object graph</code> 的大小<br />因為如果圖很大，走訪的時間就會比較久</td>
    </tr>
    <tr>
      <td style="text-align: left">Memory</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">object graph</code> 會直接影響到記憶體的使用量<br />並且加上其他 metadata，這些都會佔用記憶體</td>
    </tr>
  </tbody>
</table>

<p>真實世界中，你的記憶體不大可能是一直平穩的(i.e. <code class="language-plaintext highlighter-rouge">steady-state</code>)，比較多時候會是一下高一下低的狀況<br />
比方說 web application, 可能遇到做活動流量突然爆增，這時候 GC 的開銷就會變大<br />
而且你還要考慮這些記憶體，有可能會經過很多個 GC cycle, 也就是它執行很久(釋放的少，使用的多)</p>

<p>我們可以藉由調整 GC 執行間隔換取不同的效能<br />
比如說你想要節省 CPU 你就可以把 GC 的執行間隔拉長，但是這樣的話記憶體就會被佔用很多(因為沒清理)<br />
同樣的，如果你想要節省記憶體，你就可以把 GC 的執行間隔拉短，但是這樣的話 CPU 就會被佔用很多(因為一直跑)</p>

<p>舉例來說</p>
<ul>
  <li>假設一個 golang app 處於 <code class="language-plaintext highlighter-rouge">steady state</code>，記憶體使用量是 <code class="language-plaintext highlighter-rouge">10MiB/s</code>(意思就是每秒固定多 alloc 10MiB 的記憶體)</li>
  <li>假設當前 live heap 的大小是 <code class="language-plaintext highlighter-rouge">10MiB</code></li>
  <li>GC 需要花費 1 cpu-second 掃描 <code class="language-plaintext highlighter-rouge">100MiB</code> 的記憶體</li>
</ul>

<p>如果</p>
<ul>
  <li>GC 執行 cycle 是 1 cpu-second，那麼表示
    <ul>
      <li>在 1-cpu second 內，有 <strong>額外的 10MiB</strong> 記憶體被索取，目前的 live heap 大小是原本的 10MiB 加上 10MiB，總共 <code class="language-plaintext highlighter-rouge">20MiB</code></li>
      <li>GC 需要花費 0.1 cpu-second 來掃描 <strong><em>當前的 live heap</em></strong>(也就是 <code class="language-plaintext highlighter-rouge">10MiB</code>)</li>
      <li>所以 GC 佔用 CPU 的使用率是 <code class="language-plaintext highlighter-rouge">10%</code></li>
    </ul>
  </li>
  <li>GC 執行 cycle 是 2 cpu-second，那麼表示
    <ul>
      <li>在 2-cpu second 內，有 <strong>額外的 20MiB</strong> 記憶體被索取，目前的 live heap 大小是原本的 10MiB 加上 20MiB，總共 <code class="language-plaintext highlighter-rouge">30MiB</code></li>
      <li>GC 需要花費 <strong>仍然是</strong> 0.1 cpu-second 來掃描 <strong><em>當前的 live heap</em></strong>(也就是 <code class="language-plaintext highlighter-rouge">10MiB</code>)</li>
      <li>所以 GC 佔用 CPU 的使用率是 <code class="language-plaintext highlighter-rouge">5%</code></li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>為什麼 GC 只掃描 live heap 而不是整個 heap<br />
你不需要掃描完整的 heap，如果套用 <a href="#mark-and-sweep">Mark and Sweep</a><br />
從當前 live heap 如果走不到，那就代表它可以被回收<br />
所以實際上的開銷會是 1.) 當前 live heap 的大小以及 2.) 能夠從 live heap 被走到的少量記憶體(額外的記憶體)</p>
</blockquote>

<p>當你調整 GC cycle 的速度調慢 <code class="language-plaintext highlighter-rouge">50%</code> 的時候，雖然 GC 的 CPU 使用率 <strong>降低</strong> <code class="language-plaintext highlighter-rouge">50%</code>，但是記憶體使用量 <strong>增加</strong> <code class="language-plaintext highlighter-rouge">50%</code></p>

<h2 id="gogc">GOGC</h2>
<p>你可以透過調整 <code class="language-plaintext highlighter-rouge">GOGC</code> 的參數<br />
<code class="language-plaintext highlighter-rouge">GOGC</code> 的數值是 CPU 與 memory 的 trade-off<br />
當數值越大，Target Heap 的容量越大，GC 的間隔會被拉長，進而導致 CPU overhead 降低，反之亦然</p>

<blockquote>
  <p>設計上 Target Heap memory 會影響 GC 的間隔，它就是這樣設計的</p>
</blockquote>

<h2 id="gomemlimit">GOMEMLIMIT</h2>
<p>不過無限上調 GOGC 的數值是不合理的，因為記憶體數量終其有上限<br />
所以可以設定 memory limit(i.e. <code class="language-plaintext highlighter-rouge">GOMEMLIMIT</code>)<br />
這個限制主要是針對 Heap memory 的限制</p>

<p>不過如果你設定了 memory limit 又把 GC 關閉，就會造成 <code class="language-plaintext highlighter-rouge">Thrashing</code> 的狀況<br />
你把 GC 關了意味著記憶體不會回收，同時設定記憶體上限，最終記憶體就會被用光<br />
進而導致你的程式逐漸失去回應(i.e. <code class="language-plaintext highlighter-rouge">stall</code>)</p>

<p>為了避免這種狀況發生，Golang Runtime 其實將 memory limit 視為是 <strong><em>非硬性規定</em></strong><br />
因為如果你兩個都設定了，最終一定會導致 <code class="language-plaintext highlighter-rouge">Thrashing</code> 的狀況發生<br />
那不如讓你 bypass 掉這個限制，讓你的程式能夠繼續跑比較重要 是吧？<br />
也就是說 application 可以拿到 CPU time 來跑，換句話說，GC 分到的 CPU time 就會變少<br />
等於 GC 的 cycle 會被拉長，可以理解吧</p>

<blockquote>
  <p>cycle 拉長，一個 cpu-second 內原本能跑 0.3 cpu-second 的 GC，現在只有拿到 0.1 cpu-second 的 GC<br />
原本等待時間是 0.7 cpu-second 變成 0.9 cpu-second</p>
</blockquote>

<p>GC 在一個 cycle 內能使用的 CPU time 通常會有一個上限，比如說最多只能佔 50% 的 CPU time<br />
這樣的好處在於說，你的 application 最差只會慢 <strong>一倍</strong></p>

<blockquote>
  <p>GC 關掉，100% CPU time 都是 application 拿，假設花 10 秒<br />
GC 開啟，50% CPU time 是 GC 拿，50% CPU time 是 application 拿，因為每個 cycle application 執行時間少了一半，所以總共花 20 秒<br />
因此是 <code class="language-plaintext highlighter-rouge">10秒</code> 變 <code class="language-plaintext highlighter-rouge">20秒</code>，所以是一倍</p>
</blockquote>

<h1 id="evolution-of-golang-garbage-collector">Evolution of Golang Garbage Collector</h1>
<h2 id="stop-the-world-mark-and-sweep">Stop-the-World Mark and Sweep</h2>
<p>Golang 早期的實作是 <a href="#mark-and-sweep">Mark and Sweep</a> 並且屬於 <a href="#moving-vs-non-moving-gc">Non-moving GC</a><br />
根據不同的 GC 實作，有的會需要 <strong>Stop-the-World</strong>(i.e. <strong>STW</strong>) 的機制，也就是說你的程式會被暫停，直到 GC 完成<br />
這種作法無疑是犧牲了應用程式的效能，Golang 在這方面，選擇 GC 與 application 同步執行(i.e. <code class="language-plaintext highlighter-rouge">not fully Stop-the-World GC</code>)</p>

<p>即使是 <strong>Stop-the-World</strong> 的作法，<a href="#mark-and-sweep">Mark and Sweep</a> 還是要走過完整的 <strong>Live Heap</strong><br />
也就是說 <strong>STW</strong> 的情況下，GC 暫停的時間與 Live Heap 的大小成正比<br />
又因為 <strong>STW</strong> 會導致應用程式暫停，所以 latency 會被拉高</p>

<p>latency 維持比較低通常是比較好的狀況，代表使用者可以有比較好的體驗(按下按鈕到看到結果的時間是相對短暫的)<br />
既然 <strong>STW</strong> 的作法會導致較高的延遲，自然而然就變成 <code class="language-plaintext highlighter-rouge">not fully Stop-the-World GC</code> 的實作</p>

<blockquote>
  <p>low latency != low throughput</p>
</blockquote>

<h2 id="tricolor-mark-and-sweep">Tricolor Mark and Sweep</h2>
<p>相比於 <a href="#mark-and-sweep">Mark and Sweep</a>，Tricolor Mark and Sweep 在實作上引入了額外的一種狀態(處理中 的狀態)<br />
使 GC 可以針對不同狀態的 object 進行不同的處理<br />
這些狀態我們會使用三種顏色表示</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">color</th>
      <th style="text-align: left">description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">white</code></td>
      <td style="text-align: left">沒辦法被拜訪到的 object，之後可以被回收</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">gray</code></td>
      <td style="text-align: left">可以拜訪到的 object，但是需要進一步掃描</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">black</code></td>
      <td style="text-align: left">確定正在使用中的 object</td>
    </tr>
  </tbody>
</table>

<p>當 GC 開始的時候，所有的 object 都會被標記為 <code class="language-plaintext highlighter-rouge">white</code><br />
從 GC root 開始先把走得到的標記成 <code class="language-plaintext highlighter-rouge">gray</code><br />
再把 <code class="language-plaintext highlighter-rouge">gray</code> 標記為 <code class="language-plaintext highlighter-rouge">black</code> 直到所有 <strong><em>處理中(gray)</em></strong> 的 object 都消失<br />
這時候只剩下 <code class="language-plaintext highlighter-rouge">white</code> 跟 <code class="language-plaintext highlighter-rouge">black</code> 的 object</p>

<p>因為我們確定說 <code class="language-plaintext highlighter-rouge">black</code> 的 object 是正在使用中的 object，所以就繼續放著<br />
至於 <code class="language-plaintext highlighter-rouge">white</code> 的 object 就是可以被回收的 object<br />
至此，GC 就完成了</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/1/1d/Animation_of_tri-color_garbage_collection.gif" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">Tracing garbage collection</a></p>
</blockquote>

<hr />

<p>但是光有 Tricolor 的機制其實還不足<br />
既然 Golang 選擇 <code class="language-plaintext highlighter-rouge">not fully Stop-the-World GC</code>，其中一個挑戰就是如何確保資料的正確性</p>

<p>不同於 <a href="#mark-and-sweep">Mark and Sweep</a> 這種 STW GC<br />
同時執行 GC 與 application，因為 app 會去動記憶體嘛，那是不是有可能之前標記過得資料被移動，導致 GC 標記錯誤<br />
然後執行就會有問題</p>

<h3 id="write-barrier">Write Barrier</h3>
<p>即使是 <a href="#tricolor-mark-and-sweep">Tricolor Mark and Sweep</a>，GC 本身也需要額外透過 <em>Write Barrier</em> 的幫忙來解決記憶體移動，然後標記的問題<br />
注意到 Race 本身還是存在的，只是說 <em>Write Barrier</em> 可以確保這個 Race 的結果會被 GC 所得知，進而避免錯誤的處理</p>

<p>舉例來說，假設 A 已經被標記為 黑色 (Black)（代表 GC 已掃描完 A），而 B 是 灰色 (Gray)<br />
原本的連結是 B -&gt; C<br />
但是呢，app 突然將連結改成 A -&gt; C 並切斷了 B -&gt; C<br />
在沒有 Write Barrier 的情況下：</p>
<ol>
  <li>下一個掃描步驟會把 B 標記為黑色，但因為 B -&gt; C 已斷開，GC 沒機會把 C 染灰</li>
  <li>而 A 已經是黑色，GC 不會回頭再掃描 A，所以也不會發現 A -&gt; C</li>
  <li>最後，C 仍維持 白色 (White)，導致這個還在被使用的物件被當成垃圾回收掉</li>
</ol>

<p>所以 <em>Write Barrier</em> 就是用來解決此類問題的</p>

<h4 id="dijkstra-barrier">Dijkstra barrier</h4>
<p>至於說他是怎麼做的呢？</p>

<p>首先，Tricolor 的 GC 需要嚴格遵守以下的 invariant</p>

<blockquote>
  <p>No <code class="language-plaintext highlighter-rouge">black</code> object may contain a pointer to a <code class="language-plaintext highlighter-rouge">white</code> object.</p>
</blockquote>

<p>啥意思？ 因為 <code class="language-plaintext highlighter-rouge">white</code> object 會被 GC 掉，但如果被 reference 到，它應該要是 <code class="language-plaintext highlighter-rouge">gray</code> 的</p>

<p>再來的問題是，我要檢查誰？ 只有指標是需要的，一般變數因為生命週期是可以預期的，所以 GC 可以不處理<br />
當任何 pointer update(i.e. read、write 或是 read and write) 發生的時候都需要做再一次的檢查<br />
為什麼是當 pointer update? 因為 GC 是透過 pointer 來拜訪 object 的<br />
它指到誰 指到哪 很重要</p>

<p>怎麼做就有趣了<br />
Golang 原本只有單純的 <a href="https://www.cs.utexas.edu/~EWD/ewd04xx/EWD496B.PDF">Dijkstra barrier</a><br />
實作上來說也挺簡單的</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>writePointer(slot, ptr):
    shade(ptr)
    *slot = ptr
</pre></td></tr></tbody></table></code></pre></div></div>

<p>shade() 必須先將 <code class="language-plaintext highlighter-rouge">ptr</code> 標記為 <code class="language-plaintext highlighter-rouge">gray</code><br />
因為如果他是白色的，就會違反 invariant<br />
把它變成 <code class="language-plaintext highlighter-rouge">gray</code> 的另一個目的是讓 GC 不要把 ptr 當成是 <code class="language-plaintext highlighter-rouge">white</code> object 回收掉</p>

<p><img src="https://www.dingyuqi.com/illustration/dijkstra-insert-write-barrier.png" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://www.dingyuqi.com/en/article/go-garbage-collection/">Understanding Garbage Collection in Go</a></p>
</blockquote>

<p>不過他也有缺點<br />
<a href="#write-barrier">Write Barrier</a> 中提到的問題，<a href="#dijkstra-barrier">Dijkstra barrier</a> 本身有兩種方式可以解決</p>
<ol>
  <li>你需要一個 <code class="language-plaintext highlighter-rouge">Stack Memory Barrier</code></li>
  <li>你必須確保 stack 上的資料是 <code class="language-plaintext highlighter-rouge">permagray</code>(永久灰)</li>
</ol>

<p>Golang 選擇後者(因為 Stack Memory Barrier 的成本太高)，但是要怎麼保證 stack 上的資料是 <code class="language-plaintext highlighter-rouge">permagray</code> 呢？<br />
你需要一直去檢查 <strong>goroutine</strong> 的 stack 內的東西是不是合法的(i.e. 符合 invariant)</p>

<p>舉例來說，Heap 內的指標可能會指向 Stack 裡的 White Object<br />
當碰到這種狀況，你必須要確保 Stack 內的 White Object 不會被回收掉<br />
所以重新掃描是必要的(i.e. <code class="language-plaintext highlighter-rouge">Stack Rescan</code>)</p>

<p>但這個掃描是很頻繁且耗時的<br />
GC cycle 開始之前要掃一次，結束之前也要再掃一次<br />
每一次的掃描其實都需要 Stop-the-World，不然 stack 內的資料有可能會被改動</p>

<blockquote>
  <p>Re-scanning the stacks can take 10’s to 100’s of milliseconds in an application with a large number of active goroutines.</p>
</blockquote>

<h4 id="yuasa-style-deletion-write-barrier">Yuasa-style Deletion Write Barrier</h4>
<p><a href="https://www.sciencedirect.com/science/article/abs/pii/016412129090084Y">Yuasa-style deletion write barrier</a> 與 <a href="#dijkstra-barrier">Dijkstra barrier</a> 的差別在於，Yuasa-style 是標記 <strong>被刪除的 object</strong> 為 <code class="language-plaintext highlighter-rouge">gray</code><br />
而 <a href="#dijkstra-barrier">Dijkstra barrier</a> 是標記 <strong>被更新的 pointer</strong> 為 <code class="language-plaintext highlighter-rouge">gray</code><br />
所以 Yuasa-style 才稱為 <em>Deletion Write Barrier</em></p>

<blockquote>
  <p>ptr 不需要 shade 嗎？ 因為它其實是被 “chain” 起來的，所以 GC 會找到它</p>
</blockquote>

<p>實作上就會是</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>writePointer(slot, ptr):
    shade(*slot)
    *slot = ptr
</pre></td></tr></tbody></table></code></pre></div></div>

<p>範例圖中要記得，shade() 的對象是 <code class="language-plaintext highlighter-rouge">B</code>，因為他才是被拔掉的 object</p>

<p><img src="https://www.dingyuqi.com/illustration/yuasa-delete-write-barrier.png" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://www.dingyuqi.com/en/article/go-garbage-collection/">Understanding Garbage Collection in Go</a></p>
</blockquote>

<p>不過它有比 <a href="#dijkstra-barrier">Dijkstra barrier</a> 還要好嗎？<br />
Yuasa 在 pointer update 之前就會先 shade 舊值，因此不論它被移動到哪裡去，GC 都會找到它<br />
也因為這個特性，Yuasa 的作法不需要 Stack Rescan</p>

<h4 id="hybrid-write-barrier">Hybrid write barrier</h4>
<p>而為了要解決 <a href="#dijkstra-barrier">Dijkstra barrier</a> Stack Rescan 的缺點<br />
新版 Golang GC 的架構採用 hybrid write barrier 來解決這個問題(結合了 <a href="#dijkstra-barrier">Dijkstra barrier</a> 與 <a href="#yuasa-style-deletion-write-barrier">Yuasa-style deletion write barrier</a>)</p>

<p>最終 write barrier 的實作會長這樣</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>writePointer(slot, ptr):
    shade(*slot)
    if current stack is grey:
        shade(ptr)
    *slot = ptr
</pre></td></tr></tbody></table></code></pre></div></div>

<p>結合了兩種作法的優點</p>
<ul>
  <li><a href="#dijkstra-barrier">Dijkstra barrier</a>: 允許 concurrent scan</li>
  <li><a href="#yuasa-style-deletion-write-barrier">Yuasa-style deletion write barrier</a>: 不需要 Stack Rescan</li>
</ul>

<blockquote>
  <p>雖然 Dijkstra 與 Yuasa 都允許 concurrent scan，但是 Dijkstra 的 concurrent 程度更高</p>
</blockquote>

<p>但是新的 hybrid write barrier 實際上無法滿足 Tricolor 的 invariant<br />
相反的是，提供了一個 <code class="language-plaintext highlighter-rouge">稍微弱的 invariant</code></p>

<blockquote>
  <p>No <code class="language-plaintext highlighter-rouge">black</code> object may contain a pointer to a <code class="language-plaintext highlighter-rouge">white</code> object. :x:<br />
Any white object pointed to by a black object is reachable from a grey object via a chain of white pointers (it is grey-protected). :heavy_check_mark:</p>
</blockquote>

<p>自始至終 GC 的挑戰都是要能夠避免 “mutator” 隱藏 object 的問題<br />
這個稍微弱的 invariant 允許隱藏得很深的 <code class="language-plaintext highlighter-rouge">white</code> object 能夠被 GC 所感知，那基本上要能夠走訪就代表它應該是在同一個 “chain” 上的</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">shade(*slot)</code>
    <ul>
      <li>借鑒 <a href="#yuasa-style-deletion-write-barrier">Yuasa-style deletion write barrier</a> 的作法，使其不需要進行 Stack Rescan。這個操作可以在 “從 Heap 搬遷到內部 Stack 的過程中” 防止 mutator 試圖隱藏 object</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">shade(ptr)</code>
    <ul>
      <li>借鑒 <a href="#dijkstra-barrier">Dijkstra barrier</a> 的作法。這個操作可以在 “從內部 Stack 搬遷到 Heap 的過程中” 防止 mutator 試圖隱藏 object，不過如果 stack 已經掃完然後變 <code class="language-plaintext highlighter-rouge">black</code>，那就不需要了(原本要把 ptr 標記為 <code class="language-plaintext highlighter-rouge">gray</code> 做後續處理，但因為 ptr 本身在的 stack 已經掃完了，所以不需要)</li>
    </ul>
  </li>
</ul>

<h2 id="green-tea-garbage-collector">Green Tea Garbage Collector</h2>
<p>針對 <a href="#mark-and-sweep">Mark and Sweep</a> 的算法來說，幾乎所有的成本都是在 mark 的過程，sweep 一直以來都沒什麼大問題<br />
具體的差別大概是 90% mark 以及 10% sweep<br />
而在 mark 階段中，大約會花費 35% 的時間是在等待 heap memory 的存取，這顯然是一個可以優化的空間</p>

<p>而造成這個問題的原因是，多數資料是分散在記憶體中的<br />
GC 在執行的時候如果東西不在旁邊(i.e. cache)，就需要跑到 main memory 去拿<br />
而這會浪費很多時間</p>

<p>與其這樣做，不如盡量讓所有資料存取可以在附近就拿到<br />
這樣我們可以縮短 memory 的存取時間，進而提昇 GC 的效率</p>

<hr />

<p>新的 GC 算法旨在解決上述效能問題<br />
不過它本質上也還是 <a href="#mark-and-sweep">Mark and Sweep</a>，其核心的概念是</p>

<blockquote>
  <p>Work with pages, not objects</p>
</blockquote>

<p>雖然說是處理 page, 但實際上你還是要處理 object，在某種程度上<br />
所以新的架構會需要 metadata 來做這件事，這個 metadata 有兩個部分</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">seen</code>: 代表這個 object 被看過</li>
  <li><code class="language-plaintext highlighter-rouge">scanned</code>: 代表這個 object 被掃描過</li>
</ul>

<p>奇怪了？ 為什麼要區分 <code class="language-plaintext highlighter-rouge">seen</code> 跟 <code class="language-plaintext highlighter-rouge">scanned</code> 呢？<br />
你看過不就等於掃描過了嗎<br />
其實這正是 <strong>Green Tea</strong> 的精髓所在</p>

<p>早期，每一個 object 只會被加入 work list 一次，但是 page 的方法下，每一個 page 都會被加入 “很多次”<br />
而且不同的地方在於，如果他有 reference 到其他 object，他只會跑過去 <em>標記 seen</em> 而已，他並不會直接跑去掃描他<br />
等到我掃描完一個 work list 之後，我再從 metadata 中找出那些被 seen 過的 object，並且把他們加入到 work list 中<br />
這也是 <strong>Green Tea</strong> 效率高的關鍵</p>

<p><img src="/assets/img/posts/greentea.gif" alt="" /></p>

<blockquote>
  <p>ref: <a href="https://go.dev/blog/greenteagc">The Green Tea Garbage Collector</a></p>
</blockquote>

<p>改成掃描 page 的方式會減少 scan 的次數，不過每一次 scan 的時間會變長<br />
但這也是沒關係的，因為每一個 page 裡面的 object 都是緊密相鄰的，也就是說 cache hit 的機率更高對吧<br />
又因為 scan 的次數減少了，也代表 CPU 的壓力會降低</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Flood</th>
      <th style="text-align: center">Green Tea</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://go.dev/blog/greenteagc/graphflood-path2.png" alt="" /></td>
      <td style="text-align: center"><img src="https://go.dev/blog/greenteagc/greentea-path.png" alt="" /></td>
    </tr>
    <tr>
      <td style="text-align: center">ref: <a href="https://go.dev/blog/greenteagc">The Green Tea Garbage Collector</a></td>
      <td style="text-align: center">ref: <a href="https://go.dev/blog/greenteagc">The Green Tea Garbage Collector</a></td>
    </tr>
  </tbody>
</table>

<p>並且 <strong>Green Tea</strong> 可以受益於 CPU 架構的改進，例如 AVX-512 指令集擁有 512 位元的暫存器的大小允許 <strong>Green Tea</strong> 可以將 metadata 全部塞進去，而且在 vector register 上也有 bitwise operation 的支援，使得 Scanning 的過程僅需少量 CPU cycle 即可完成</p>

<h3 id="performance-evaluation">Performance Evaluation</h3>
<p>根據 Google 官方的測試，<code class="language-plaintext highlighter-rouge">Green Tea</code> 普遍情況下可以有 10% ~ 40% 左右的性能提升<br />
不過在某些特定的情況下不是</p>

<p><strong>Green Tea</strong> 的做法本質上是將瑣碎的 scan 的次數減少，合併成一個大型的 page scan 來達到加速的效果<br />
問題是，並非每一次都可以這樣 scan<br />
如果遇到 single object per page 的情況，那麼那些優勢就會蕩然無存</p>

<p>注意到，極端情況下，performance 甚至可能會比 <code class="language-plaintext highlighter-rouge">Flood</code> 還要差<br />
雖然說實作上有針對 single object per page 的情況做優化，但並沒辦法完全消除<br />
不過，你可能很難遇到這種情況，事實上，只要你能夠掃描 <strong><em>2% 的 page 資料</em></strong>，其效能就能夠超越 <code class="language-plaintext highlighter-rouge">Flood</code> 算法</p>

<h1 id="goroutine-count-to-affect-garbage-collection">Goroutine Count to Affect Garbage Collection</h1>
<p>本次實驗，使用環境如下</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">uname</span> <span class="nt">-a</span>
Linux station 6.8.0-90-generic <span class="c">#91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2 x86_64 x86_64 x86_64 GNU/Linux</span>

<span class="nv">$ </span>go version
go version go1.25.5 linux/amd64
</pre></td></tr></tbody></table></code></pre></div></div>

<p>實驗內容會開到 100000 個 Goroutine 一起測試<br />
其內容就是單純的 <code class="language-plaintext highlighter-rouge">time.Sleep</code> 這樣</p>

<p><img src="https://github.com/ambersun1234/blog-labs/blob/master/golang-gc/golang-memory.png?raw=true" alt="" /></p>

<p>先查看，不同數量的 Goroutine 開起來的時候，會需要多少的 Heap 以及 Stack 的空間<br />
可以看到，<code class="language-plaintext highlighter-rouge">10w</code> 個 Goroutine 會使用到約 <code class="language-plaintext highlighter-rouge">200MB</code> 的 Stack 記憶體<br />
可以得出一個 Goroutine 會先分配 <code class="language-plaintext highlighter-rouge">2KB</code> 的空間，跟官方宣稱的一樣</p>

<p>Heap 記憶體的部份，<code class="language-plaintext highlighter-rouge">10w</code> 個 Goroutine 則是大概 <code class="language-plaintext highlighter-rouge">56MB</code> 左右</p>

<p><img src="https://github.com/ambersun1234/blog-labs/blob/master/golang-gc/golang-gc-swt.png?raw=true" alt="" /></p>

<p><img src="https://github.com/ambersun1234/blog-labs/blob/master/golang-gc/golang-gc-total.png?raw=true" alt="" /></p>

<p>而實際測試出來的 GC 時間，也可以看到，基本上 Green Tea 的 GC 時間是比 Flood 要來的短<br />
只不過正如前面提到的，性能提昇的幅度並不是很大<br />
實際跑測試大概落在 <code class="language-plaintext highlighter-rouge">14%</code> 左右</p>

<p>關於 benchmark 的實作可以參考 <a href="https://github.com/ambersun1234/blog-labs/tree/master/golang-gc">ambersun1234/blog-labs/golang-gc</a></p>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">Tracing garbage collection</a></li>
  <li><a href="https://tip.golang.org/doc/gc-guide">A Guide to the Go Garbage Collector</a></li>
  <li><a href="https://inside.java/2020/06/25/compact-forwarding/">Compact Forwarding Information</a></li>
  <li><a href="https://go.dev/blog/greenteagc">The Green Tea Garbage Collector</a></li>
  <li><a href="https://aimuke.github.io/go/2019/05/21/gc-tricolor-algorithm/">图解Golang的GC算法-三色标记法</a></li>
  <li><a href="https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md">design/17503-eliminate-rescan.md</a></li>
  <li><a href="https://www.facebook.com/groups/system.software2020/posts/531299507804253/">2020 年系統軟體系列課程討論區</a></li>
  <li><a href="https://www.dingyuqi.com/en/article/go-garbage-collection/">Understanding Garbage Collection in Go</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="random" /><category term="golang" /><category term="goroutine" /><category term="garbage collection" /><category term="gc" /><category term="reference counting" /><category term="mark and sweep" /><category term="tricolor mark and sweep" /><category term="moving gc" /><category term="non-moving gc" /><category term="fragmentation" /><category term="external fragmentation" /><category term="internal fragmentation" /><category term="steady state" /><category term="thrashing" /><category term="gogc" /><category term="gomemlimit" /><category term="green tea gc" /><category term="flood gc" /><category term="golang gc" /><category term="dijkstra barrier" /><category term="yuasa style deletion write barrier" /><category term="object graph" /><category term="live heap" /><category term="cycle reference" /><category term="stop the world" /><category term="write barrier" /><category term="steady state" /><summary type="html"><![CDATA[Goroutine 本身是輕量的，但如果無上限的開 Goroutine 會對程式造成一定的影響。本篇文章會先探討 Golang Garbage Collection 的機制，從早期 non fully stop the world 的 GC 到現在的 Green Tea GC，這些改進對於整體效能可以有多大的提昇。最後透過一個簡單的實驗視覺化新版 Green Tea GC 的表現，以此了解在不同數量級下的 Goroutine 會有多大的影響]]></summary></entry><entry><title type="html">Kubernetes 從零開始 - Pod 高級抽象 Workload Resources</title><link href="https://ambersuncreates.com/kubernetes/kubernetes-workloads/" rel="alternate" type="text/html" title="Kubernetes 從零開始 - Pod 高級抽象 Workload Resources" /><published>2025-11-23T00:00:00+08:00</published><updated>2025-11-23T22:32:20+08:00</updated><id>https://ambersuncreates.com/kubernetes/kubernetes-workloads</id><content type="html" xml:base="https://ambersuncreates.com/kubernetes/kubernetes-workloads/"><![CDATA[<h1 id="high-level-abstraction">High Level Abstraction</h1>
<p>之前提到 Pod 是 Kubernetes 當中部署的最小單位，因為其設計關係(比如說容易被 reschedule 以及被刪除等等)，是比較不適合直接操作的<br />
因此 Kubernetes 提供了更高層次的抽象，讓我們可以更方便的管理 Pod<br />
本文將會走過一遍這些更高階的抽象實作，並且介紹他們的特性</p>

<blockquote>
  <p>可參考 <a href="../../kubernetes/kubernetes-pod">Kubernetes 從零開始 - 容器基本抽象 Pod | Shawn Hsu</a></p>
</blockquote>

<h1 id="workload-workload-resources-and-resources">Workload, Workload Resources and Resources</h1>
<h2 id="workload">Workload</h2>
<p>一個執行在 Kubernetes 上的應用程式，稱之為 Workload</p>

<h2 id="workload-resources">Workload Resources</h2>
<p>比方說剛開始認識 Kubernetes 的時候，你會使用 Deployment 建構你的前後端服務<br />
<a href="#deployment">Deployment</a> 就是其中的一種，也是最常見的 <a href="#workload-resources">Workload Resources</a></p>

<p>與直接操作 Pod 不同，<a href="#workload-resources">Workload Resources</a> 提供了更高階的抽象，讓你可以更方便的管理 Pod<br />
假設該節點發生故障，那上面的 Pod 都會被消失嘛，透過 Controller 它會自動幫你恢復到預期狀態<br />
等於說讓 Kubernetes 幫我們管理全部的狀態<br />
我們就能夠專注在應用程式的開發上</p>

<blockquote>
  <p>有關 Controller 可以參考 <a href="../../kubernetes/kubernetes-controller">Kubernetes 從零開始 - 從自幹 Controller 到理解狀態管理 | Shawn Hsu</a></p>
</blockquote>

<p>除了基本的 Workload Resource 之外，為了讓開發者能有更彈性的資源管理<br />
<code class="language-plaintext highlighter-rouge">Custom Resource Definition(CRD)</code> 被引入了<br />
利用 CRD 你可以定義自己的 Resource 將它利用於你的應用程式中<br />
所以 CRD 也可以算是 Workload Resource 的一種</p>

<blockquote>
  <p>有關 CRD 可以參考 <a href="../../kubernetes/kubernetes-crd">Kubernetes 從零開始 - client-go 實操 CRD | Shawn Hsu</a></p>
</blockquote>

<h2 id="resources">Resources</h2>
<p>注意到 <a href="#workload-resources">Workload Resources</a> 與 <a href="#resources">Resources</a> 之間的差異<br />
<a href="#resources">Resources</a> 泛指所有你可以在 Kubernetes 中使用的物件，而 <a href="#workload-resources">Workload Resources</a> 是其中一個類別<br />
像是你可能有印象的 <code class="language-plaintext highlighter-rouge">ConfigMap</code>, <code class="language-plaintext highlighter-rouge">Secret</code>, <code class="language-plaintext highlighter-rouge">Service</code> 等等都是所謂的 Resource<br />
你可以用 <code class="language-plaintext highlighter-rouge">$ kubectl api-resources</code> 來查看所有的 Resources</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl api-resources
NAME                              SHORTNAMES   APIVERSION                        NAMESPACED   KIND
bindings                                       v1                                <span class="nb">true         </span>Binding
configmaps                        cm           v1                                <span class="nb">true         </span>ConfigMap
endpoints                         ep           v1                                <span class="nb">true         </span>Endpoints
events                            ev           v1                                <span class="nb">true         </span>Event
limitranges                       limits       v1                                <span class="nb">true         </span>LimitRange
namespaces                        ns           v1                                <span class="nb">false        </span>Namespace
nodes                             no           v1                                <span class="nb">false        </span>Node
persistentvolumeclaims            pvc          v1                                <span class="nb">true         </span>PersistentVolumeClaim
persistentvolumes                 pv           v1                                <span class="nb">false        </span>PersistentVolume
pods                              po           v1                                <span class="nb">true         </span>Pod
podtemplates                                   v1                                <span class="nb">true         </span>PodTemplate
replicationcontrollers            rc           v1                                <span class="nb">true         </span>ReplicationController
resourcequotas                    quota        v1                                <span class="nb">true         </span>ResourceQuota
secrets                                        v1                                <span class="nb">true         </span>Secret
serviceaccounts                   sa           v1                                <span class="nb">true         </span>ServiceAccount
services                          svc          v1                                <span class="nb">true         </span>Service
apiservices                                    apiregistration.k8s.io/v1         <span class="nb">false        </span>APIService
controllerrevisions                            apps/v1                           <span class="nb">true         </span>ControllerRevision
daemonsets                        ds           apps/v1                           <span class="nb">true         </span>DaemonSet
deployments                       deploy       apps/v1                           <span class="nb">true         </span>Deployment
replicasets                       rs           apps/v1                           <span class="nb">true         </span>ReplicaSet
statefulsets                      sts          apps/v1                           <span class="nb">true         </span>StatefulSet
selfsubjectreviews                             authentication.k8s.io/v1          <span class="nb">false        </span>SelfSubjectReview
tokenreviews                                   authentication.k8s.io/v1          <span class="nb">false        </span>TokenReview
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>也可以用 <code class="language-plaintext highlighter-rouge">$ kubectl api-versions</code> 查看所有支援的版本<br />
api-resources 只會列出最低支援的版本，如果同時有多個版本，需要 api-versions 來確認</p>
</blockquote>

<h1 id="brief-introduction-to-workload-resources">Brief Introduction to Workload Resources</h1>
<h2 id="replicaset">ReplicaSet</h2>
<p>在 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployment</a> 有寫一句話 <code class="language-plaintext highlighter-rouge">A Deployment provides declarative updates for Pods and ReplicaSets.</code><br />
我們已知 Pod 是最小的部署單位，也可以說是整個 Kubernetes Cluster 的基礎，但現在看起來 ReplicaSet 好像也是 low level abstraction?</p>

<p>ReplicaSet 是用來維護一定數量的 Pod<br />
這些 Pod 是使用相同的 template 定義的，亦即所有內部執行的東西是一樣的<br />
這些 Pods 被稱之為 <strong>replica</strong></p>

<h3 id="why-manage-replicaset-through-deployment">Why Manage ReplicaSet through Deployment?</h3>
<p>ReplicaSet 貴為一種 <a href="#workload-resources">Workload Resources</a>，他的目的是確保一定數量的 Pod 在運行<br />
但是為什麼文件希望我們使用 Deployment 而不是 ReplicaSet 呢？<br />
ReplicaSet 沒辦法做到 declarative update, 所以他彈性沒有到那麼高<br />
因此官方才會推薦使用 <a href="#deployment">Deployment</a> 來管理 ReplicaSet</p>

<p>只有當</p>
<ol>
  <li>你需要 customize 更新策略</li>
  <li>不需要任何更新</li>
</ol>

<p>的時候，你才應該使用 ReplicaSet</p>

<blockquote>
  <p>所以 ReplicaSet 並不是 low level abstraction, 他只是一個比較基礎的 workload resource</p>
</blockquote>

<h2 id="deployment">Deployment</h2>
<p>針對不需要管理狀態的 service, 你可以使用 deployment<br />
狀態是啥意思？ 簡單的想法是，能夠被丟掉重開然後不會有任何影響的服務，就稱為不需要管理狀態的服務</p>

<p>資料庫，cache 這些基本上會認定為需要管理狀態的<br />
因為他底層是需要儲存資料在硬碟上的，如果 scheduler 把它排到另一台機器上，那資料就會不見了<br />
因此這種服務，就要避免使用 deployment</p>

<p>相反的，像是 backend server 這種，如果沒有使用 session 之類的來管理，那本質上他也是 stateless 的<br />
因此很適合放在 deployment 裡面<br />
scheduler 可以根據不同的需求將 backend server 安排到不同的機器上，同一時間也不會影響到服務的運作</p>

<h3 id="stateless-matters">Stateless Matters</h3>
<p>Deployment 可以管理一或多個 Pod 的狀態，而他們通常是 stateless 的服務</p>

<blockquote>
  <p>你也可以跑 Redis 在 Deployment 上面這樣也不是不行</p>
</blockquote>

<p>k8s Controller 會幫你管理 Deployment 的狀態，將他逐步的往你想要的狀態靠近<br />
簡單來說，我預期要有 3 個 Pod 在運行，但是現在只有 2 個，那 Controller 會幫你自動的補上那一個 Pod<br />
Controller 會根據你定義好的 <strong>理想的狀態</strong>，逐步的實現，並且在達到之後保持在那個狀態<br />
當出錯的時候，Controller 也會自動的幫你修復</p>

<blockquote>
  <p>k8s 是屬於 declarative programming 也就是告訴你想要的狀態，具體要怎麼做我不管</p>
</blockquote>

<h2 id="statefulset">StatefulSet</h2>
<p>說 StatefulSet 就是 <a href="#deployment">Deployment</a> 加上狀態其實不準確<br />
我原本以為單純的就是可能 volume 之類的狀態，事實上 StatefulSet 管理的狀態不只如此</p>

<p>考慮以下</p>
<ul>
  <li>Pod 在設計上就是可以被隨時丟棄的，換言之，如果它被丟棄了，它就不是原本的那個 Pod 對吧</li>
  <li>如果使用 <a href="../../kubernetes/kubernetes-volume#ephemeral-volume">Ephemeral Volume</a>，當 Pod 被重新排程，它就不是原本那個 Ephemeral Volume 了對吧</li>
  <li>如果透過 Service 訪問一群 Pods，下一次能確定訪問到的是原本的那個 Pod 嗎？</li>
  <li>如果啟動順序不同，對於這整組 Pods 來說，是不是也可以視為是不同的？</li>
</ul>

<p>以上這些問題，是 <code class="language-plaintext highlighter-rouge">StatefulSet</code> 要解決的<br />
它想要確保的是，我訪問的、存取的以及連線的，都要是原本的那個<br />
大致上可以歸類為，”穩定的” 以及 “有序的”<br />
符合以上就可以考慮使用 <code class="language-plaintext highlighter-rouge">StatefulSet</code></p>

<p>針對上述提問，解決辦法如下</p>
<ul>
  <li>給予每一個 Pod 一個 unique 的名字(i.e. <code class="language-plaintext highlighter-rouge">pod-0</code>, <code class="language-plaintext highlighter-rouge">pod-1</code>, … <code class="language-plaintext highlighter-rouge">pod-N</code>)，我們就當作他是相同的
    <ul>
      <li>可是 Pod 生命是短暫的這件事情還是成立阿？ 它還是會被刪除或重新排程<br />
相同的 identity 才是重點，因為這個 identity 有可能需要跟其他穩定資源綁定之類的，如 <a href="../../kubernetes/kubernetes-volume#persistent-volume">Persistent Volume</a></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">volumeClaimTemplates</code> 允許 StatefulSet 獨立生成一個 PVC，每個獨立的 Pod 都有一個獨立的 PVC，進而取得獨立的 PV
    <ul>
      <li>其實你也可以單純的用單一 Volume，共享 PV(存取模式可能要稍微注意就是)</li>
    </ul>
  </li>
  <li>service 有一種東西叫做 <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">Headless Service</a>，你可以直接透過 domain name 的方式直接連到 Pod 本身
    <ul>
      <li>比如說 <code class="language-plaintext highlighter-rouge">redis-master.default.svc.cluster.local</code> 這種，原本是 Service name 開頭嘛，但因為你需要直接指定 Pod 本身，所以就變成 Pod name 開頭。以這個例子來說就是有一個 Pod 叫做 <code class="language-plaintext highlighter-rouge">redis-master</code></li>
      <li>即使你可以用 domain name 的方式存取，不代表有 load balancing 的功能、cluster IP 或者 kube-proxy 處理的功能。它只是單純的把 domain name 轉換成 ip address 而已</li>
    </ul>
  </li>
  <li>啟動、刪除以及更新順序會嚴格遵照 0 到 N - 1 的順序，啟動的時候是升冪，刪除的時候是降冪
    <ul>
      <li>如果前一個沒啟動成功，下一個就會卡住，如果設定不當，可能會導致整組服務無法正常運作(可參考 <a href="https://pin-yi.me/blog/kubernetes/k8s-statefulset-podmanagementpolicy/">正式環境上踩到 StatefulSet 的雷，拿到 P1 的教訓</a>)</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>有關 volume 相關可以參考 <a href="../../kubernetes/kubernetes-volume">Kubernetes 從零開始 - 你的 Volume 到底 Mount 到哪裡去了？ | Shawn Hsu</a></p>
</blockquote>

<h2 id="daemonset">DaemonSet</h2>
<p>daemon 在計算機當中通常指的是背景程式如 <code class="language-plaintext highlighter-rouge">sshd</code><br />
Kubernetes 中，DaemonSet 就是跑在每個節點上的應用程式<br />
注意到，是 <strong><em>每個節點</em></strong></p>

<p>這些應用程式通常是 node-level 的設施，像是節點等級的 logging, monitoring 等等</p>

<p>那為什麼不直接在節點寫啟動 script?<br />
擁有統一的管理機制是比較方便的，相同的設定語言，相同的習慣</p>

<p>至於 Pod 呢？ 由於其短暫生命週期，執行 daemon 類的服務並不是一個好的選擇<br />
這樣說，是不是 <a href="#deployment">Deployment</a> 也能做到？ 是的，但是 Deployment 並不是最佳選擇<br />
我們說 DaemonSet 會部署在 “每一個節點” 上，<a href="#deployment">Deployment</a> 無法輕易做到</p>

<p>縱使 node affinity 以及 node selector 可以做到<br />
但是變成你要針對每一個節點寫 node selector，這樣你要維護的東西會變很多，而且幾乎長一樣<br />
當有一個節點新增進 cluster 的時候，<a href="#deployment">Deployment</a> 需要手動更新 yaml 來部署新的節點<br />
所以才有 DaemonSet 的出現</p>

<h2 id="jobs-and-cronjob">Jobs and CronJob</h2>
<p>針對單次的任務，使用 <code class="language-plaintext highlighter-rouge">Job</code> 會是合理的選擇<br />
為什麼不用 Pod? 答案還是一樣，因為 Pod 的生命週期是短暫的，況且如果遇到那種要重試幾次的任務也不合適</p>

<p>Job 本身可以設定幾個有意思的參數<br />
比如說 <code class="language-plaintext highlighter-rouge">.spec.completions</code> 以及 <code class="language-plaintext highlighter-rouge">.spec.parallelism</code><br />
你需要完成這個任務幾次就是 completions，同時執行幾個就是 parallelism<br />
另外還有 <code class="language-plaintext highlighter-rouge">.spec.suspend</code> 可以停止 Job 的執行</p>

<p>針對那種要平行處理的任務，parallelism 可以很方便的做到<br />
不過，每個 Pod 執行一樣的任務嗎？ 其實有時候你想要的是每個 Pod 執行一小部份的內容<br />
在 Kubernetes 1.21 中引入了 <a href="https://kubernetes.io/blog/2021/04/19/introducing-indexed-jobs/">Indexed Job</a> 的概念</p>

<p>其實概念滿簡單的，就是給每一個 Pod 一個 index，在設計上你就可以根據 index 來分配任務(i.e. <code class="language-plaintext highlighter-rouge">0</code> ~ <code class="language-plaintext highlighter-rouge">N - 1</code>)<br />
有了它，你就不需要額外設置一個 work queue 來分配任務<br />
說是這樣說，等於你在 code 裡面需要自己根據 index 來分配任務，有點麻煩</p>

<p>這部份是透过指定 <code class="language-plaintext highlighter-rouge">.spec.completionMode</code> 來實現的<br />
預設情況下是 <code class="language-plaintext highlighter-rouge">NonIndexed</code> 但你不需要特別寫上去</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">batch/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Job</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">sample-job'</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">completions</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">parallelism</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">completionMode</span><span class="pi">:</span> <span class="s">Indexed</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">command</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s1">'</span><span class="s">bash'</span>
        <span class="pi">-</span> <span class="s1">'</span><span class="s">-c'</span>
        <span class="pi">-</span> <span class="s1">'</span><span class="s">echo</span><span class="nv"> </span><span class="s">"My</span><span class="nv"> </span><span class="s">partition:</span><span class="nv"> </span><span class="s">${JOB_COMPLETION_INDEX}"'</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s1">'</span><span class="s">docker.io/library/bash'</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">sample-load'</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<hr />

<p>至於說重複的任務，Kubernetes 也有 <code class="language-plaintext highlighter-rouge">CronJob</code><br />
寫法與 Job 類似，最大的差別就是要設定排程(i.e. <code class="language-plaintext highlighter-rouge">.spec.schedule</code>)<br />
語法與 crontab 一致</p>

<h2 id="comparison">Comparison</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Workload Resource</th>
      <th style="text-align: right">Goal</th>
      <th style="text-align: right">State</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="#replicaset">ReplicaSet</a></td>
      <td style="text-align: right">提供足夠數量的 Pod，需要客製化策略的時候適用</td>
      <td style="text-align: right">:x:</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#deployment">Deployment</a></td>
      <td style="text-align: right">提供足夠數量的 Pod，底下是 <a href="#replicaset">ReplicaSet</a></td>
      <td style="text-align: right">:x:</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#statefulset">StatefulSet</a></td>
      <td style="text-align: right">給予穩定的 Pod、儲存空間以及網路</td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#daemonset">DaemonSet</a></td>
      <td style="text-align: right">部屬於每個節點上</td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#jobs-and-cronjob">Job/CronJob</a></td>
      <td style="text-align: right">一次或多次重複的任務</td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
  </tbody>
</table>

<h1 id="rolling-update-for-workload-resources">Rolling Update for Workload Resources</h1>
<p>對於高階的 Workload Resources，最重要的是服務不中斷<br />
<a href="#deployment">Deployment</a>, <a href="#statefulset">StatefulSet</a> 以及 <a href="#daemonset">DaemonSet</a> 都支援 Rolling Update</p>

<p>Rolling Update 的意思是，逐步更新你的服務，至少有一個 Pod 是可以服務使用者的<br />
所以看起來就像是沒有中斷過一樣<br />
針對部屬策略，可以參考 <a href="../../kubernetes/kubernetes-scale">Kubernetes 從零開始 - 部署策略 101 | Shawn Hsu</a><br />
這邊專注於 “怎麼做”</p>

<blockquote>
  <p>注意到只有更新 label 或者是 Pod template 才會觸發 Rolling Update<br />
更新 replica 數量並不會觸發 Rolling Update</p>
</blockquote>

<h2 id="rolling-update-example">Rolling Update Example</h2>
<p>先建立一個 Deployment 來測試</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl create deployment <span class="nb">dd</span> <span class="nt">--image</span> nginx:1.16.1 <span class="nt">--replicas</span> 3
</pre></td></tr></tbody></table></code></pre></div></div>

<p>更新 Deployment 所使用的 image 為 <code class="language-plaintext highlighter-rouge">nginx:1.14.2</code><br />
可以 <code class="language-plaintext highlighter-rouge">$ kubectl set</code> 或是 <code class="language-plaintext highlighter-rouge">$ kubectl edit</code> 來更新<br />
如果你同步觀察 Pod 的狀態，應該可以觀察到一上一下的現象</p>

<p>然後你可以透過 <code class="language-plaintext highlighter-rouge">$ kubectl rollout status</code> 來查看 Rolling Update 的狀態<br />
以及 <code class="language-plaintext highlighter-rouge">$ kubectl rollout history</code> 來查看 Rolling Update 的歷史</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl rollout <span class="nb">history </span>deployment <span class="nb">dd 
</span>deployment.apps/dd 
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         &lt;none&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>很顯然，這種 revision 資訊滿簡陋的<br />
指定 revision 可以查看該 revision 的詳細資訊</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl rollout <span class="nb">history </span>deployment <span class="nb">dd</span> <span class="nt">--revision</span> 1
deployment.apps/dd with revision <span class="c">#1</span>
Pod Template:
  Labels:       <span class="nv">app</span><span class="o">=</span><span class="nb">dd
        </span>pod-template-hash<span class="o">=</span>844587458f
  Containers:
   nginx:
    Image:      nginx:1.16.1
    Port:       &lt;none&gt;
    Host Port:  &lt;none&gt;
    Environment:        &lt;none&gt;
    Mounts:     &lt;none&gt;
  Volumes:      &lt;none&gt;
  Node-Selectors:       &lt;none&gt;
  Tolerations:  &lt;none&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre>kubectl rollout <span class="nb">history </span>deployment <span class="nb">dd</span> <span class="nt">--revision</span> 2
deployment.apps/dd with revision <span class="c">#2</span>
Pod Template:
  Labels:       <span class="nv">app</span><span class="o">=</span><span class="nb">dd
        </span>pod-template-hash<span class="o">=</span>6b88c4858d
  Containers:
   nginx:
    Image:      nginx:1.14.2
    Port:       &lt;none&gt;
    Host Port:  &lt;none&gt;
    Environment:        &lt;none&gt;
    Mounts:     &lt;none&gt;
  Volumes:      &lt;none&gt;
  Node-Selectors:       &lt;none&gt;
  Tolerations:  &lt;none&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>另外，在更新的時候其實也可以暫停的</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl rollout pause/resume deployment <span class="nb">dd
</span>deployment.apps/dd paused/resumed
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="revert-the-update">Revert the Update</h2>
<p>你可以透過 <code class="language-plaintext highlighter-rouge">$ kubectl rollout undo</code> 來回退到上一個 revision<br />
或者如果你要跳到特定的 revision，可以加上 <code class="language-plaintext highlighter-rouge">--to-revision</code> 參數</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl rollout undo deployment <span class="nb">dd</span> <span class="nt">--to-revision</span> 1
deployment.apps/dd rolled back
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="scaling-workload-resources">Scaling Workload Resources</h1>
<p>Scaling 就是調整 replica 的數量<br />
在 Kubernetes 中，<a href="#deployment">Deployment</a>, <a href="#statefulset">StatefulSet</a> 以及 <a href="#daemonset">DaemonSet</a> 都支援 Scaling<br />
以 <a href="#deployment">Deployment</a> 為例，可以手動設定 yaml 中的 <code class="language-plaintext highlighter-rouge">replicas</code> 數量</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl scale deployment <span class="nb">dd</span> <span class="nt">--replicas</span> 5
deployment.apps/dd scaled
</pre></td></tr></tbody></table></code></pre></div></div>

<p>抑或者是使用 Autoscaler，注意到是 Horizontal Pod Autoscaler(HPA)<br />
而不是 Vertical Pod Autoscaler(VPA)</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl autoscale deployment <span class="nb">dd</span> <span class="nt">--min</span><span class="o">=</span>1 <span class="nt">--max</span><span class="o">=</span>10 <span class="nt">--cpu-percent</span><span class="o">=</span>50
horizontalpodautoscaler.autoscaling/dd autoscaled
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>可以參考 <a href="../../kubernetes/kubernetes-scale">Kubernetes 從零開始 - 部署策略 101 | Shawn Hsu</a></p>
</blockquote>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/">Workloads</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/">Workload Management</a></li>
  <li><a href="https://stackoverflow.com/questions/69448131/kubernetes-whats-the-difference-between-deployment-and-replica-set">Kubernetes: what’s the difference between Deployment and Replica set?</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployment</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSet</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/">Job</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">CronJob</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="kubernetes" /><category term="deployment" /><category term="statefulset" /><category term="daemonset" /><category term="job" /><category term="cronjob" /><category term="replicaset" /><category term="abstraction" /><category term="workload" /><category term="workload resources" /><category term="resources" /><category term="rolling update" /><category term="indexed job" /><category term="job completion mode" /><category term="headless service" /><summary type="html"><![CDATA[本文將會介紹 Kubernetes 中的高階抽象 Workload Resources，並且介紹他們的特性以及如何使用]]></summary></entry><entry><title type="html">Kubernetes 從零開始 - 你的 Volume 到底 Mount 到哪裡去了？</title><link href="https://ambersuncreates.com/kubernetes/kubernetes-volume/" rel="alternate" type="text/html" title="Kubernetes 從零開始 - 你的 Volume 到底 Mount 到哪裡去了？" /><published>2025-11-13T00:00:00+08:00</published><updated>2025-11-13T01:40:06+08:00</updated><id>https://ambersuncreates.com/kubernetes/kubernetes-volume</id><content type="html" xml:base="https://ambersuncreates.com/kubernetes/kubernetes-volume/"><![CDATA[<h1 id="introduction-to-kubernetes-volume">Introduction to Kubernetes Volume</h1>
<p>從 Docker 的年代開始，掛載 host 的檔案系統不是什麼新鮮事<br />
而 mount 的方式也很直覺，直接指定 host 的檔案路徑，你就能夠在 container 裡面存取相關的資料<br />
到了 Kubernetes，也是有一樣的概念，但是 mount 的方式變得五花八門，相對複雜</p>

<p>本文將會帶你了解那些最常用的 Volume，以及他們的特性</p>

<h2 id="quick-look-to-volume">Quick Look to Volume</h2>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">batch/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Job</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">busybox</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">busybox</span>
        <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">sh'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">-c'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">ls</span><span class="nv"> </span><span class="s">-al</span><span class="nv"> </span><span class="s">/mnt/data;</span><span class="nv"> </span><span class="s">echo</span><span class="nv"> </span><span class="s">"----";</span><span class="nv"> </span><span class="s">ls</span><span class="nv"> </span><span class="s">-al</span><span class="nv"> </span><span class="s">/mnt/cm'</span><span class="pi">]</span>
        <span class="na">volumeMounts</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/mnt/data</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume</span>
            <span class="na">subPath</span><span class="pi">:</span> <span class="s">dataset1</span>
          <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/mnt/cm/fn</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume-cm</span>
            <span class="na">subPath</span><span class="pi">:</span> <span class="s">firstName.txt</span>
      <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume</span>
        <span class="na">emptyDir</span><span class="pi">:</span> <span class="pi">{}</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume-cm</span>
        <span class="na">configMap</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">my-cm</span>
          <span class="na">items</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">firstName</span>
              <span class="na">path</span><span class="pi">:</span> <span class="s">firstName.txt</span>
      <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>為了因應不同的情境，Kubernetes 在設計上是相對彈性的<br />
從上述的 Job spec 你可以看到，你需要定義這個 Pod 需要哪一些 volume(i.e. <code class="language-plaintext highlighter-rouge">.spec.volumes</code>)<br />
然後在裡面詳細的描述你要怎麼掛載進去要掛到哪(i.e. <code class="language-plaintext highlighter-rouge">.spec.containers[*].volumeMounts</code>)</p>

<blockquote>
  <p>Pod 本身可以同時掛載 <strong>一或多個不同的 volume</strong></p>
</blockquote>

<p>當然這種簡單的寫法是屬於 <a href="#ephemeral-volume">Ephemeral Volume</a> 的範疇<br />
如果使用 <a href="#persistent-volume">Persistent Volume</a> 的話，你需要更複雜的定義(i.e. <a href="#how-should-you-use-persistent-volume">Persistent Volume Claim</a>)</p>

<h2 id="how-to-mount">How to Mount?</h2>
<p>但具體來說怎麼掛載，可以說，概念上與 Docker 是一模一樣的<br />
你需要有兩個路徑</p>
<ol>
  <li>Container 內部掛載路徑
    <ul>
      <li>掛載路徑是你自己決定的，比方說 <code class="language-plaintext highlighter-rouge">/mnt/data</code></li>
    </ul>
  </li>
  <li>Node 上的資源路徑
    <ul>
      <li>有一個固定的路徑，規則是 <code class="language-plaintext highlighter-rouge">/var/lib/kubelet/pods/&lt;pod uid&gt;/volumes/&lt;volume type&gt;/&lt;volume name&gt;</code></li>
    </ul>
  </li>
</ol>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-container</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/mnt/data</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume</span>
    <span class="na">emptyDir</span><span class="pi">:</span> <span class="pi">{}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>當容器啟動的時候，container runtime 會根據以上資訊逐一進行綁定<br />
考慮以上 yaml，執行順序會是</p>
<ol>
  <li>在 Node 上建立 <code class="language-plaintext highlighter-rouge">/var/lib/kubelet/pods/1234/volumes/kubernetes.io~empty-dir/my-volume</code></li>
  <li>container runtime 將以下進行綁定
    <ul>
      <li><code class="language-plaintext highlighter-rouge">/var/lib/kubelet/pods/1234/volumes/kubernetes.io~empty-dir/my-volume</code> :arrow_right: <code class="language-plaintext highlighter-rouge">/mnt/data</code></li>
    </ul>
  </li>
  <li>啟動容器</li>
</ol>

<h3 id="precision-control-with-subpath">Precision Control with subPath</h3>
<p>一個常見的問題是，掛載這件事情沒弄好會造成資料遺失的問題<br />
比方說如果你掛載到的地方本來就有資料，把它蓋過去可能東西就壞了<br />
又或者是你只要掛一部分的資料而已，而不是整個 volume</p>

<p>以上的情境催生出了 <code class="language-plaintext highlighter-rouge">subPath</code> 這個概念</p>

<h4 id="mount-path-obscuration">Mount Path Obscuration</h4>
<p>但實際上也不是蓋過去啦，是被遮蔽了<br />
linux 掛載有一個機制是這樣子的，當你掛載的路徑有資料，它會把原本的舊資料隱藏起來，直到你移除掛載<br />
這個概念也同樣適用於 Kubernetes</p>

<p>如果在 linux 上你可以這樣測試<br />
透過將 tmpfs 掛載到測試資料夾上可以很明顯的觀察到 obscuration 的效果</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="rouge-code"><pre><span class="c"># 建立測試資料夾並填入測試資料</span>
<span class="nv">$ </span><span class="nb">mkdir test</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"test"</span> <span class="o">&gt;</span> <span class="nb">test</span>/test.txt
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> <span class="nb">test
</span>total 1
drwxr-xr-x 2 root root 4096 Nov  1 10:00 <span class="nb">.</span>
drwxr-xr-x 4 root root 4096 Nov  1 10:00 ..
<span class="nt">-rw-r--r--</span> 1 root root    4 Nov  1 10:00 test.txt
<span class="nv">$ </span>mountpoint <span class="nb">test
test </span>is a mountpoint
<span class="c"># 掛載 tmpfs 到 test 資料夾</span>
<span class="nv">$ </span><span class="nb">sudo </span>mount <span class="nt">-t</span> tmpfs tmpfs <span class="nb">test</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> <span class="nb">test</span>
<span class="c"># 檔案消失了</span>
<span class="nv">$ </span>mountpoint <span class="nb">test
test </span>is a mountpoint
<span class="c"># 移除掛載</span>
<span class="nv">$ </span><span class="nb">sudo </span>umount <span class="nb">test
test </span>is not a mountpoint
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> <span class="nb">test</span>
<span class="c"># 檔案又出現了</span>
total 1
drwxr-xr-x 2 root root 4096 Nov  1 10:00 <span class="nb">.</span>
drwxr-xr-x 4 root root 4096 Nov  1 10:00 ..
<span class="nt">-rw-r--r--</span> 1 root root    4 Nov  1 10:00 test.txt
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>你也可以建立一個 K8s Job 測試</p>
</blockquote>

<p>系統也不會阻止你掛上去，所以這可能會造成一些問題，比方說你蓋掉了他的啟動 script<br />
像是掛在 <code class="language-plaintext highlighter-rouge">/etc</code> 有可能造成錯誤，<code class="language-plaintext highlighter-rouge">/usr</code> 會是比較好的選擇<br />
你需要足夠細心，確保原本 image 內部的資料不會被覆蓋</p>

<h4 id="how-to-use-subpath">How to use subPath?</h4>
<p><code class="language-plaintext highlighter-rouge">subPath</code> 很好的解決了覆蓋資料以及部份掛載的問題<br />
考慮以下範例</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-container</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/mnt/data</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume</span>
      <span class="na">subPath</span><span class="pi">:</span> <span class="s">dataset1</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-volume</span>
    <span class="na">emptyDir</span><span class="pi">:</span> <span class="pi">{}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>概念上還是一樣的<br />
container volume 一樣會對回去 Node 上的資源路徑</p>

<p>原本是這樣嘛</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">/var/lib/kubelet/pods/1234/volumes/kubernetes.io~empty-dir/my-volume</code></li>
  <li><code class="language-plaintext highlighter-rouge">/mnt/data</code></li>
</ul>

<p>多了 <code class="language-plaintext highlighter-rouge">subPath</code> 就是新增在 Node 上的資源路徑的最後方<br />
所以掛載路徑會變成</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">/var/lib/kubelet/pods/1234/volumes/kubernetes.io~empty-dir/my-volume/dataset1</code></li>
  <li><code class="language-plaintext highlighter-rouge">/mnt/data</code></li>
</ul>

<p>注意到 <code class="language-plaintext highlighter-rouge">subPath</code> 是 <strong><em>相對於 volume root 的 相對路徑</em></strong><br />
你的 volume root 是 <code class="language-plaintext highlighter-rouge">/var/lib/kubelet/pods/1234/volumes/kubernetes.io~empty-dir/my-volume</code><br />
mountPath 永遠指向你想要東西在哪裡可以存取到</p>

<blockquote>
  <p>subPath 是加在要使用的 volume 上面，不是 mountPath</p>
</blockquote>

<p>如果你掛載在 <code class="language-plaintext highlighter-rouge">/mnt/data/inner/myfile</code><br />
上層的資料夾並不會被掛載進去，意思是當你改動 <code class="language-plaintext highlighter-rouge">/mnt/data/inner</code> 的資料，並不會反應回去 Node 上<br />
因為你只掛載了單一檔案到 container 內部</p>

<blockquote>
  <p>mountPath 如果配合 subPath 使用，可以掛載單一檔案<br />
沒有指定 subPath 的時候(i.e. <code class="language-plaintext highlighter-rouge">subPath: ""</code>)，會掛載整個 volume root 到 mountPath</p>
</blockquote>

<h1 id="kubernetes-volume-type">Kubernetes Volume Type</h1>
<p>不同的 <a href="#volume-type">Volume Type</a> 有不同的特性<br />
<a href="#ephemeral-volume">Ephemeral Volume</a> 的生命週期與 Pod 本身的生命週期是綁定的<br />
缺點在於說如果 Pod 被刪除，volume 也會被刪除<br />
針對需要資料持久化的情境，使用 <a href="#persistent-volume">Persistent Volume</a> 會是比較好的選擇</p>

<p>如果你想要把所有的 volume 都掛到同一個地方，那可以參考 <a href="#projected-volume">Projected Volume</a></p>

<h2 id="ephemeral-volume">Ephemeral Volume</h2>
<p>如果這個 volume 是與 Pod 本身的生命週期綁定的，那我們稱這類 volume 為 <a href="#ephemeral-volume">Ephemeral Volume</a></p>

<p>Ephemeral Volume 很適合用於一些暫存的資料，這使得 Pod 可以很輕鬆的被建立以及刪除<br />
而不需要擔心資料持久化的問題</p>

<p>也因為異揮發的特性，在 Pod spec 裡面就可以完整定義 volume 的掛載方式<br />
而不需要仰賴其他的機制</p>

<h3 id="hostpath">hostPath</h3>
<p>如果你要做到跟 Docker volume 一模一樣的功能，Kubernetes 裡面對應到的是 <code class="language-plaintext highlighter-rouge">hostPath</code> 這個 volume<br />
指定 host 的路徑，他就能夠讀取到 host 的檔案<br />
不過，這裡的 host 是指哪裡的 host 呢？<br />
什麼意思，因為 Kubernetes 支援多個節點，所以本質上你的 app 有可能執行在不同的節點上<br />
而 <code class="language-plaintext highlighter-rouge">hostPath</code> 裡面的 host 是指定到 <strong>節點上</strong> 的資源路徑</p>

<p>不過，<code class="language-plaintext highlighter-rouge">hostPath</code> 沒有到很安全，因為你可以直接存取到 host 的檔案<br />
如果操作不當，可能會洩漏 system credential，甚至是能夠讓 container 存取 privileged 的 API<br />
有些使用情境下是可以接受的，比如說你需要讀取系統層級的 log</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hostpath-example-linux</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">example-container</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">registry.k8s.io/test-webserver</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/foo</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">example-volume</span>
      <span class="na">readOnly</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">example-volume</span>
    <span class="na">hostPath</span><span class="pi">:</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">/data/foo</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">Directory</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="emptydir">emptyDir</h3>
<p>如果你只是單純的需要一個暫存的空間，那可以考慮使用 <code class="language-plaintext highlighter-rouge">emptyDir</code><br />
在 Pod 被建立的時候，volume 會被建立，反之被刪除的時候也會跟著一起被刪掉</p>

<p>所有 Pod 裡面的 container 都可以任一讀寫到這個 volume<br />
比方說你可以掛一個 sidecar container 來做 log 的收集與處理<br />
主要的 container 將 log 寫到相同的 volume 裡面</p>

<blockquote>
  <p>有關 sidecar container 可以參考 <a href="../../kubernetes/kubernetes-sidecar">Kubernetes 從零開始 - Sidecar 與 Lifecycle Hook 組合技 | Shawn Hsu</a></p>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">test-pd</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">registry.k8s.io/test-webserver</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">test-container</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/cache</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">cache-volume</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">cache-volume</span>
    <span class="na">emptyDir</span><span class="pi">:</span> <span class="pi">{}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>根據節點的儲存空間，比方說 SSD 還是 HDD，預設就是會走到該媒介上面<br />
你可以使用 <code class="language-plaintext highlighter-rouge">emptyDir.medium</code> 額外指定使用記憶體(但注意到不能說我 SSD HDD 都有所以我想指定其中一個，這是不行的)<br />
以及 <code class="language-plaintext highlighter-rouge">emptyDir.sizeLimit</code> 指定 volume 的大小限制</p>

<blockquote>
  <p>medium 類別</p>
  <ul>
    <li><strong>”“</strong> : 預設，使用節點上的儲存空間(SSD 或是 HDD)</li>
    <li><strong>Memory</strong> : 使用記憶體</li>
  </ul>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">test-pd</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">registry.k8s.io/test-webserver</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">test-container</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/cache</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">cache-volume</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">cache-volume</span>
    <span class="na">emptyDir</span><span class="pi">:</span>
      <span class="na">sizeLimit</span><span class="pi">:</span> <span class="s">500Mi</span>
      <span class="na">medium</span><span class="pi">:</span> <span class="s">Memory</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="configmap-and-secret">configMap and secret</h3>
<p>另一種很好用的方式是直接將外掛的參數以及資料直接掛載進 container 裡面<br />
在未習得這個方法之前，如果有類似的需求我都是傳 environment variable 進去<br />
透過 init container 掛載 <a href="#emptyDir">emptyDir</a> 並寫入檔案然後主 container 掛載相同 <a href="#emptyDir">emptyDir</a> 存取</p>

<p>但很顯然的，這種方式是有問題的<br />
將資料，尤其是密碼之類的透過 env 傳入是很不安全的行為<br />
所以原生支援掛載還是挺方便的</p>

<blockquote>
  <p>需要注意的是，無論是 <code class="language-plaintext highlighter-rouge">configMap</code> 還是 <code class="language-plaintext highlighter-rouge">secret</code>，掛載前他們都必須先被建立<br />
並且以上兩者的掛載都是 <strong>readonly</strong> 的</p>
</blockquote>

<p>具體點來說，掛載進去容器內部的方式是以檔案為主<br />
你可能會想說，<code class="language-plaintext highlighter-rouge">secret</code> 也以檔案的方式掛載進去？ 不會有安全隱患嗎？<br />
所以其實針對 <code class="language-plaintext highlighter-rouge">secret</code> 的部份，其實是使用 <a href="https://docs.kernel.org/filesystems/tmpfs.html">tmpfs</a><br />
而其本身是將資料都放在 “易揮發” 的儲存空間中，確保不會有任何機會可以寫入永久儲存</p>

<blockquote>
  <p>資料放在記憶體就一定安全嗎？ 並不是<br />
只是這樣子的手段可以一定程度上降低風險</p>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">configmap-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">test</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">busybox:1.28</span>
    <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">sh'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">-c'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">echo</span><span class="nv"> </span><span class="s">"The</span><span class="nv"> </span><span class="s">app</span><span class="nv"> </span><span class="s">is</span><span class="nv"> </span><span class="s">running!"</span><span class="nv"> </span><span class="s">&amp;&amp;</span><span class="nv"> </span><span class="s">tail</span><span class="nv"> </span><span class="s">-f</span><span class="nv"> </span><span class="s">/dev/null'</span><span class="pi">]</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-vol</span>
        <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/etc/config</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-vol</span>
    <span class="na">configMap</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">log-config</span>
      <span class="na">items</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">log_level</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">log_level.conf</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>以上的例子是只有將一部分的 configMap 掛載進入容器內部<br />
<code class="language-plaintext highlighter-rouge">config-vol</code> 是一個 volume 的名稱，目標是 <code class="language-plaintext highlighter-rouge">log-config</code> 這個 configMap 的 <code class="language-plaintext highlighter-rouge">log_level</code> 這個 key<br />
將這份資料掛載到 <code class="language-plaintext highlighter-rouge">log_level.conf</code> 這個檔案裡面</p>

<p>那這個檔案在哪裡呢？<br />
<code class="language-plaintext highlighter-rouge">volumeMounts</code> 裡面的 <code class="language-plaintext highlighter-rouge">mountPath</code> 就是檔案掛載的路徑<br />
所以檔案完整路徑會是 <code class="language-plaintext highlighter-rouge">/etc/config/log_level.conf</code></p>

<p>你也可以使用 <a href="#precision-control-with-subpath">subPath</a> 的方式掛載資料，需要注意的是<br />
Pod 並不會自動拉取新的資料，等於說你需要手動重啟 Pod 才能看到新的資料</p>

<h2 id="projected-volume">Projected Volume</h2>
<p>Projected Volume 並不是介於 <a href="#ephemeral-volume">Ephemeral Volume</a> 與 <a href="#persistent-volume">Persistent Volume</a> 之間的東西<br />
而是一種特殊型態的 volume，將不同類型的 volume 掛載到相同資料夾下並統一管理<br />
目前來說僅有少數 volume 支持這種特性，其中最著名的是 <code class="language-plaintext highlighter-rouge">configMap</code> 以及 <code class="language-plaintext highlighter-rouge">secret</code></p>

<blockquote>
  <p>要想掛載到同一個資料夾底下，這些 volume 必須處於同一個 namespace 下</p>
</blockquote>

<p>掛載到相同資料夾底下有什麼好處？<br />
有些 use case 是你的 deployment 需要設定檔，也同時需要 API key 這種東西<br />
如果分開掛載，是不是就分隔兩地了？ 所以開發者們希望有一個統一管理的地方，至少他們是這樣覺得的(可參考 <a href="https://github.com/kubernetes/design-proposals-archive/blob/main/node/all-in-one-volume.md">all-in-one volume</a> design)</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">batch/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Job</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">volume-test</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">container-test</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">busybox</span>
        <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span>
          <span class="s2">"</span><span class="s">sh"</span><span class="pi">,</span> 
          <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span> 
          <span class="s2">"</span><span class="s">echo</span><span class="nv"> </span><span class="s">/projected-volume/my-group/my-username;</span> 
          <span class="s">echo</span><span class="nv"> </span><span class="s">/projected-volume/my-group/my-config"</span>
        <span class="pi">]</span>
        <span class="na">volumeMounts</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">all-in-one</span>
          <span class="na">mountPath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/projected-volume"</span>
          <span class="na">readOnly</span><span class="pi">:</span> <span class="no">true</span>
      <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">all-in-one</span>
        <span class="na">projected</span><span class="pi">:</span>
          <span class="na">sources</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">secret</span><span class="pi">:</span>
              <span class="na">name</span><span class="pi">:</span> <span class="s">mysecret</span>
              <span class="na">items</span><span class="pi">:</span>
                <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">username</span>
                  <span class="na">path</span><span class="pi">:</span> <span class="s">my-group/my-username</span>
          <span class="pi">-</span> <span class="na">configMap</span><span class="pi">:</span>
              <span class="na">name</span><span class="pi">:</span> <span class="s">myconfigmap</span>
              <span class="na">items</span><span class="pi">:</span>
                <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">config</span>
                  <span class="na">path</span><span class="pi">:</span> <span class="s">my-group/my-config</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>如果你的 volume 都掛載到同一個檔案是會錯誤的<br />
比如說都是 <code class="language-plaintext highlighter-rouge">mygroup/my-data</code> 就會出錯</p>

<h2 id="persistent-volume">Persistent Volume</h2>
<p>如果這個 volume 是與 Pod 本身的生命週期相互獨立的，那我們稱這類 volume 為 <a href="#persistent-volume">Persistent Volume</a></p>

<h3 id="local">local</h3>
<p>local 是指定到 node 上的 <strong>掛載資源路徑</strong>(如 外接硬碟)<br />
它最終還是依賴於節點本身，你需要依靠節點去存取這些資源</p>

<blockquote>
  <p>local volume 不支援動態配置</p>
</blockquote>

<p>舉例來說，<a href="https://github.com/libfuse/sshfs">libfuse/sshfs</a> 可以透過 SSH 將遠端的檔案系統掛載到本機上<br />
一樣的概念，檔案系統不在本機上，但你可以 mount 到本機，使得操作起來跟本機的檔案系統一樣</p>

<p>話雖如此，如果你的節點掛了，那你就無法存取到這個 volume 了<br />
volume 還是好的，是因為 node 掛掉<br />
因此，local volume 會在一定程度上受到節點可用性的影響</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolume</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">example-pv</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">capacity</span><span class="pi">:</span>
    <span class="na">storage</span><span class="pi">:</span> <span class="s">100Gi</span>
  <span class="na">volumeMode</span><span class="pi">:</span> <span class="s">Filesystem</span>
  <span class="na">accessModes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">persistentVolumeReclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">local-storage</span>
  <span class="na">local</span><span class="pi">:</span>
    <span class="na">path</span><span class="pi">:</span> <span class="s">/mnt/disks/ssd1</span>
  <span class="na">nodeAffinity</span><span class="pi">:</span>
    <span class="na">required</span><span class="pi">:</span>
      <span class="na">nodeSelectorTerms</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">matchExpressions</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">kubernetes.io/hostname</span>
          <span class="na">operator</span><span class="pi">:</span> <span class="s">In</span>
          <span class="na">values</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">example-node</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="how-should-you-use-persistent-volume">How should you Use Persistent Volume?</h1>
<p>相比於 <a href="#ephemeral-volume">Ephemeral Volume</a>，Persistent Volume 的使用是比較複雜的<br />
有了 <a href="#persistent-volume">Persistent Volume</a> 其實是不夠的，因為他的生命週期與 Pod 本身獨立<br />
如果 <a href="#persistent-volume">PV</a> 允許直接掛上去，那等於綁定其 lifecycle，而這不是我們所想要的</p>

<p><a href="#persistent-volume-claim">Persistent Volume Claim</a> 就是用來解決這個問題的<br />
這個 Resource 表示的是 <strong>a request for storage by a user</strong><br />
等於說是個令牌的概念，這個 Claim 裡面包含了許多資訊，比方說你要的這個空間要多大、權限是什麼等等的<br />
因為 <a href="#persistent-volume">Persistent Volume</a> 包含了滿多底層的資訊<br />
講好聽點是細節豐富，但實際上就是複雜，使用者不需要知道這麼多東西，因此多個一個 <strong>Claim</strong> 的概念簡化</p>

<p>如果你要不到想要的資源，可能是目前可用的 <a href="#persistent-volume">PV</a> 他們的空間不夠，或者是權限沒辦法滿足你的需求<br />
其實這些需求可以被寫成所謂的 <a href="#storage-classes">StorageClass</a>，算是一個分組的概念<br />
每個 <a href="#persistent-volume">PV</a> 基本上可以被歸類到某個 StorageClass 底下(但有些不能)<br />
歸類有啥用呢？ 因為某些 <a href="#persistent-volume">PV</a> 是可以根據 StorageClass 動態建立的</p>

<blockquote>
  <p>需要動態建立的 StorageClass 必須要啟用 <code class="language-plaintext highlighter-rouge">DefaultStorageClass</code> Admission Controller</p>
</blockquote>

<p>如果真的遇到只能靜態建立的 StorageClass，那就只能等了</p>

<h2 id="persistent-volume-claim">Persistent Volume Claim</h2>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">myclaim</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">volumeMode</span><span class="pi">:</span> <span class="s">Filesystem</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">8Gi</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">slow</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">release</span><span class="pi">:</span> <span class="s2">"</span><span class="s">stable"</span>
    <span class="na">matchExpressions</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="pi">{</span><span class="nv">key</span><span class="pi">:</span> <span class="nv">environment</span><span class="pi">,</span> <span class="nv">operator</span><span class="pi">:</span> <span class="nv">In</span><span class="pi">,</span> <span class="nv">values</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">dev</span><span class="pi">]}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>PVC 表示的是你希望拿到什麼樣子的 <a href="#persistent-volume">PV</a><br />
包含他的 Access Modes, Storage Class, 以及大小等等的</p>

<p>如果 PVC 中有指定 StorageClass，則 Control Plane 除了基本大小的確認，也會保證 StorageClass 是相同的<br />
設定成 <code class="language-plaintext highlighter-rouge">""</code> 呢？ 你也只能挑選 StorageClass 為 <code class="language-plaintext highlighter-rouge">""</code> 的 <a href="#persistent-volume">PV</a> 中選擇</p>

<blockquote>
  <p>請注意到，<code class="language-plaintext highlighter-rouge">storageClassName: ""</code> 與沒有設定 storageClassName 是不同的</p>
</blockquote>

<p>當你想要改變預設的 default StorageClass 的時候，需要特別注意的是<br />
如果在這中間有任何 PVC 被建立，他們的 StorageClass 不會有預設值的(<code class="language-plaintext highlighter-rouge">""</code> 並不是預設值)<br />
所以針對那些沒有 StorageClass 的 PVC，我會自己幫你填入 <code class="language-plaintext highlighter-rouge">Default StorageClass</code></p>

<p>什麼意思？<br />
當新的 Default StorageClass 被指定，所有缺少 StorageClass 的 PVC 都會被自動填入 Default StorageClass<br />
包含像是</p>
<ol>
  <li>空值</li>
  <li><code class="language-plaintext highlighter-rouge">storageClassName</code> 這個 key 不存在</li>
</ol>

<p>的時候，會被填入當前 Default StorageClass<br />
這個行為被稱作 <code class="language-plaintext highlighter-rouge">Retroactive default storageClass assignment</code></p>

<hr />

<p>那 PVC 要如何被使用，就跟 <a href="#ephemeral-volume">Ephemeral Volume</a> 一樣，透過 <code class="language-plaintext highlighter-rouge">volumeMounts</code> 來掛載</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">mypod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">myfrontend</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
      <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/var/www/html"</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">mypd</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">mypd</span>
      <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
        <span class="na">claimName</span><span class="pi">:</span> <span class="s">myclaim</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="storage-classes">Storage Classes</h2>
<p>不同的儲存空間擁有不同的特性，例如說不同的 backup 策略、不同的等級或者是不同的 SLA<br />
cluster administrator 透過定義一或多個 <code class="language-plaintext highlighter-rouge">StorageClass</code> 來表示說本 cluster 提供哪些類型的儲存空間</p>

<p>有些 StorageClass 只能透過靜態的方式建立，比如說 <a href="#local">local</a></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl get storageclasses.storage.k8s.io local-path <span class="nt">-o</span> yaml 
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">defaultVolumeType</span><span class="pi">:</span> <span class="s">local</span>
    <span class="na">objectset.rio.cattle.io/applied</span><span class="pi">:</span> <span class="s">H4sIAAAAAAAA/4</span>
    <span class="na">objectset.rio.cattle.io/id</span><span class="pi">:</span> <span class="s2">"</span><span class="s">"</span>
    <span class="na">objectset.rio.cattle.io/owner-gvk</span><span class="pi">:</span> <span class="s">k3s.cattle.io/v1, Kind=Addon</span>
    <span class="na">objectset.rio.cattle.io/owner-name</span><span class="pi">:</span> <span class="s">local-storage</span>
    <span class="na">objectset.rio.cattle.io/owner-namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
    <span class="na">storageclass.kubernetes.io/is-default-class</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-10-31T15:16:17Z"</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">objectset.rio.cattle.io/hash</span><span class="pi">:</span> <span class="s">183f35c65ffbc3064603f43f1580d8c68a2dabd4</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path</span>
  <span class="na">resourceVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">282"</span>
  <span class="na">uid</span><span class="pi">:</span> <span class="s">55db47f6-e45f-4308-b085-cf68e8c9b159</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">rancher.io/local-path</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">WaitForFirstConsumer</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>一般來說，<code class="language-plaintext highlighter-rouge">StorageClass</code> 會有這些 properties</p>
<ol>
  <li><strong>provisioner</strong></li>
  <li><strong>parameters</strong></li>
  <li><strong>reclaim policy</strong></li>
</ol>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">storageclass.kubernetes.io/is-default-class</code> 是用來標示說這個 StorageClass 是預設的</p>
</blockquote>

<blockquote>
  <p>有些 Volume 是允許你擴展大小的，注意到只能增加不能減少(i.e. <code class="language-plaintext highlighter-rouge">allowVolumeExpansion: true</code>)</p>
</blockquote>

<h2 id="put-it-all-together">Put it All Together</h2>
<p>在 Pod 層面，你透過 <a href="#persistent-volume-claim">Persistent Volume Claim</a> 來申請一個 volume<br />
Control Plane 會根據你的需求，幫你找到適合的 <a href="#persistent-volume">Persistent Volume</a><br />
你能拿到的 <a href="#persistent-volume">PV</a> 一定是符合你的要求，某些時候甚至會是超出你的需求<br />
注意到，<a href="#persistent-volume">PV</a> 與 <a href="#persistent-volume-claim">PVC</a> 之間是 1:1 的關係，一個 <a href="#persistent-volume-claim">PVC</a> 只能對應到一個 <a href="#persistent-volume">PV</a><br />
比方說 50GB 的 <a href="#persistent-volume">PV</a> 是不可能被申請 100GB 的 <a href="#persistent-volume-claim">PVC</a> 所使用的</p>

<p>綁定(i.e. <code class="language-plaintext highlighter-rouge">Binding</code>)過後的 <a href="#persistent-volume">PV</a> 可以使用多久呢？<br />
你想要用多久就可以用多久的那種程度</p>

<p>在使用的過程中，任何的刪除都會造成嚴重的傷害<br />
所以基本的保護需要做到(i.e. <code class="language-plaintext highlighter-rouge">Use Protection</code>)，比如說</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">PVC</code> 只有在 “沒有任何 Pod” 使用的情況下才會真正被刪除</li>
  <li><code class="language-plaintext highlighter-rouge">PV</code> 只有在 “沒有任何 PVC” 使用的情況下才會真正被刪除</li>
</ul>

<p>即使正在使用中，你強行刪除也會被阻擋(c.f. <strong>Finalizers</strong>)</p>

<p>當你使用完畢，<a href="#persistent-volume">PV</a> 可以被其他人重複利用，不過複用之前可能要稍微處理一下<br />
他有以下幾種選擇(i.e. <code class="language-plaintext highlighter-rouge">Reclaim Policy</code>)</p>
<ol>
  <li>Retain 保留，將資料保留在磁碟上，由 admin 決定如何處置</li>
  <li>Delete 刪除，將資料刪除，磁碟空間釋出</li>
  <li>Recycle 回收，本質上就是將資料刪除然後重新使用，這個選項已經被棄用，建議使用 <code class="language-plaintext highlighter-rouge">Dynamic Provisioning</code></li>
</ol>

<p>不過 1:1 的關係，會不會造成使用上的困擾，比方說我只是想讀取資料而已沒有要寫<br />
有沒有一種辦法允許多個 Pod 使用同一個 <a href="#persistent-volume">PV</a>？<br />
可以透過 Access Modes 來實現</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ReadWriteOnce</code>: 單一節點，可讀寫</li>
  <li><code class="language-plaintext highlighter-rouge">ReadOnlyMany</code>: 多節點，可讀</li>
  <li><code class="language-plaintext highlighter-rouge">ReadWriteMany</code>: 多節點，可讀寫</li>
  <li><code class="language-plaintext highlighter-rouge">ReadWriteOncePod</code>: 單一節點內的單一 Pod，可讀寫</li>
</ul>

<p><a href="#persistent-volume">PV</a> 與 <a href="#persistent-volume-claim">PVC</a> 是一對一<br />
可沒說 Pod 跟 <a href="#persistent-volume-claim">PVC</a> 是一對一<br />
事實上，透過以上不同的存取模式，同一個 <a href="#persistent-volume-claim">PVC</a> 可以被多個 Pod 使用</p>

<h1 id="difference-between-hostpath-and-local">Difference Between <a href="#hostPath">hostPath</a> and <a href="#local">local</a></h1>
<p>同樣都是存取節點上的資料，區分 <a href="#hostPath">hostPath</a> 與 <a href="#local">local</a> 是有意義的<br />
不單單只是因為掛載的方式差異，更多的是 scheduler 對於兩者有著不同的處理方式</p>

<blockquote>
  <p>我當然可以用 <a href="#hostpath">hostPath</a> 指到一個掛載上去的硬碟<br />
這不會錯，是可以正常運行的</p>
</blockquote>

<p>我們知道，Pod 最終會被 scheduler 排程到某一個節點上運行<br />
並且 Pod 會因為各種原因被重新排程，跑到不同的節點上執行<br />
<a href="#hostpath">hostPath</a> 在不同的節點上，代表著不同的實體儲存空間</p>

<p>比方說</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Node A</code>: <code class="language-plaintext highlighter-rouge">/var/log/auth.log</code></li>
  <li><code class="language-plaintext highlighter-rouge">Node B</code>: <code class="language-plaintext highlighter-rouge">/var/log/auth.log</code></li>
</ul>

<p>即使 hostPath 的路徑相同，它也是在不同的節點上，資料當然是不一樣的<br />
而且 scheduler 並不知曉這件事情<br />
所以這是為什麼 <a href="#hostpath">hostPath</a> 被設計成是 <code class="language-plaintext highlighter-rouge">Ephemeral Volume</code></p>

<p>相反的，<a href="#local">local</a> 雖然也是依賴於節點，但是它會透過 <strong>node affinity</strong> 來標示<br />
啥意思？ 外接硬碟理論上同一時間只能被掛載到唯一的節點上，你需要標示說這個 volume 是在哪一個節點上的<br />
如果需要 <a href="#local">local</a> 的 Pod 則會被排程到相同的節點上(就是依靠 node affinity 來實現)</p>

<blockquote>
  <p>為什麼要同一個節點？ 設計 persistent volume 不就是為了抽象化嗎？<br />
是這樣沒錯，但是它不像 object storage 從哪裡都拿的到對吧</p>
</blockquote>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Persistent Volumes</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/storage/projected-volumes/">Projected Volumes</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/">Ephemeral Volumes</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/storage/volumes/">Volumes</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath">Using subPath</a></li>
  <li><a href="https://stackoverflow.com/questions/65399714/what-is-the-difference-between-subpath-and-mountpath-in-kubernetes">What is the difference between subPath and mountPath in Kubernetes</a></li>
  <li><a href="https://kubernetes.io/blog/2018/04/04/fixing-subpath-volume-vulnerability/#kubernetes-background">Fixing the Subpath Volume Vulnerability in Kubernetes</a></li>
  <li><a href="https://docs.docker.com/engine/storage/volumes/#mounting-a-volume-over-existing-data">Mounting a volume over existing data</a></li>
  <li><a href="https://draven.co/kubernetes-volume/">详解 Kubernetes Volume 的实现原理</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/">Storage Classes</a></li>
  <li><a href="https://stackoverflow.com/questions/67345577/can-we-connect-multiple-pods-to-the-same-pvc">Can we connect multiple pods to the same PVC?</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="kubernetes" /><category term="volume" /><category term="container" /><category term="mount" /><category term="hostpath" /><category term="local" /><category term="persistent volume claim" /><category term="storage class" /><category term="projected volume" /><category term="ephemeral volume" /><category term="persistent volume" /><category term="subpath" /><category term="finalizers" /><category term="reclaim policy" /><category term="access modes" /><category term="binding" /><category term="use protection" /><category term="dynamic provisioning" /><category term="default storage class" /><category term="retroactive default storage class assignment" /><category term="pv" /><category term="pvc" /><category term="readwriteonce" /><category term="readonlymany" /><category term="readwritemany" /><category term="readwriteoncepod" /><summary type="html"><![CDATA[Kubernetes Volume 相比 Docker 的掛載方式更為複雜，本文會帶你了解那些最常用的 Volume 以及他們的特性]]></summary></entry><entry><title type="html">Kubernetes 從零開始 - 在分散式的世界實現 Zero Downtime 路由管理</title><link href="https://ambersuncreates.com/kubernetes/kubernetes-traffic/" rel="alternate" type="text/html" title="Kubernetes 從零開始 - 在分散式的世界實現 Zero Downtime 路由管理" /><published>2025-10-16T00:00:00+08:00</published><updated>2025-10-16T13:54:52+08:00</updated><id>https://ambersuncreates.com/kubernetes/kubernetes-traffic</id><content type="html" xml:base="https://ambersuncreates.com/kubernetes/kubernetes-traffic/"><![CDATA[<h1 id="proxy">Proxy</h1>
<p>Proxy 是一個中間人，負責處理 client 與 server 之間的溝通請求<br />
相比於 client 直接與 server 溝通，Proxy 的優勢在於可以進行流量控制、負載平衡、安全性控制等<br />
他可以分為兩類 <a href="#forward-proxy">Forward Proxy</a> 以及 <a href="#reverse-proxy">Reverse Proxy</a></p>

<blockquote>
  <p>Proxy(network level) 是負責全部的流量，而 middleware(application level) 只有負責該次 request/response</p>
</blockquote>

<h2 id="forward-proxy">Forward Proxy</h2>
<p><img src="https://www.jyt0532.com/public/forward-proxy.png" alt="Forward Proxy" width="500" /></p>

<blockquote>
  <p>ref: <a href="https://www.jyt0532.com/2019/11/18/proxy-reverse-proxy/">系統設計 - 正向代理跟反向代理</a></p>
</blockquote>

<p>正向代理是負責處理從 “client” 發出去的流量(換言之就是處理 Outgoing 的流量)<br />
如果遇到說你不希望 server 可以知道 client 的資訊，就可以使用正向代理<br />
所有的 client 都會先經過 forward proxy 再轉發到 server<br />
常見的策略是 forward proxy 會將 client 的 ip 轉換成自己的 ip，藉此隱藏 client 的資訊</p>

<h2 id="reverse-proxy">Reverse Proxy</h2>
<p><img src="https://www.jyt0532.com/public/reverse-proxy.png" alt="Reverse Proxy" width="500" /></p>

<blockquote>
  <p>ref: <a href="https://www.jyt0532.com/2019/11/18/proxy-reverse-proxy/">系統設計 - 正向代理跟反向代理</a></p>
</blockquote>

<p>反向代理則是負責處理進到 “server” 的流量(換言之就是處理 Incoming 的流量)<br />
所有的 request 都會先經過 reverse proxy 再轉發到後端<br />
這樣的好處是可以隱藏後端 server 資訊，以及進行負載平衡(可參考 <a href="#load-balancing">Load Balancing</a>)<br />
你可以決定要將 request 導向哪一個 server</p>

<blockquote>
  <p>使用 Nginx 實現 reverse proxy，如果你需要保留原始 request 資訊<br />
可以利用 <a href="https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_set_header">proxy_set_header</a> 幫你加 <code class="language-plaintext highlighter-rouge">Host</code> 以及 <code class="language-plaintext highlighter-rouge">Connection</code></p>
</blockquote>

<h1 id="load-balancing">Load Balancing</h1>
<p><img src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20201030211002/Load-Balancer-System-Design.png" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://www.geeksforgeeks.org/load-balancing-approach-in-distributed-system/">Load Balancing Approach in Distributed System</a></p>
</blockquote>

<p>負載平衡是一種常見的增加伺服器吞吐能力的手段<br />
他的假設是你的應用程式部屬在 <strong>多台機器</strong> 上<br />
你不會希望只有其中一台伺服器很忙而已</p>

<p>因此負載平衡會將大量的 request 盡量均勻的分佈在所有 worker(機器) 上面<br />
當新的機器加入的時候(scaling)，它也能夠分攤現有的工作量，使得吞吐量得以提昇</p>

<h2 id="load-balancing-methods">Load Balancing Methods</h2>
<p>基本上負載平衡的算法分為靜態以及動態兩種</p>
<ul>
  <li>靜態：根據伺服器的負載能力來分配工作量，例如 <a href="#round-robin">Round Robin</a>, <a href="#weighted-round-robin">Weighted Round Robin</a>, <a href="#dns-round-robin">DNS Round Robin</a></li>
  <li>動態：根據動態的資訊來分配工作量，例如 <a href="#least-connection">Least Connection</a>，<a href="#sticky-session">Sticky Session</a></li>
</ul>

<blockquote>
  <p>為什麼 <a href="#weighted-round-robin">Weighted Round Robin</a> 是靜態的？<br />
因為你沒辦法動態調整 CPU Memory 這些資源分配，並且 load balancer 本身也沒有辦法知道伺服器的負載能力</p>
</blockquote>

<h3 id="round-robin">Round Robin</h3>
<p>Round Robin 的算法就是，每個人都有一小段時間服務<br />
在作業系統是排程算法之一，在負載平衡的世界也有類似的身影<br />
因為你的伺服器可能有很多個，套用 Round Robin 的概念就會是<br />
Server A 先服務，下一個給 Server B，再來給 Server C，以此類推</p>

<h4 id="weighted-round-robin">Weighted Round Robin</h4>
<p><a href="#round-robin">Round Robin</a> 的缺點是，他沒辦法根據不同伺服器的負載能力來分配工作量<br />
比方說 Server A 擁有更好的 CPU 更多的 RAM, 理論上他要負責更多的 request<br />
所以 Weighted Round Robin 就是為了解決這個問題而誕生的</p>

<p>他可以給不同的伺服器一個權重，權重高的就會被分配到更多的 request</p>

<h4 id="dns-round-robin">DNS Round Robin</h4>
<p>一個 domain name 可以指定多個 ip address<br />
當 client 請求該 domain name 的時候，DNS 會回應一連串的 ip address<br />
client 會隨機選擇一個 ip address 進行連線</p>

<p>所以透過這種方式就可以達到基本的負載平衡(DNS Round Robin)<br />
那你也可以加 <a href="#weighted-round-robin">Weighted Round Robin</a> 的概念進去</p>

<blockquote>
  <p>有關 DNS Round Robin<br />
可參考 <a href="../../network/network-basics">重新認識網路 - 從基礎開始 | Shawn Hsu</a></p>
</blockquote>

<h3 id="least-connection">Least Connection</h3>
<p>Load balancer 會根據每一台伺服器當前的連線數量判定說要不要將 request 轉發過去<br />
對比 <a href="#weighted-round-robin">Weighted Round Robin</a> 來說，他可以動態的調整伺服器的負載能力<br />
不會只依靠單一的權重來決定，而是會根據伺服器當前的連線數量來決定</p>

<h3 id="sticky-session">Sticky Session</h3>
<p>執行 load balancing 如果碰到 session 這種東西可能會有一點麻煩<br />
假設你的 session 是儲存在 server 本身的，那問題可大了</p>

<p>多台的機器做 load balancing 意味著你下一次 request 到後端，可能是不一樣的 server 在服務<br />
此時，server B 並沒有你在 server A 上面註冊的 session<br />
因此你可能會遇到一些存取的問題</p>

<p>這個時候你會希望，client A 永遠是由 server A 服務，並不會由其他伺服器接手<br />
所以 sticky session 的用意就是這個</p>

<p>同時 Nginx 也在 Plus 的服務中提供相關服務，可參考以下文件 <a href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#enabling-session-persistence">Enabling Session Persistence</a></p>

<p>雖然現在實務上，因為 HTTP 本身 stateless 的特性<br />
搭配 token 驗證身份的方式，使得 sticky session 較少見</p>

<h1 id="routing-in-kubernetes">Routing in Kubernetes</h1>
<h2 id="kubernetes-service-discovery">Kubernetes Service Discovery</h2>
<p>針對 cluster 內部的 Pods，你可以透過定義 <code class="language-plaintext highlighter-rouge">Service</code> 來讓外部進行存取<br />
那 <code class="language-plaintext highlighter-rouge">Service</code> 是如何知道有哪些 Pods 的呢？</p>

<p>在 <code class="language-plaintext highlighter-rouge">Service</code> 建立之初，<strong>control plane</strong>(i.e. <a href="https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/endpointslice/reconciler.go#L107">EndpointSlice Controller</a>) 會在有 selector 的情況下自動幫你建立 <a href="https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/">EndpointSlice</a> 這個 Resource<br />
因為 Pod 本身還是有自己的 ip address，為了能夠讓 Service 能夠轉接到 Pod 上面<br />
這些資訊是被儲存在 <code class="language-plaintext highlighter-rouge">EndpointSlice</code> 裡面(其他的資訊例如說，conditions, hostname, nodename 以及 zone)</p>

<blockquote>
  <p>EndpointSlice 的前身是 Endpoints</p>
</blockquote>

<p>Pod 是 ephemeral 的，所以即使你有紀錄 Pod 的 ip address<br />
他也可能被移除以及重新加入，然後紀錄就會失效<br />
<a href="https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/endpointslice/reconciler.go#L107">EndpointSlice Controller</a> 會負責監控這些資源的變化，當相關的 Resource 有更動，controller 就會重新調整 <code class="language-plaintext highlighter-rouge">EndpointSlice</code> 的資訊<br />
使得這個紀錄永遠都會是 up-to-date 的</p>

<blockquote>
  <p>有關 controller 可以參考 <a href="../../kubernetes/kubernetes-controller-concept">Kubernetes 從零開始 - Informer 架構以及 Controller Pattern | Shawn Hsu</a></p>
</blockquote>

<p>這個紀錄必須讓其他的節點也知道，<code class="language-plaintext highlighter-rouge">kube-proxy</code> 依賴於 <code class="language-plaintext highlighter-rouge">EndpointSlice</code> 進行內部路由<br />
每個節點必須積極的同步這些資料，為了確保傳遞的過程是輕量的<br />
所以新增會優於更新，因為新增一個全新的 <code class="language-plaintext highlighter-rouge">EndpointSlice</code> 比更新多筆 <code class="language-plaintext highlighter-rouge">EndpointSlice</code> 來得更輕量<br />
<code class="language-plaintext highlighter-rouge">EndpointSlice</code> 本身只會存有 100 筆資訊(可以調整)，如果超過，則會切割成多個 <code class="language-plaintext highlighter-rouge">EndpointSlice</code></p>

<hr />

<p>在執行路由的時候，如果你想要維持低延遲的特性，一個方法是 server 就在你家旁邊<br />
這樣就不會有跨區域的網路延遲<br />
在 Kubernetes 中，你可以在 <code class="language-plaintext highlighter-rouge">Service</code> 裡面設定 annotation <code class="language-plaintext highlighter-rouge">service.kubernetes.io/topology-mode: Auto</code> 來達成<br />
<a href="https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/endpointslice/reconciler.go#L107">EndpointSlice Controller</a> 會負責在 record 旁邊附加 “hint” 來表示這個 Pod 的拓樸資訊<br />
然後 <code class="language-plaintext highlighter-rouge">kube-proxy</code> 會根據這些 hint 來決定要如何路由(i.e. <code class="language-plaintext highlighter-rouge">TAR, Topology Aware Routing</code>)</p>

<p>當然也不是說設定 annotation 就有用，比方說如果 node 沒有 <code class="language-plaintext highlighter-rouge">topology.kubernetes.io/zone</code> 的 label，那麼 <code class="language-plaintext highlighter-rouge">TAR</code> 就無法使用<br />
限制其實還滿多的，可以參考 <a href="https://kubernetes.io/docs/concepts/services-networking/topology-aware-routing/#safeguards">Safeguards</a> 以及 <a href="https://kubernetes.io/docs/concepts/services-networking/topology-aware-routing/#constraints">Constraints</a></p>

<h2 id="terminology-ingress-vs-egress">Terminology Ingress vs. Egress</h2>
<p>通常在講 network traffic 的時候，早些年 inbound/outbound 的說法比較常見<br />
現在我們會使用 ingress/egress 來表示</p>

<p>根據 <a href="https://www.reddit.com/r/networking/comments/umh5k1/when_and_why_did_inoutbound_become_ingressegress/">When (and why?) did in-/outbound become ingress/egress?</a> 上的討論來看<br />
bound 類的說法比較像是這是終點的意思，而 gress 類比較是 “經過” 的意思</p>

<p>所以</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ingress</code> = 流入的流量</li>
  <li><code class="language-plaintext highlighter-rouge">egress</code> = 流出的流量</li>
</ul>

<blockquote>
  <p>流入哪？ 流出哪裡呢？<br />
端看你怎麼界定那個邊界<br />
邊界也可以是路由器、一台虛擬機或一個集群</p>
</blockquote>

<blockquote>
  <p>不要將 Ingress 與 Kubernetes Ingress Resource 混為一談<br />
Kubernetes Ingress Resource 是一個 Kubernetes Resource<br />
用於定義不同的路由規則以轉發 HTTP/HTTPS 的流量<br />
但 Ingress 這個單詞的意思已經演變成一種更為廣泛的概念，所以我們會以這個為準</p>
</blockquote>

<h2 id="from-service-to-ingress-controller">From Service to Ingress Controller</h2>
<p><code class="language-plaintext highlighter-rouge">Service</code> 能做到的有限，比方說他沒辦法客製化路由規則<br />
比方說我想要 <code class="language-plaintext highlighter-rouge">/api</code> 到 <em>Service A</em>，然後 <code class="language-plaintext highlighter-rouge">/admin</code> 到 <em>Service B</em><br />
基本上你需要額外的工具輔助達到類似的效果</p>

<p>Kubernetes 沒有內建這種工具，取而代之的是所謂 <strong>Ingress Controller</strong><br />
流入集群內部的流量統一會先經過 Ingress Controller 進行處理(所以他是一個 <a href="#reverse-proxy">Reverse Proxy</a> 的概念)<br />
你可以自由選擇不同 vendor 的 solution, 比如說 <a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 或者 <a href="#traefik-ingress-controller">Traefik Ingress Controller</a><br />
基本上都支援基礎的路由設定，更進階的 load balancing、logging、 L4 routing 以及 TLS 等等的看各家實作</p>

<blockquote>
  <p>有關 L4, L7 可以參考 <a href="../../network/network-osi">重新認識網路 - OSI 七層模型 | Shawn Hsu</a></p>
</blockquote>

<p>除了進階的功能以外，最基本的 L7 路由是由 Kubernetes <code class="language-plaintext highlighter-rouge">Ingress</code> Resource 定義<br />
其實你可以注意到，<code class="language-plaintext highlighter-rouge">Ingress</code> 並不是要取代 <code class="language-plaintext highlighter-rouge">Service</code>，而是互補的<br />
底層還是要依靠 <code class="language-plaintext highlighter-rouge">Service</code> 來進行轉發</p>

<blockquote>
  <p>如果要使用進階的功能，內建的 Ingress 可能不足以描述<br />
所以不同 vendor 可能會使用其他資源甚至是 CRD，比如說 <a href="https://apisix.apache.org/">Apache APISIX</a> 有 <a href="https://apisix.apache.org/docs/ingress-controller/concepts/resources/#ingress-api-extensions">ApisixRoute</a> 資源</p>
</blockquote>

<blockquote>
  <p>有關 CRD 可以參考 <a href="../../kubernetes/kubernetes-crd">Kubernetes 從零開始 - client-go 實操 CRD | Shawn Hsu</a></p>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-wildcard-host</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s2">"</span><span class="s">foo.bar.com"</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/bar"</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">service1</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s2">"</span><span class="s">*.foo.com"</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/foo"</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">service2</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="ingress-controllers">Ingress Controllers</h1>
<h2 id="ingress-nginx-controller">Ingress Nginx Controller</h2>
<p>Ingress Nginx Controller 就是以 <a href="https://nginx.org/">Nginx</a> 為基礎的 Ingress Controller<br />
基本上這個 controller 的主要目的是根據不同的 Resource 生成 <strong>nginx.conf</strong> 的設定檔<br />
這些 Resource 包括 <code class="language-plaintext highlighter-rouge">Ingress</code>, <code class="language-plaintext highlighter-rouge">Services</code>, <code class="language-plaintext highlighter-rouge">Endpoints</code>, <code class="language-plaintext highlighter-rouge">Secrets</code> 以及 <code class="language-plaintext highlighter-rouge">ConfigMaps</code></p>

<p>每一次 Resource 有變化，Controller 就會重新生成設定檔<br />
這樣的做法會一直重複生成，雖然很耗資源，但這是必要的，因為你沒辦法知道 Resource 的變化會不會最終導致 <strong>nginx.conf</strong> 的變化<br />
也有可能沒改變？ 那這樣就不需要更新設定檔了(不過計算還是需要的)</p>

<p>實作上 Ingress Nginx Controller 是使用 <strong>Informer</strong> 進行處理<br />
註冊 EventHandler 來監聽，並且通過 Ring Buffer(RingChannel) 傳遞需要處理的資料(可以參考 <a href="https://github.com/kubernetes/ingress-nginx/blob/main/internal/ingress/controller/store/store.go#L250">controller/store/store.go#L250</a>)<br />
之後再由 Ingress Controller 的 <code class="language-plaintext highlighter-rouge">Start</code> 取出資料再放到 <strong>SyncQueue</strong> 裡面(可參考 <a href="https://github.com/kubernetes/ingress-nginx/blob/main/internal/ingress/controller/nginx.go#L359">controller/nginx.go#L359</a>)</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre><span class="c">// New creates a new object store to be used in the ingress controller.</span>
<span class="c">//</span>
<span class="c">//nolint:gocyclo // Ignore function complexity error.</span>
<span class="k">func</span> <span class="n">New</span><span class="p">(</span>
    <span class="n">namespace</span> <span class="kt">string</span><span class="p">,</span>
    <span class="n">namespaceSelector</span> <span class="n">labels</span><span class="o">.</span><span class="n">Selector</span><span class="p">,</span>
    <span class="n">configmap</span><span class="p">,</span> <span class="n">tcp</span><span class="p">,</span> <span class="n">udp</span><span class="p">,</span> <span class="n">defaultSSLCertificate</span> <span class="kt">string</span><span class="p">,</span>
    <span class="n">resyncPeriod</span> <span class="n">time</span><span class="o">.</span><span class="n">Duration</span><span class="p">,</span>
    <span class="n">client</span> <span class="n">clientset</span><span class="o">.</span><span class="n">Interface</span><span class="p">,</span>
    <span class="n">updateCh</span> <span class="o">*</span><span class="n">channels</span><span class="o">.</span><span class="n">RingChannel</span><span class="p">,</span>
    <span class="n">disableCatchAll</span> <span class="kt">bool</span><span class="p">,</span>
    <span class="n">deepInspector</span> <span class="kt">bool</span><span class="p">,</span>
    <span class="n">icConfig</span> <span class="o">*</span><span class="n">ingressclass</span><span class="o">.</span><span class="n">Configuration</span><span class="p">,</span>
    <span class="n">disableSyncEvents</span> <span class="kt">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="n">Storer</span> <span class="p">{</span>
    <span class="n">ingEventHandler</span> <span class="o">:=</span> <span class="n">cache</span><span class="o">.</span><span class="n">ResourceEventHandlerFuncs</span><span class="p">{</span>
        <span class="n">AddFunc</span><span class="o">:</span> <span class="k">func</span><span class="p">(</span><span class="n">obj</span> <span class="k">interface</span><span class="p">{})</span> <span class="p">{</span>
          <span class="n">ing</span><span class="p">,</span> <span class="n">_</span> <span class="o">:=</span> <span class="n">toIngress</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>

          <span class="k">if</span> <span class="o">!</span><span class="n">watchedNamespace</span><span class="p">(</span><span class="n">ing</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="p">{</span>
              <span class="k">return</span>
          <span class="p">}</span>

          <span class="n">ic</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">store</span><span class="o">.</span><span class="n">GetIngressClass</span><span class="p">(</span><span class="n">ing</span><span class="p">,</span> <span class="n">icConfig</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
              <span class="n">klog</span><span class="o">.</span><span class="n">InfoS</span><span class="p">(</span><span class="s">"Ignoring ingress because of error while validating ingress class"</span><span class="p">,</span> <span class="s">"ingress"</span><span class="p">,</span> <span class="n">klog</span><span class="o">.</span><span class="n">KObj</span><span class="p">(</span><span class="n">ing</span><span class="p">),</span> <span class="s">"error"</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
              <span class="k">return</span>
          <span class="p">}</span>

          <span class="n">klog</span><span class="o">.</span><span class="n">InfoS</span><span class="p">(</span><span class="s">"Found valid IngressClass"</span><span class="p">,</span> <span class="s">"ingress"</span><span class="p">,</span> <span class="n">klog</span><span class="o">.</span><span class="n">KObj</span><span class="p">(</span><span class="n">ing</span><span class="p">),</span> <span class="s">"ingressclass"</span><span class="p">,</span> <span class="n">ic</span><span class="p">)</span>

          <span class="o">...</span>

        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="rouge-code"><pre><span class="c">// Start starts a new NGINX master process running in the foreground.</span>
<span class="k">func</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span><span class="n">NGINXController</span><span class="p">)</span> <span class="n">Start</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">{</span>
        <span class="k">select</span> <span class="p">{</span>
        <span class="k">case</span> <span class="n">err</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">n</span><span class="o">.</span><span class="n">ngxErrCh</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">isShuttingDown</span> <span class="p">{</span>
                <span class="k">return</span>
            <span class="p">}</span>

            <span class="c">// if the nginx master process dies, the workers continue to process requests</span>
            <span class="c">// until the failure of the configured livenessProbe and restart of the pod.</span>
            <span class="k">if</span> <span class="n">process</span><span class="o">.</span><span class="n">IsRespawnIfRequired</span><span class="p">(</span><span class="n">err</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">return</span>
            <span class="p">}</span>

        <span class="k">case</span> <span class="n">event</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">n</span><span class="o">.</span><span class="n">updateCh</span><span class="o">.</span><span class="n">Out</span><span class="p">()</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">isShuttingDown</span> <span class="p">{</span>
                <span class="k">break</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="n">evt</span><span class="p">,</span> <span class="n">ok</span> <span class="o">:=</span> <span class="n">event</span><span class="o">.</span><span class="p">(</span><span class="n">store</span><span class="o">.</span><span class="n">Event</span><span class="p">);</span> <span class="n">ok</span> <span class="p">{</span>
                <span class="n">klog</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="m">3</span><span class="p">)</span><span class="o">.</span><span class="n">InfoS</span><span class="p">(</span><span class="s">"Event received"</span><span class="p">,</span> <span class="s">"type"</span><span class="p">,</span> <span class="n">evt</span><span class="o">.</span><span class="n">Type</span><span class="p">,</span> <span class="s">"object"</span><span class="p">,</span> <span class="n">evt</span><span class="o">.</span><span class="n">Obj</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">evt</span><span class="o">.</span><span class="n">Type</span> <span class="o">==</span> <span class="n">store</span><span class="o">.</span><span class="n">ConfigurationEvent</span> <span class="p">{</span>
                    <span class="c">// TODO: is this necessary? Consider removing this special case</span>
                    <span class="n">n</span><span class="o">.</span><span class="n">syncQueue</span><span class="o">.</span><span class="n">EnqueueTask</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">GetDummyObject</span><span class="p">(</span><span class="s">"configmap-change"</span><span class="p">))</span>
                    <span class="k">continue</span>
                <span class="p">}</span>

                <span class="n">n</span><span class="o">.</span><span class="n">syncQueue</span><span class="o">.</span><span class="n">EnqueueSkippableTask</span><span class="p">(</span><span class="n">evt</span><span class="o">.</span><span class="n">Obj</span><span class="p">)</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="n">klog</span><span class="o">.</span><span class="n">Warningf</span><span class="p">(</span><span class="s">"Unexpected event type received %T"</span><span class="p">,</span> <span class="n">event</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="k">case</span> <span class="o">&lt;-</span><span class="n">n</span><span class="o">.</span><span class="n">stopCh</span><span class="o">:</span>
            <span class="k">return</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>有關 Ring Buffer 可以參考 <a href="../../random/golang-channel#ring-buffer">Goroutine 與 Channel 的共舞 | Shawn Hsu</a></p>
</blockquote>

<blockquote>
  <p>有關 Informer 可以參考 <a href="../../kubernetes/kubernetes-controller-concept">Kubernetes 從零開始 - Informer 架構以及 Controller Pattern | Shawn Hsu</a></p>
</blockquote>

<p>那這個 <strong>SyncQueue</strong> 在初始化的時候會給一個 callback 負責處理 queue 裡面的資料<br />
以 Ingress Nginx Controller 來說，就是 <code class="language-plaintext highlighter-rouge">syncIngress</code>(<a href="https://github.com/kubernetes/ingress-nginx/blob/main/internal/ingress/controller/store/store.go#L908">controller/store.go#L908</a>)</p>

<p>那設定檔最終會被交給 <a href="https://nginx.org/">Nginx</a> 內部並且 reload<br />
Resource 的新增刪除更新某種程度上都會影響 reload 的頻率<br />
比如說</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Ingress</code> 被新增</li>
  <li><code class="language-plaintext highlighter-rouge">Ingress</code>, <code class="language-plaintext highlighter-rouge">Secrets</code>, <code class="language-plaintext highlighter-rouge">Services</code> 被刪除</li>
  <li><code class="language-plaintext highlighter-rouge">Ingress</code> 的內部路由規則，TLS 或者 annotation 有變化</li>
</ul>

<p>等等的都會要 reload</p>

<blockquote>
  <p>如果你的 Ingress 是非法的，比如說打錯字之類的<br />
為了避免無法正常運作，Admission Webhook 會被用於驗證，通過之後才會送到 Controller 進行處理</p>
</blockquote>

<h3 id="downtime-of-ingress-nginx-controller">Downtime of Ingress Nginx Controller</h3>
<p>那這個 reload 其實會造成問題<br />
<a href="https://nginx.org/en/docs/control.html">Nginx</a> 的 reload 是透過新的 worker process 接替(新的連線都由他處理)<br />
然後舊的 worker process 會被 graceful shutdown(i.e. 處理完當前的連接就會停止)<br />
看起來不會造成 downtime?</p>

<p><img src="https://static.apiseven.com/apisix-webp/2022/11/25/638039cf15879.webp" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://apisix.apache.org/zh/blog/2022/11/23/why-is-not-reload-hot-loaded-in-nginx/">为什么 NGINX 的 reload 不是热加载？</a></p>
</blockquote>

<p>考慮到 keepalive 的長連接設定<br />
因為 config 更新會造成 reload，<a href="https://nginx.org/en/docs/control.html">Nginx</a> 便會主動通知 connection 關閉<br />
然而在系統負載過高的情況下，client 可能會沒收到關閉的通知，進一步造成 downtime</p>

<blockquote>
  <p>可以參考 <a href="https://my.f5.com/s/article/K000153144">K000153144: How to extend Graceful Shutdown Time for NGINX worker Process during Configuration Reload</a></p>
</blockquote>

<p>另一個點是，舊的 worker process 需要處理連接的時間其實是無法預測的<br />
所以說如果你一直 trigger reload，old worker process 就會一直長出來，並且因為執行時間是無法預測的<br />
進而導致 process 數量過多，提升系統壓力，進而導致 downtime 的出現</p>

<h2 id="traefik-ingress-controller">Traefik Ingress Controller</h2>
<p>而 Traefik 就不會有 downtime 的問題，因為 Traefik 不需要將 configuration reload，然後再交給新的 worker process 去處理<br />
所有的設定檔都是 in-memory 進行 hot reload 的<br />
整體的實作也同樣是基於 <strong>Informer</strong> 的衍伸架構</p>

<blockquote>
  <p>有關 Informer 可以參考 <a href="../../kubernetes/kubernetes-controller-concept">Kubernetes 從零開始 - Informer 架構以及 Controller Pattern | Shawn Hsu</a></p>
</blockquote>

<p>監聽 Ingress Resource 的變化是使用 <code class="language-plaintext highlighter-rouge">WatchAll</code> 這個 function 註冊 EventHandler(可以參考 <a href="https://github.com/traefik/traefik/blob/master/pkg/provider/kubernetes/ingress/client.go#L141">ingress/client.go#L141</a>)<br />
並且透過 <strong>eventCh</strong> 的 Golang channel 接收 event</p>

<blockquote>
  <p>有關 Golang channel 可以參考 <a href="../../random/golang-channel">Goroutine 與 Channel 的共舞 | Shawn Hsu</a></p>
</blockquote>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="k">const</span> <span class="p">(</span>
    <span class="n">resyncPeriod</span>   <span class="o">=</span> <span class="m">10</span> <span class="o">*</span> <span class="n">time</span><span class="o">.</span><span class="n">Minute</span>
    <span class="n">defaultTimeout</span> <span class="o">=</span> <span class="m">5</span> <span class="o">*</span> <span class="n">time</span><span class="o">.</span><span class="n">Second</span>
<span class="p">)</span>

<span class="c">// WatchAll starts namespace-specific controllers for all relevant kinds.</span>
<span class="k">func</span> <span class="p">(</span><span class="n">c</span> <span class="o">*</span><span class="n">clientWrapper</span><span class="p">)</span> <span class="n">WatchAll</span><span class="p">(</span><span class="n">namespaces</span> <span class="p">[]</span><span class="kt">string</span><span class="p">,</span> <span class="n">stopCh</span> <span class="o">&lt;-</span><span class="k">chan</span> <span class="k">struct</span><span class="p">{})</span> <span class="p">(</span><span class="o">&lt;-</span><span class="k">chan</span> <span class="k">interface</span><span class="p">{},</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">eventCh</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">(</span><span class="k">chan</span> <span class="k">interface</span><span class="p">{},</span> <span class="m">1</span><span class="p">)</span>
    <span class="n">eventHandler</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="n">k8s</span><span class="o">.</span><span class="n">ResourceEventHandler</span><span class="p">{</span><span class="n">Ev</span><span class="o">:</span> <span class="n">eventCh</span><span class="p">}</span>

    <span class="o">...</span>

    <span class="n">factoryIngress</span> <span class="o">:=</span> <span class="n">kinformers</span><span class="o">.</span><span class="n">NewSharedInformerFactoryWithOptions</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">clientset</span><span class="p">,</span> <span class="n">resyncPeriod</span><span class="p">,</span> <span class="n">kinformers</span><span class="o">.</span><span class="n">WithNamespace</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">kinformers</span><span class="o">.</span><span class="n">WithTweakListOptions</span><span class="p">(</span><span class="n">matchesLabelSelector</span><span class="p">))</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">factoryIngress</span><span class="o">.</span><span class="n">Networking</span><span class="p">()</span><span class="o">.</span><span class="n">V1</span><span class="p">()</span><span class="o">.</span><span class="n">Ingresses</span><span class="p">()</span><span class="o">.</span><span class="n">Informer</span><span class="p">()</span><span class="o">.</span><span class="n">AddEventHandler</span><span class="p">(</span><span class="n">eventHandler</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
        <span class="k">return</span> <span class="no">nil</span><span class="p">,</span> <span class="n">err</span>
    <span class="p">}</span>

    <span class="o">...</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>這個 <strong>eventCh</strong> 的資料會被 <code class="language-plaintext highlighter-rouge">Provide</code> 的 function 接收並處理<br />
初步來看，會讀取 Ingress Resource 的資料並且計算 hash 值，只有在不同的 hash 值才會進行下一步<br />
下一步會被進一步送到 <strong>configurationChan</strong> 裡面(可以參考 <a href="https://github.com/traefik/traefik/blob/master/pkg/provider/kubernetes/ingress/kubernetes.go#L136">ingress/kubernetes.go#L136</a>)</p>

<blockquote>
  <p><strong>eventCh</strong> 是一個 Ring Buffer(code 裡面稱為 RingChannel)，可以參考 <a href="https://github.com/traefik/traefik/blob/master/pkg/provider/aggregator/ring_channel.go">aggregator/ring_channel.go</a><br />
有關 Ring Buffer 可以參考 <a href="../../random/golang-channel#ring-buffer">Goroutine 與 Channel 的共舞 | Shawn Hsu</a></p>
</blockquote>

<blockquote>
  <p>所有的 Provider 都是被 <a href="https://github.com/traefik/traefik/blob/master/pkg/provider/aggregator/aggregator.go">Provider Aggregator</a> 所管理</p>
</blockquote>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
</pre></td><td class="rouge-code"><pre><span class="c">// Provide allows the k8s provider to provide configurations to traefik</span>
<span class="c">// using the given configuration channel.</span>
<span class="k">func</span> <span class="p">(</span><span class="n">p</span> <span class="o">*</span><span class="n">Provider</span><span class="p">)</span> <span class="n">Provide</span><span class="p">(</span><span class="n">configurationChan</span> <span class="k">chan</span><span class="o">&lt;-</span> <span class="n">dynamic</span><span class="o">.</span><span class="n">Message</span><span class="p">,</span> <span class="n">pool</span> <span class="o">*</span><span class="n">safe</span><span class="o">.</span><span class="n">Pool</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
    <span class="n">logger</span> <span class="o">:=</span> <span class="n">log</span><span class="o">.</span><span class="n">With</span><span class="p">()</span><span class="o">.</span><span class="n">Str</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">ProviderName</span><span class="p">,</span> <span class="s">"kubernetes"</span><span class="p">)</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span>
    <span class="n">ctxLog</span> <span class="o">:=</span> <span class="n">logger</span><span class="o">.</span><span class="n">WithContext</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">Background</span><span class="p">())</span>

    <span class="n">k8sClient</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">p</span><span class="o">.</span><span class="n">newK8sClient</span><span class="p">(</span><span class="n">ctxLog</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">err</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">AllowExternalNameServices</span> <span class="p">{</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">Info</span><span class="p">()</span><span class="o">.</span><span class="n">Msg</span><span class="p">(</span><span class="s">"ExternalName service loading is enabled, please ensure that this is expected (see AllowExternalNameServices option)"</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">pool</span><span class="o">.</span><span class="n">GoCtx</span><span class="p">(</span><span class="k">func</span><span class="p">(</span><span class="n">ctxPool</span> <span class="n">context</span><span class="o">.</span><span class="n">Context</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">operation</span> <span class="o">:=</span> <span class="k">func</span><span class="p">()</span> <span class="kt">error</span> <span class="p">{</span>
            <span class="n">eventsChan</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">k8sClient</span><span class="o">.</span><span class="n">WatchAll</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">Namespaces</span><span class="p">,</span> <span class="n">ctxPool</span><span class="o">.</span><span class="n">Done</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">Error</span><span class="p">()</span><span class="o">.</span><span class="n">Err</span><span class="p">(</span><span class="n">err</span><span class="p">)</span><span class="o">.</span><span class="n">Msg</span><span class="p">(</span><span class="s">"Error watching kubernetes events"</span><span class="p">)</span>
                <span class="n">timer</span> <span class="o">:=</span> <span class="n">time</span><span class="o">.</span><span class="n">NewTimer</span><span class="p">(</span><span class="m">1</span> <span class="o">*</span> <span class="n">time</span><span class="o">.</span><span class="n">Second</span><span class="p">)</span>
                <span class="k">select</span> <span class="p">{</span>
                <span class="k">case</span> <span class="o">&lt;-</span><span class="n">timer</span><span class="o">.</span><span class="n">C</span><span class="o">:</span>
                    <span class="k">return</span> <span class="n">err</span>
                <span class="k">case</span> <span class="o">&lt;-</span><span class="n">ctxPool</span><span class="o">.</span><span class="n">Done</span><span class="p">()</span><span class="o">:</span>
                    <span class="k">return</span> <span class="no">nil</span>
                <span class="p">}</span>
            <span class="p">}</span>

          <span class="n">throttleDuration</span> <span class="o">:=</span> <span class="n">time</span><span class="o">.</span><span class="n">Duration</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">ThrottleDuration</span><span class="p">)</span>
          <span class="n">throttledChan</span> <span class="o">:=</span> <span class="n">throttleEvents</span><span class="p">(</span><span class="n">ctxLog</span><span class="p">,</span> <span class="n">throttleDuration</span><span class="p">,</span> <span class="n">pool</span><span class="p">,</span> <span class="n">eventsChan</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">throttledChan</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
              <span class="n">eventsChan</span> <span class="o">=</span> <span class="n">throttledChan</span>
          <span class="p">}</span>

          <span class="k">for</span> <span class="p">{</span>
              <span class="k">select</span> <span class="p">{</span>
              <span class="k">case</span> <span class="o">&lt;-</span><span class="n">ctxPool</span><span class="o">.</span><span class="n">Done</span><span class="p">()</span><span class="o">:</span>
                  <span class="k">return</span> <span class="no">nil</span>
              <span class="k">case</span> <span class="n">event</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">eventsChan</span><span class="o">:</span>
                  <span class="c">// Note that event is the *first* event that came in during this</span>
                  <span class="c">// throttling interval -- if we're hitting our throttle, we may have</span>
                  <span class="c">// dropped events. This is fine, because we don't treat different</span>
                  <span class="c">// event types differently. But if we do in the future, we'll need to</span>
                  <span class="c">// track more information about the dropped events.</span>
                  <span class="n">conf</span> <span class="o">:=</span> <span class="n">p</span><span class="o">.</span><span class="n">loadConfigurationFromIngresses</span><span class="p">(</span><span class="n">ctxLog</span><span class="p">,</span> <span class="n">k8sClient</span><span class="p">)</span>

                  <span class="n">confHash</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">hashstructure</span><span class="o">.</span><span class="n">Hash</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="no">nil</span><span class="p">)</span>
                  <span class="k">switch</span> <span class="p">{</span>
                  <span class="k">case</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span><span class="o">:</span>
                      <span class="n">logger</span><span class="o">.</span><span class="n">Error</span><span class="p">()</span><span class="o">.</span><span class="n">Msg</span><span class="p">(</span><span class="s">"Unable to hash the configuration"</span><span class="p">)</span>
                  <span class="k">case</span> <span class="n">p</span><span class="o">.</span><span class="n">lastConfiguration</span><span class="o">.</span><span class="n">Get</span><span class="p">()</span> <span class="o">==</span> <span class="n">confHash</span><span class="o">:</span>
                      <span class="n">logger</span><span class="o">.</span><span class="n">Debug</span><span class="p">()</span><span class="o">.</span><span class="n">Msgf</span><span class="p">(</span><span class="s">"Skipping Kubernetes event kind %T"</span><span class="p">,</span> <span class="n">event</span><span class="p">)</span>
                  <span class="k">default</span><span class="o">:</span>
                      <span class="n">p</span><span class="o">.</span><span class="n">lastConfiguration</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">confHash</span><span class="p">)</span>
                      <span class="n">configurationChan</span> <span class="o">&lt;-</span> <span class="n">dynamic</span><span class="o">.</span><span class="n">Message</span><span class="p">{</span>
                        <span class="n">ProviderName</span><span class="o">:</span>  <span class="s">"kubernetes"</span><span class="p">,</span>
                        <span class="n">Configuration</span><span class="o">:</span> <span class="n">conf</span><span class="p">,</span>
                      <span class="p">}</span>
                  <span class="p">}</span>

                  <span class="c">// If we're throttling, we sleep here for the throttle duration to</span>
                  <span class="c">// enforce that we don't refresh faster than our throttle. time.Sleep</span>
                  <span class="c">// returns immediately if p.ThrottleDuration is 0 (no throttle).</span>
                  <span class="n">time</span><span class="o">.</span><span class="n">Sleep</span><span class="p">(</span><span class="n">throttleDuration</span><span class="p">)</span>
              <span class="p">}</span>
          <span class="p">}</span>
        <span class="p">}</span>

        <span class="n">notify</span> <span class="o">:=</span> <span class="k">func</span><span class="p">(</span><span class="n">err</span> <span class="kt">error</span><span class="p">,</span> <span class="n">time</span> <span class="n">time</span><span class="o">.</span><span class="n">Duration</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">Error</span><span class="p">()</span><span class="o">.</span><span class="n">Err</span><span class="p">(</span><span class="n">err</span><span class="p">)</span><span class="o">.</span><span class="n">Msgf</span><span class="p">(</span><span class="s">"Provider error, retrying in %s"</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="n">err</span> <span class="o">:=</span> <span class="n">backoff</span><span class="o">.</span><span class="n">RetryNotify</span><span class="p">(</span><span class="n">safe</span><span class="o">.</span><span class="n">OperationWithRecover</span><span class="p">(</span><span class="n">operation</span><span class="p">),</span> <span class="n">backoff</span><span class="o">.</span><span class="n">WithContext</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">NewBackOff</span><span class="p">(</span><span class="n">backoff</span><span class="o">.</span><span class="n">NewExponentialBackOff</span><span class="p">()),</span> <span class="n">ctxPool</span><span class="p">),</span> <span class="n">notify</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">Error</span><span class="p">()</span><span class="o">.</span><span class="n">Err</span><span class="p">(</span><span class="n">err</span><span class="p">)</span><span class="o">.</span><span class="n">Msg</span><span class="p">(</span><span class="s">"Cannot retrieve data"</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">})</span>

    <span class="k">return</span> <span class="no">nil</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>那，是誰 consume <strong>configurationChan</strong> 呢？<br />
主程式 traefik 會在啟動的時候初始化 <code class="language-plaintext highlighter-rouge">ConfigurationWatcher</code>(可參考 <a href="https://github.com/traefik/traefik/blob/master/cmd/traefik/traefik.go#L313">cmd/traefik/traefik.go#L313</a>)<br />
同時 <strong>configurationChan</strong> 也是在 <code class="language-plaintext highlighter-rouge">ConfigurationWatcher</code> 裡面被建立以及被提供給 Provider Aggregator 使用</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="k">func</span> <span class="p">(</span><span class="n">c</span> <span class="o">*</span><span class="n">ConfigurationWatcher</span><span class="p">)</span> <span class="n">startProviderAggregator</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">log</span><span class="o">.</span><span class="n">Info</span><span class="p">()</span><span class="o">.</span><span class="n">Msgf</span><span class="p">(</span><span class="s">"Starting provider aggregator %T"</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">providerAggregator</span><span class="p">)</span>

    <span class="n">safe</span><span class="o">.</span><span class="n">Go</span><span class="p">(</span><span class="k">func</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">err</span> <span class="o">:=</span> <span class="n">c</span><span class="o">.</span><span class="n">providerAggregator</span><span class="o">.</span><span class="n">Provide</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">allProvidersConfigs</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">routinesPool</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
            <span class="n">log</span><span class="o">.</span><span class="n">Error</span><span class="p">()</span><span class="o">.</span><span class="n">Err</span><span class="p">(</span><span class="n">err</span><span class="p">)</span><span class="o">.</span><span class="n">Msgf</span><span class="p">(</span><span class="s">"Error starting provider aggregator %T"</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">providerAggregator</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">})</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>真正的魔法發生在 <code class="language-plaintext highlighter-rouge">receiveConfigurations</code> 以及 <code class="language-plaintext highlighter-rouge">applyConfigurations</code> 裡面<br />
<code class="language-plaintext highlighter-rouge">ConfigurationWatcher</code> 裡面有兩個 channel，分別是 <strong>allProvidersConfigs</strong> 以及 <strong>newConfigs</strong><br />
<code class="language-plaintext highlighter-rouge">receiveConfigurations</code> 負責從 <strong>allProvidersConfigs</strong> 接收資料，並且進行處理<br />
然後再將資料送到 <strong>newConfigs</strong> 裡面，被 <code class="language-plaintext highlighter-rouge">applyConfigurations</code> 所使用</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
</pre></td><td class="rouge-code"><pre><span class="c">// receiveConfigurations receives configuration changes from the providers.</span>
<span class="c">// The configuration message then gets passed along a series of check, notably</span>
<span class="c">// to verify that, for a given provider, the configuration that was just received</span>
<span class="c">// is at least different from the previously received one.</span>
<span class="c">// The full set of configurations is then sent to the throttling goroutine,</span>
<span class="c">// (throttleAndApplyConfigurations) via a RingChannel, which ensures that we can</span>
<span class="c">// constantly send in a non-blocking way to the throttling goroutine the last</span>
<span class="c">// global state we are aware of.</span>
<span class="k">func</span> <span class="p">(</span><span class="n">c</span> <span class="o">*</span><span class="n">ConfigurationWatcher</span><span class="p">)</span> <span class="n">receiveConfigurations</span><span class="p">(</span><span class="n">ctx</span> <span class="n">context</span><span class="o">.</span><span class="n">Context</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">newConfigurations</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">(</span><span class="n">dynamic</span><span class="o">.</span><span class="n">Configurations</span><span class="p">)</span>
    <span class="k">var</span> <span class="n">output</span> <span class="k">chan</span> <span class="n">dynamic</span><span class="o">.</span><span class="n">Configurations</span>
    <span class="k">for</span> <span class="p">{</span>
        <span class="k">select</span> <span class="p">{</span>
        <span class="k">case</span> <span class="o">&lt;-</span><span class="n">ctx</span><span class="o">.</span><span class="n">Done</span><span class="p">()</span><span class="o">:</span>
            <span class="k">return</span>
        <span class="c">// DeepCopy is necessary because newConfigurations gets modified later by the consumer of c.newConfigs</span>
        <span class="k">case</span> <span class="n">output</span> <span class="o">&lt;-</span> <span class="n">newConfigurations</span><span class="o">.</span><span class="n">DeepCopy</span><span class="p">()</span><span class="o">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="no">nil</span>

        <span class="k">default</span><span class="o">:</span>
            <span class="k">select</span> <span class="p">{</span>
            <span class="k">case</span> <span class="o">&lt;-</span><span class="n">ctx</span><span class="o">.</span><span class="n">Done</span><span class="p">()</span><span class="o">:</span>
                <span class="k">return</span>
            <span class="k">case</span> <span class="n">configMsg</span><span class="p">,</span> <span class="n">ok</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">c</span><span class="o">.</span><span class="n">allProvidersConfigs</span><span class="o">:</span>
                <span class="k">if</span> <span class="o">!</span><span class="n">ok</span> <span class="p">{</span>
                    <span class="k">return</span>
                <span class="p">}</span>

                <span class="n">logger</span> <span class="o">:=</span> <span class="n">log</span><span class="o">.</span><span class="n">Ctx</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span><span class="o">.</span><span class="n">With</span><span class="p">()</span><span class="o">.</span><span class="n">Str</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">ProviderName</span><span class="p">,</span> <span class="n">configMsg</span><span class="o">.</span><span class="n">ProviderName</span><span class="p">)</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">configMsg</span><span class="o">.</span><span class="n">Configuration</span> <span class="o">==</span> <span class="no">nil</span> <span class="p">{</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">Debug</span><span class="p">()</span><span class="o">.</span><span class="n">Msg</span><span class="p">(</span><span class="s">"Skipping nil configuration"</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="p">}</span>

                <span class="k">if</span> <span class="n">isEmptyConfiguration</span><span class="p">(</span><span class="n">configMsg</span><span class="o">.</span><span class="n">Configuration</span><span class="p">)</span> <span class="p">{</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">Debug</span><span class="p">()</span><span class="o">.</span><span class="n">Msg</span><span class="p">(</span><span class="s">"Skipping empty configuration"</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="p">}</span>

                <span class="n">logConfiguration</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">configMsg</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">reflect</span><span class="o">.</span><span class="n">DeepEqual</span><span class="p">(</span><span class="n">newConfigurations</span><span class="p">[</span><span class="n">configMsg</span><span class="o">.</span><span class="n">ProviderName</span><span class="p">],</span> <span class="n">configMsg</span><span class="o">.</span><span class="n">Configuration</span><span class="p">)</span> <span class="p">{</span>
                    <span class="c">// no change, do nothing</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">Debug</span><span class="p">()</span><span class="o">.</span><span class="n">Msg</span><span class="p">(</span><span class="s">"Skipping unchanged configuration"</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="p">}</span>

                <span class="n">newConfigurations</span><span class="p">[</span><span class="n">configMsg</span><span class="o">.</span><span class="n">ProviderName</span><span class="p">]</span> <span class="o">=</span> <span class="n">configMsg</span><span class="o">.</span><span class="n">Configuration</span><span class="o">.</span><span class="n">DeepCopy</span><span class="p">()</span>

                <span class="n">output</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">newConfigs</span>

            <span class="c">// DeepCopy is necessary because newConfigurations gets modified later by the consumer of c.newConfigs</span>
            <span class="k">case</span> <span class="n">output</span> <span class="o">&lt;-</span> <span class="n">newConfigurations</span><span class="o">.</span><span class="n">DeepCopy</span><span class="p">()</span><span class="o">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="no">nil</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre><span class="c">// applyConfigurations blocks on a RingChannel that receives the new</span>
<span class="c">// set of configurations that is compiled and sent by receiveConfigurations as soon</span>
<span class="c">// as a provider change occurs. If the new set is different from the previous set</span>
<span class="c">// that had been applied, the new set is applied, and we sleep for a while before</span>
<span class="c">// listening on the channel again.</span>
<span class="k">func</span> <span class="p">(</span><span class="n">c</span> <span class="o">*</span><span class="n">ConfigurationWatcher</span><span class="p">)</span> <span class="n">applyConfigurations</span><span class="p">(</span><span class="n">ctx</span> <span class="n">context</span><span class="o">.</span><span class="n">Context</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">var</span> <span class="n">lastConfigurations</span> <span class="n">dynamic</span><span class="o">.</span><span class="n">Configurations</span>
    <span class="k">for</span> <span class="p">{</span>
        <span class="k">select</span> <span class="p">{</span>
        <span class="k">case</span> <span class="o">&lt;-</span><span class="n">ctx</span><span class="o">.</span><span class="n">Done</span><span class="p">()</span><span class="o">:</span>
            <span class="k">return</span>
        <span class="k">case</span> <span class="n">newConfigs</span><span class="p">,</span> <span class="n">ok</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">c</span><span class="o">.</span><span class="n">newConfigs</span><span class="o">:</span>
            <span class="k">if</span> <span class="o">!</span><span class="n">ok</span> <span class="p">{</span>
                <span class="k">return</span>
            <span class="p">}</span>

            <span class="c">// We wait for first configuration of the required provider before applying configurations.</span>
            <span class="k">if</span> <span class="n">_</span><span class="p">,</span> <span class="n">ok</span> <span class="o">:=</span> <span class="n">newConfigs</span><span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">requiredProvider</span><span class="p">];</span> <span class="n">c</span><span class="o">.</span><span class="n">requiredProvider</span> <span class="o">!=</span> <span class="s">""</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">ok</span> <span class="p">{</span>
                <span class="k">continue</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="n">reflect</span><span class="o">.</span><span class="n">DeepEqual</span><span class="p">(</span><span class="n">newConfigs</span><span class="p">,</span> <span class="n">lastConfigurations</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">continue</span>
            <span class="p">}</span>

            <span class="n">conf</span> <span class="o">:=</span> <span class="n">mergeConfiguration</span><span class="p">(</span><span class="n">newConfigs</span><span class="o">.</span><span class="n">DeepCopy</span><span class="p">(),</span> <span class="n">c</span><span class="o">.</span><span class="n">defaultEntryPoints</span><span class="p">)</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">applyModel</span><span class="p">(</span><span class="n">conf</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">listener</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">c</span><span class="o">.</span><span class="n">configurationListeners</span> <span class="p">{</span>
                <span class="n">listener</span><span class="p">(</span><span class="n">conf</span><span class="p">)</span>
            <span class="p">}</span>

            <span class="n">lastConfigurations</span> <span class="o">=</span> <span class="n">newConfigs</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="apache-apisix-ingress-controller">Apache APISIX Ingress Controller</h2>
<p>與 <a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 以及 <a href="#traefik-ingress-controller">Traefik Ingress Controller</a> 不同的是<br />
APISIX 他的設定檔是存放在 <code class="language-plaintext highlighter-rouge">etcd</code> 裡面，而不是直接 in-memory</p>

<blockquote>
  <p>Traefik Enterprise 則是由 Control Plane 負責推播所有資料(包含 events, certificates 以及 Traefik 設定檔等等)，跟 Traefik OSS 的實作是不同的<br />
這些資料是存放在 distributed 的 key-value store 裡面</p>
</blockquote>

<p>Apache APISIX 本身是為了解決 <a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 的 reload 問題而誕生的<br />
而實作上是基於 <a href="https://nginx.org/">Nginx</a> 以及 LuaJIT(<a href="https://openresty.org/">OpenResty</a>)<br />
透過將動態路由的設定檔置於 APISIX Core 中，所有的 request 都會先經過 <a href="https://nginx.org/">Nginx</a> 的單點入口，再經過 APISIX Core 動態的指定 upstream(i.e. 你的後端)，從而避免 <a href="https://nginx.org/">Nginx</a> reload 帶來的影響<br />
也因為 APISIX 本人與 <code class="language-plaintext highlighter-rouge">etcd</code> 都支援多點部署，單點失效並不會影響整體 proxy 的運作</p>

<blockquote>
  <p>APISIX 內，<a href="https://nginx.org/">Nginx</a> 只會有一個 server 一個 location<br />
所以不管 APISIX Core 怎麼變化，Nginx 都不需要 reload</p>
</blockquote>

<h1 id="ingress-controller-to-support-gateway-api">Ingress Controller to Support Gateway API</h1>
<p><code class="language-plaintext highlighter-rouge">Ingress</code> 的 Resource 的設計是很粗略的<br />
除了缺少比較進階的功能之外，他也沒辦法進行擴充，移植性也很差</p>

<p>如果更換 Controller，<code class="language-plaintext highlighter-rouge">Ingress</code> 大概率無法重複利用<br />
比方說 <a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 會透過自定義的 annotation 來達到特殊的功能<br />
如果你換成 <a href="#traefik-ingress-controller">Traefik Ingress Controller</a>，那這個 annotation 就無法使用<br />
每一家都有他自己特殊的設定檔，其實是會造成混亂<br />
比較好的做法是例如說 L4 routing 這種比較常見的設定應該是由 Resource 來管理，而非依靠 Controller 自己的實作，所以 <strong><em>標準化是必要的</em></strong></p>

<p>而且 <code class="language-plaintext highlighter-rouge">Ingress</code> 需要開發者知道不同底層的設定與實作(例如 <a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 需要使用這個 annotation 達到某某功能而其他的則是另一個)<br />
身為 Application Developer 的我們其實根本不需要知道這些<br />
於是 Kubernetes 想要利用新的 API 來達到</p>
<ol>
  <li>更細緻的控制(L4 routing, TLS … etc.)</li>
  <li>提供標準化的接口(避免 vendor lock-in)</li>
  <li>Policy 權責分離</li>
</ol>

<p>稱之為 <code class="language-plaintext highlighter-rouge">Gateway API</code></p>

<h2 id="gateway-api">Gateway API</h2>
<p>但 <code class="language-plaintext highlighter-rouge">Gateway API</code> 其實一個統稱，他包含多個 Resource 如 <a href="#gatewayclass">GatewayClass</a>, <a href="#gateway">Gateway</a>, <a href="#route">HTTPRoute</a> 以及 <a href="#route">GRPCRoute</a><br />
分成不同的 Resource 其實是對應到不同的角色(權責分離)</p>

<h3 id="route">Route</h3>
<p>比如說身為應用程式開發者的我們其實比較在乎的是 <code class="language-plaintext highlighter-rouge">HTTPRoute</code> 以及 <code class="language-plaintext highlighter-rouge">GRPCRoute</code> 等等的<br />
底層要用什麼來實現(<a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 或者 <a href="#traefik-ingress-controller">Traefik Ingress Controller</a>)其實對我們來說沒差<br />
反正他會動就好了嘛</p>

<p>我只在乎，<code class="language-plaintext highlighter-rouge">/foo</code> 要導向 <code class="language-plaintext highlighter-rouge">whoami</code> 這個 service 的 80 port<br />
這才是重點</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">gateway.networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">HTTPRoute</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">http-app</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">parentRefs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-gateway</span>
  <span class="na">hostnames</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">whoami</span>
  <span class="na">rules</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">matches</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span>
            <span class="na">type</span><span class="pi">:</span> <span class="s">Exact</span>
            <span class="na">value</span><span class="pi">:</span> <span class="s">/foo</span>
      <span class="na">backendRefs</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">whoami</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="gatewayclass">GatewayClass</h3>
<p>那誰會在乎要底層用什麼來實現呢？<br />
肯定是管理 cluster 的人<br />
比方說我想要使用 <code class="language-plaintext highlighter-rouge">traefik.io/gateway-controller</code></p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">gateway.networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">GatewayClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-gateway-class</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">controllerName</span><span class="pi">:</span> <span class="s">traefik.io/gateway-controller</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="gateway">Gateway</h3>
<p>你指定了 <a href="#route">Route</a>，選定了 Ingress Controller(<a href="#gatewayclass">GatewayClass</a>)<br />
其實還有一個東西要指定，是進入集群的入口</p>

<p>這個設定有點陌生<br />
如果回顧 <a href="#from-service-to-ingress-controller">From Service to Ingress Controller</a> 的時候，你會發現<br />
即使在 <code class="language-plaintext highlighter-rouge">Ingress Resource</code> 裡面也沒有相對應的東西啊？</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-wildcard-host</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s2">"</span><span class="s">foo.bar.com"</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/bar"</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">service1</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s2">"</span><span class="s">*.foo.com"</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/foo"</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">service2</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>那這個集群的入口是什麼東西呢？<br />
你沒看到的原因在於 Ingress Controller 其實幫你做掉了<br />
舉 <a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 為例，根據 <a href="https://kubernetes.github.io/ingress-nginx/user-guide/basic-usage/">Basic usage - host based routing</a></p>

<blockquote>
  <p>On many cloud providers ingress-nginx will also create the corresponding Load Balancer resource.<br />
All you have to do is get the external IP and add a DNS A record inside your DNS provider that point myservicea.foo.org and myserviceb.foo.org to the nginx external IP.</p>
</blockquote>

<p>從上述你可以很清楚的看到說，所有的流量會先進到 Load Balancer Resource<br />
所以入口就是這個東西</p>

<p>如果以新的 API 來實作就是</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">gateway.networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Gateway</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-gateway</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">gatewayClassName</span><span class="pi">:</span> <span class="s">my-gateway-class</span>
  <span class="na">listeners</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">https</span>
  <span class="na">	  protocol</span><span class="pi">:</span> <span class="s">HTTPS</span>
  <span class="na">	  port</span><span class="pi">:</span> <span class="m">443</span>
<span class="err">  	</span>  <span class="na">tls</span><span class="pi">:</span>
        <span class="na">certificateRefs</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">kind</span><span class="pi">:</span> <span class="s">Secret</span>
        <span class="na">	name</span><span class="pi">:</span> <span class="s">mysecret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="put-it-all-together">Put it All Together</h3>
<p><img src="https://containous.ghost.io/content/images/size/w2400/2024/06/Traefik-Labs---Kubernetes-Gateway-API-resources---traffic-flow.jpg" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://traefik.io/glossary/kubernetes-gateway-api">Kubernetes Gateway API: What Is It and Why Do You Need It?</a></p>
</blockquote>

<p>你可以看到說，Gateway API 實際上是將每個東西都拆得很開<br />
根據不同的角色，各自維護他們所關心的東西</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Cluster Admin</code> 負責決定要使用哪一個 Ingress Controller 並指定於 <a href="#gatewayclass">GatewayClass</a></li>
  <li><code class="language-plaintext highlighter-rouge">Devops Team</code> 負責管理集群的入口並指定於 <a href="#gateway">Gateway</a></li>
  <li><code class="language-plaintext highlighter-rouge">Application Developer</code> 負責管理路由規則並指定於 <a href="#route">Route</a></li>
</ul>

<p>以前的 <code class="language-plaintext highlighter-rouge">Ingress</code> 把所有東西都放在一起<br />
他沒辦法很好的做到權責分離，<code class="language-plaintext highlighter-rouge">Application Developer</code> 只需要改一個 route<br />
但卻需要取得完整的設定檔，他有可能去動到其他東西，進而造成不必要的錯誤</p>

<h2 id="adoption-of-gateway-api">Adoption of Gateway API</h2>
<p>身為 <code class="language-plaintext highlighter-rouge">Ingress</code> 的後繼者，<code class="language-plaintext highlighter-rouge">Gateway API</code> 的進度卻不盡人意<br />
雖然新的標準立意良善並且修正了許多缺點，但一次性的 migration 是必須的<br />
俗話說的好，會動就不要動它，很顯然的這些優點並沒有說服開發者們進行升級</p>

<p>並且也不是現有的 Ingress Controller 都支援 <code class="language-plaintext highlighter-rouge">Gateway API</code><br />
舉例來說，<a href="#ingress-nginx-controller">Ingress Nginx Controller</a> 不支援 <code class="language-plaintext highlighter-rouge">Gateway API</code>(可參考 <a href="https://github.com/kubernetes/ingress-nginx/issues/13002">⚠️ Ingress NGINX Project Status Update ⚠️</a>)<br />
取而代之的是一個新的專案 <a href="https://github.com/kubernetes-sigs/ingate">kubernetes-sigs/ingate</a></p>

<p>更換新的 Ingress Controller 除了要升級 <code class="language-plaintext highlighter-rouge">Ingress</code> 到 <code class="language-plaintext highlighter-rouge">Gateway API</code> 之外<br />
Controller 的穩定性也是需要考慮的<br />
種種原因之下導致現在 <code class="language-plaintext highlighter-rouge">Gateway API</code> 的採用率並不高</p>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://www.vmware.com/topics/round-robin-load-balancing">Round Robin Load Balancing Definition</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">DNS for Services and Pods</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/">EndpointSlices</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a></li>
  <li><a href="https://www.reddit.com/r/kubernetes/comments/1kri73b/ingress_controller_v_gateway_api/">Ingress controller V Gateway API</a></li>
  <li><a href="https://www.reddit.com/r/kubernetes/comments/pa9jfg/im_a_newb_to_kubernetes_why_do_i_need/">I’m a newb to Kubernetes. Why do I need NGINX/Traefic/etc. ingress controllers?</a></li>
  <li><a href="https://github.com/kubernetes/ingress-nginx/blob/main/docs/how-it-works.md">How it works</a></li>
  <li><a href="https://stackoverflow.com/questions/43088363/how-nginx-reload-work-why-it-is-zero-downtime">How nginx reload work ? why it is zero-downtime</a></li>
  <li><a href="https://nginx.org/en/docs/control.html">https://nginx.org/en/docs/control.html</a></li>
  <li><a href="https://apisix.apache.org/zh/blog/2022/11/23/why-is-not-reload-hot-loaded-in-nginx/">为什么 NGINX 的 reload 不是热加载？</a></li>
  <li><a href="https://apisix.apache.org/blog/2022/07/30/why-we-need-apache-apisix/">Why do you need Apache APISIX when you have NGINX and Kong?</a></li>
  <li><a href="https://doc.traefik.io/traefik-enterprise/concepts/">Concepts</a></li>
  <li><a href="https://apisix.apache.org/zh/blog/2021/08/25/why-apache-apisix-chose-nginx-and-lua/">为什么 Apache APISIX 选择 NGINX+Lua 技术栈？</a></li>
  <li><a href="https://www.reddit.com/r/kubernetes/comments/1kri73b/ingress_controller_v_gateway_api/">Ingress controller V Gateway API</a></li>
  <li><a href="https://traefik.io/glossary/kubernetes-gateway-api">Kubernetes Gateway API: What Is It and Why Do You Need It?</a></li>
  <li><a href="https://kubernetes.github.io/ingress-nginx/user-guide/basic-usage/">Basic usage - host based routing</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/services-networking/gateway/#migrating-from-ingress">Gateway API</a></li>
  <li><a href="https://github.com/kubernetes/ingress-nginx/issues/13002">⚠️ Ingress NGINX Project Status Update ⚠️</a></li>
  <li><a href="https://www.cloudflare.com/zh-tw/learning/performance/types-of-load-balancing-algorithms/">負載平衡演算法類型</a></li>
  <li><a href="https://aws.amazon.com/what-is/load-balancing/">什麼是負載平衡？</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="kubernetes" /><category term="ingress" /><category term="egress" /><category term="inbound" /><category term="outbound" /><category term="load balancer" /><category term="nginx" /><category term="reverse proxy" /><category term="proxy" /><category term="round robin" /><category term="weighted round robin" /><category term="dns round robin" /><category term="least connection" /><category term="sticky session" /><category term="gateway api" /><category term="ingress nginx controller" /><category term="traefik ingress controller" /><category term="ingress controller" /><category term="gateway class" /><category term="gateway" /><category term="route" /><category term="httproute" /><category term="grpcroute" /><category term="nginx" /><category term="traefik" /><category term="apache apisix" /><category term="apisix" /><category term="kubernetes-sigs/ingate" /><category term="controller" /><category term="informer" /><category term="zero downtime" /><category term="endpointslice" /><category term="topology aware routing" /><category term="golang" /><category term="golang channel" /><category term="goroutine" /><category term="forward proxy" /><category term="reverse proxy" /><category term="service discovery" /><category term="l4" /><category term="l7" /><summary type="html"><![CDATA[Zero Downtime 需要各種機制來達成，其中一個就是路由管理。本篇文章將會從基本的 Kubernetes Service Discovery 機制開始，到為什麼你需要使用 Ingress Controller，參考各種不同 vendor 的實作理解 Downtime 的問題，最後引入新的 Gateway API 來嘗試解決這些問題]]></summary></entry><entry><title type="html">Kubernetes 從零開始 - 部署策略 101</title><link href="https://ambersuncreates.com/kubernetes/kubernetes-scale/" rel="alternate" type="text/html" title="Kubernetes 從零開始 - 部署策略 101" /><published>2025-09-24T00:00:00+08:00</published><updated>2025-10-10T21:45:50+08:00</updated><id>https://ambersuncreates.com/kubernetes/kubernetes-scale</id><content type="html" xml:base="https://ambersuncreates.com/kubernetes/kubernetes-scale/"><![CDATA[<h1 id="scaling-workloads">Scaling Workloads</h1>
<p>只有單台機器服務的情況下，多數是不足的<br />
因為你需要考量到，比如說服務突然的不可用(軟體錯誤、硬體故障等等的)，或者是流量真的大到一台機器處理不來的情況<br />
這時候你就會需要用到 “scaling” 的概念</p>

<p>在 <a href="../../database/database-distributed-database">資料庫 - 初探分散式資料庫 | Shawn Hsu</a> 中，我們有大概的看過一些概念</p>
<ul>
  <li><a href="#horizontal-pod-autoscalerhpa">scale out</a>
    <ul>
      <li>透過將 application 分散到不同的機器上面，解決單台機器硬體資源不足的問題</li>
    </ul>
  </li>
  <li><a href="#vertical-pod-autoscalervpa">scale up</a>
    <ul>
      <li>單純的增加單台機器上的硬體資源如 CPU, Memory 等等</li>
    </ul>
  </li>
</ul>

<p>如今的系統架構，基本上都使用 <a href="#horizontal-pod-autoscalerhpa">scale out</a> 的概念居多<br />
原因在於說，單台機器的硬體資源是有上限的，你的 CPU 跟 Memory 不可能無限增加，相反的，多台機器可以解決這個問題(你可以無限增加機器數量，把它連起來就好)</p>

<blockquote>
  <p><a href="https://pm2.keymetrics.io/">Node.js PM2</a> 的 cluster mode 也是利用了 scaling 的概念</p>
</blockquote>

<blockquote>
  <p>scale out 要注意的是，你的服務最好是 stateless 的<br />
stateful 其實也可以，只是資料一致性等等會是個滿大的問題<br />
而 HTTP server 基本上都是 stateless 的，所以你可以很輕鬆的 scale out</p>
</blockquote>

<blockquote>
  <p>還有一個很常見的誤區，monolithic 架構是可以 scale 的<br />
不是只有 microservice 架構可以 scale</p>
</blockquote>

<h2 id="manual-scaling">Manual Scaling</h2>
<p>有一個真實的例子是這樣子的<br />
行銷團隊預計在晚上的時候向使用者推播一個新消息<br />
然後訊息內容裡面包含一個到官網的連結，告訴使用者說官網全新改版</p>

<p>所以其實我們可以預期說，在晚上的時候網站的流量應該會增加，是比平常還要多的那種程度<br />
讓機器自己 scale 肯定是沒有問題的，但是我們都忽略了一個至關重要的細節<br />
也就是雲端自己把機器建立起來，執行起來是需要花時間的<br />
這個等待時間是致命的</p>

<p>因為可能第二台機器上線了，然後因為這個 delay，使用者早就看完並離開，流量又下去了<br />
然後他什麼也沒做就又被迫下線，然後使用者體驗到的是一個卡到爆的網站<br />
可能行銷帶來的效益就不是那麼足夠了</p>

<p>也因此，針對這種 <strong>已知會有流量增加的</strong> 的情況，比較好的方式是事先手動增加服務容量<br />
換句話說，在行銷團隊要發送推播的時候，工程團隊就必須先手動調整好伺服器的設定，用以應對接下來的流量<br />
這樣使用者體驗到的就會是流暢的服務</p>

<h2 id="auto-scaling">Auto Scaling</h2>
<p>相比之下，auto scaling 能夠自己根據目前不同的負載自動的調整所需要的資源</p>

<blockquote>
  <p>如果單純的 scale workloads 還無法滿足需求，那就需要進行 node 的 scale 了<br />
可以參考 <a href="https://kubernetes.io/docs/concepts/cluster-administration/node-autoscaling/">Node Autoscaling</a></p>
</blockquote>

<h3 id="horizontal-pod-autoscalerhpa">Horizontal Pod Autoscaler(HPA)</h3>
<p>在 Kubernetes 中，<code class="language-plaintext highlighter-rouge">scale out</code> 是透過 <code class="language-plaintext highlighter-rouge">Horizontal Pod Autoscaler(HPA)</code> 來實現的</p>

<p>HPA 是透過所謂的 control loop 去不定時的監控底下的資源(預設是 15 秒掃一次，但可以用 <code class="language-plaintext highlighter-rouge">--horizontal-pod-autoscaler-sync-period</code> 來調整)<br />
具體來說是，在 <code class="language-plaintext highlighter-rouge">HorizontalPodAutoscaler</code> CRD 裡面，指定說你要監聽的 resource 是哪一個(apiVersion, kind 跟 name)<br />
然後就看該 resource 的 metrics 做調整</p>

<blockquote>
  <p>對於那種不支援 scale 的 resource 如 <strong>DemonSet</strong> 是沒辦法使用 HPA 的</p>
</blockquote>

<p>更具體一點來說，他是根據 metrics 決定 replica 的數量的</p>

\[desiredReplicas = \lceil currentReplicas \times \frac{currentMetric}{desiredMetric} \rceil\]

<p>這個公式中，透過計算 metric 的比值決定你需不需要調整 replica 的數量<br />
完美的情況下，這個比值應該為 <strong><em>1</em></strong>，所以 desiredReplicas 會等於 currentReplicas<br />
而因為 metric 的資料是即時且不斷變化的，replica 數量會被一直調整<br />
造成所謂的 thrashing 現象(或稱 flapping)</p>

<blockquote>
  <p>flapping 的問題可以透過設定 <a href="#stabilization-window">Stabilization Window</a> 以及 <a href="#tolerance">Tolerance</a> 來調整</p>
</blockquote>

<h4 id="the-scaling-behavior">The Scaling Behavior</h4>
<p>要如何 scale 是個好問題<br />
replica 的數量如果忽高忽低，對底層的 infra 來說是一種負擔，何況是對使用者<br />
因此，在 HPA 裡面，你可以細部調整 K8s 要如何 scale<br />
具體來說，有 <a href="#scaling-policy">Scaling Policy</a>, <a href="#stabilization-window">Stabilization Window</a> 以及 <a href="#tolerance">Tolerance</a> 可以調整</p>

<h5 id="tolerance">Tolerance</h5>
<p><code class="language-plaintext highlighter-rouge">tolerance</code> 本質上就是允許一定程度的上下浮動<br />
讓 replica 的數量不會太過敏感<br />
預設情況下是 <code class="language-plaintext highlighter-rouge">10%</code> 的誤差範圍，可以透過 <code class="language-plaintext highlighter-rouge">--horizontal-pod-autoscaler-tolerance</code> 來調整<br />
或是 CRD 裡面直接指定 tolerance(可以參考 <a href="https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec">HorizontalPodAutoscalerSpec</a>)</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="na">behavior</span><span class="pi">:</span>
  <span class="na">scaleUp</span><span class="pi">:</span>
    <span class="na">tolerance</span><span class="pi">:</span> <span class="m">0.05</span> <span class="c1"># 5% tolerance for scale up</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h5 id="stabilization-window">Stabilization Window</h5>
<p><code class="language-plaintext highlighter-rouge">stabilization window</code> 也可以解決 flapping 的問題<br />
因為 metric 的資料不間斷變化會造成 Pod 的數量不斷的上下浮動<br />
既然數量會一直變化，其中的一個辦法是取一段時間區間，看說這段時間內，Pod 的數量如何<br />
HPA 的算法會在資料區間，取得 <strong><em>最高的 replica 數量</em></strong> 使用</p>

<p>為什麼是最高？</p>

<ul>
  <li>
    <p>如果流量一會高一會低，區間內最高值基本上就會是 <strong>持平</strong> 的趨勢<br />
也就是說 Pod 並不會突然的被刪掉又被加回來</p>
  </li>
  <li>
    <p>如果流量確實在減少，那麼計算出來的 desired replica count 肯定會隨著時間越來越少<br />
每一次的 evaluation 如果都取最高值，最終也會呈現 <strong>緩降</strong> 的趨勢<br />
如此一來便達到穩定的目的</p>
  </li>
</ul>

<blockquote>
  <p>stabilizationWindowSeconds 也可以設定 scaleUp 的狀況<br />
只是不太常這樣用，因為 scale up 就代表很緊急了(客訴滿天飛)，所以不需要穩定期</p>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="na">behavior</span><span class="pi">:</span>
  <span class="na">scaleDown</span><span class="pi">:</span>
    <span class="na">stabilizationWindowSeconds</span><span class="pi">:</span> <span class="m">300</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>可以在 CRD 裡面直接指定 stabilizationWindowSeconds(可以參考 <a href="https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec">HorizontalPodAutoscalerSpec</a>)</p>
</blockquote>

<h5 id="scaling-policy">Scaling Policy</h5>
<p>另外的 <code class="language-plaintext highlighter-rouge">scaling policy</code> 也同樣可以應用於 scaling 的調整<br />
有別於 <a href="#stabilization-window">Stabilization Window</a> 以及 <a href="#tolerance">Tolerance</a> 針對 replica 數量的決策<br />
policy 主要著墨在 “如何調整”</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="na">behavior</span><span class="pi">:</span>
  <span class="na">scaleDown</span><span class="pi">:</span>
    <span class="na">policies</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">Pods</span>
      <span class="na">value</span><span class="pi">:</span> <span class="m">4</span>
      <span class="na">periodSeconds</span><span class="pi">:</span> <span class="m">60</span>
    <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">Percent</span>
      <span class="na">value</span><span class="pi">:</span> <span class="m">10</span>
      <span class="na">periodSeconds</span><span class="pi">:</span> <span class="m">60</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>可以在 CRD 裡面直接指定 policies(可以參考 <a href="https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec">HorizontalPodAutoscalerSpec</a>)</p>
</blockquote>

<p>假設計算出來的 desired replica 是 100 但是當前只有 10<br />
意味著 90 個 Pod 要被啟動<br />
一次性啟動這麼多 Pod，雖然是合法的，但你其實不確定這會不會造成問題<br />
像我自己在本機跑 cluster 的時候，如果一次建立這麼多的 Pod，我是有感覺到電腦忽然變卡<br />
而這種穩定性問題是需要被重視的</p>

<p>既然不建議一次啟動這麼多 Pod，分批也是可行的選項<br />
所以這其實就是 <code class="language-plaintext highlighter-rouge">scaling policy</code> 要做的事情<br />
透過定義 “如何” 調整，穩定的 scale 才是我們想要的</p>

<p>上述例子中</p>
<ul>
  <li>policy[0] 代表著 60 秒內只能調整 4 個 Pod</li>
  <li>policy[1] 代表著 60 秒內只能調整總體 10% 的 Pod</li>
</ul>

<p>你可以針對 <code class="language-plaintext highlighter-rouge">scaleUp</code> 以及 <code class="language-plaintext highlighter-rouge">scaleDown</code> 分別指定不同的 policy<br />
然後如果你有多個 policies，可以額外設定 <code class="language-plaintext highlighter-rouge">.spec.behavior.scaleUp.selectPolicy</code> 決定要怎麼挑<br />
是要在眾多 policies 中挑選 <strong><em>影響最大還是最小的</em></strong>(Min, Max)，又或者是禁用調整(Disabled)呢？</p>

<blockquote>
  <p>預設 selectPolicy 會挑影響最大的，也就是 <code class="language-plaintext highlighter-rouge">Max</code></p>
</blockquote>

<h4 id="metric-data">Metric Data</h4>
<p>稍早在 <a href="#horizontal-pod-autoscalerhpa">Horizontal Pod Autoscaler(HPA)</a> 提到，replica 數量是透過 metric 來決定的<br />
可是還是很抽象，究竟要監聽什麼呢？<br />
更具體的來說，你可以使用以下這些資源</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Resource</code>
    <ul>
      <li>一個最基本的判斷方式就是使用 CPU, Memory 的資源去判斷需不需要 scale<br />
  每個 scale target 底層一定都是執行 Pod，每個 Pod 用的資源都不一樣，多個 Pod 的資源會被 <strong>平均起來</strong> 計算進而得出 current metric
        <blockquote>
          <p>不過，由於他會被平均起來，所以有可能總體是足夠的，但其中某個 Pod 累得半死也是有可能的</p>
        </blockquote>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">ContainerResource</code>
    <ul>
      <li>為了避免 Pod 平均帶來的誤差，你也可以指定在 container level 計算<br />
  其他都跟 <code class="language-plaintext highlighter-rouge">Resource</code> 一樣，只不過是看 scale target 底下的 Pod 底下的 container<br />
  而且也都是會被平均起來算出 current metric</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Pods</code>
    <ul>
      <li>我們稍早都是在看 CPU, Memory 的資源，那有沒有其他資源可以使用呢？<br />
  答案也是肯定的，只不過需要客製化(可以參考 <a href="#metrics-apis">Metrics APIs</a>)<br />
  計算方式也一樣，會被平均起來做比較</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Object</code>
    <ul>
      <li>這種類型比較特別，他是監聽 <strong><em>single Kubernetes object</em></strong> 的 metric<br />
  文件上的例子是 Ingress 的 hits-per-second<br />
  在建立路由的時候，你的規則是定義在 Ingress Object 內，配合 <a href="#metrics-apis">Metrics APIs</a> 可以搭配查詢說有多少流量進來</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">External</code>
    <ul>
      <li>這種類型比較特別，他是監聽 <strong><em>external resource</em></strong> 的 metric<br />
  外部指的就是說，這個 metric 不是 Kubernetes 內建的，而是你自行定義的<br />
  比方說，consumer 的數是由 message queue 內部的資料數量決定，而當然他也是需要 <a href="#metrics-apis">Metrics APIs</a> 的配合</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>可以參考 <code class="language-plaintext highlighter-rouge">$ kubectl explain hpa.spec.metrics</code></p>
</blockquote>

<p>公式裡的 current metric 已經定義好了<br />
剩下的 desired metric 就相對簡單了</p>

\[desiredReplicas = \lceil currentReplicas \times \frac{currentMetric}{desiredMetric} \rceil\]

<p>就三種類型</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">averageUtilization</code>: 平均的數字(百分比)</li>
  <li><code class="language-plaintext highlighter-rouge">averageValue</code>: 平均的數字</li>
  <li><code class="language-plaintext highlighter-rouge">value</code>: 單純的數字，沒有平均過的數值(適用於 <code class="language-plaintext highlighter-rouge">Object</code> 這種，比方說計算 hits-per-second 的時候)</li>
</ul>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">Resource</code> 搭配 <code class="language-plaintext highlighter-rouge">averageUtilization</code> 會變成平均的平均嗎？<br />
是 current metric 先平均，得到 A 這個平均值，然後跟 desired metric 的平均值 B 相比較</p>
</blockquote>

<blockquote>
  <p>可以參考 <code class="language-plaintext highlighter-rouge">$ kubectl explain hpa.spec.metrics.{metric_type}.target</code></p>
</blockquote>

<h5 id="metrics-apis">Metrics APIs</h5>
<p>我們知道了要監聽什麼，監聽的資料從哪來又是個問題<br />
HPA controller 是透過 Metrics API 取得資料的<br />
而以下的設定是必要的</p>
<ol>
  <li><a href="https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/">API Aggregation Layer</a> 需要被啟用</li>
  <li>Metrics API 需要被啟用。基本上來說，分成三大種
    <ul>
      <li><code class="language-plaintext highlighter-rouge">resource metrics</code>: 基本上資料會從 <a href="https://github.com/kubernetes-sigs/metrics-server">metrics server</a> 取得，資料內容會是 K8s object 的資料</li>
      <li><code class="language-plaintext highlighter-rouge">custom metrics</code>: 但是如果你需要自己客製化資料，就是 custom metrics。注意到他還是使用 K8s object 的資料</li>
      <li><code class="language-plaintext highlighter-rouge">external metrics</code>: 客製化，但是是外部的資料</li>
    </ul>
  </li>
</ol>

<p>舉例來說 <a href="https://github.com/kubernetes-sigs/prometheus-adapter">kubernetes-sigs/prometheus-adapter</a> 裡面包含了 custom metrics 以及 external metrics 的實現</p>

<h4 id="summary">Summary</h4>
<p>HPA 的概念稍微複雜許多，你需要搞清楚不同資源下需要的設定檔是哪一種<br />
並且需要意識到在 scaling 的過程中可能產生的問題<br />
東西蠻多，需要多多消化</p>

<h3 id="vertical-pod-autoscalervpa">Vertical Pod Autoscaler(VPA)</h3>
<p>在 Kubernetes 中，<code class="language-plaintext highlighter-rouge">scale up</code>(調整 Pod 的資源，比如說 CPU 跟 Memory) 是透過 <code class="language-plaintext highlighter-rouge">Vertical Pod Autoscaler(VPA)</code> 來實現的<br />
VPA 並非內建的，是需要額外安裝的(<a href="https://github.com/kubernetes/autoscaler/tree/9f87b78df0f1d6e142234bb32e8acbd71295585a/vertical-pod-autoscaler">kubernetes/autoscaler</a>)</p>

<p>VPA 會需要額外的 <a href="https://github.com/kubernetes-sigs/metrics-server">metrics server</a> 取得目前的資源使用情況<br />
使用的部分，你會需要撰寫 <code class="language-plaintext highlighter-rouge">VerticalPodAutoscaler</code> 的 CRD 來實現<br />
然後再 CRD 內部，指定你要監聽的 Resource 是什麼，比如說這個例子會是 <code class="language-plaintext highlighter-rouge">hamster</code></p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
</pre></td><td class="rouge-code"><pre><span class="c1"># This config creates a deployment with two pods, each requesting 100 millicores</span>
<span class="c1"># and trying to utilize slightly above 500 millicores (repeatedly using CPU for</span>
<span class="c1"># 0.5s and sleeping 0.5s).</span>
<span class="c1"># It also creates a corresponding Vertical Pod Autoscaler that adjusts the</span>
<span class="c1"># requests.</span>
<span class="c1"># Note that the update mode is left unset, so it defaults to "Auto" mode.</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">autoscaling.k8s.io/v1"</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VerticalPodAutoscaler</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hamster-vpa</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="c1"># recommenders field can be unset when using the default recommender.</span>
  <span class="c1"># When using an alternative recommender, the alternative recommender's name</span>
  <span class="c1"># can be specified as the following in a list.</span>
  <span class="c1"># recommenders: </span>
  <span class="c1">#   - name: 'alternative'</span>
  <span class="na">targetRef</span><span class="pi">:</span>
    <span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">apps/v1"</span>
    <span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">hamster</span>
  <span class="na">resourcePolicy</span><span class="pi">:</span>
    <span class="na">containerPolicies</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">containerName</span><span class="pi">:</span> <span class="s1">'</span><span class="s">*'</span>
        <span class="na">minAllowed</span><span class="pi">:</span>
          <span class="na">cpu</span><span class="pi">:</span> <span class="s">100m</span>
          <span class="na">memory</span><span class="pi">:</span> <span class="s">50Mi</span>
        <span class="na">maxAllowed</span><span class="pi">:</span>
          <span class="na">cpu</span><span class="pi">:</span> <span class="m">1</span>
          <span class="na">memory</span><span class="pi">:</span> <span class="s">500Mi</span>
        <span class="na">controlledResources</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">cpu"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">memory"</span><span class="pi">]</span>
    <span class="na">updatePolicy</span><span class="pi">:</span>
      <span class="na">updateMode</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Auto"</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hamster</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">hamster</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">2</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">hamster</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">securityContext</span><span class="pi">:</span>
        <span class="na">runAsNonRoot</span><span class="pi">:</span> <span class="no">true</span>
        <span class="na">runAsUser</span><span class="pi">:</span> <span class="m">65534</span> <span class="c1"># nobody</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">hamster</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">registry.k8s.io/ubuntu-slim:0.1</span>
          <span class="na">resources</span><span class="pi">:</span>
            <span class="na">requests</span><span class="pi">:</span>
              <span class="na">cpu</span><span class="pi">:</span> <span class="s">100m</span>
              <span class="na">memory</span><span class="pi">:</span> <span class="s">50Mi</span>
          <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">/bin/sh"</span><span class="pi">]</span>
          <span class="na">args</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">-c"</span>
            <span class="pi">-</span> <span class="s2">"</span><span class="s">while</span><span class="nv"> </span><span class="s">true;</span><span class="nv"> </span><span class="s">do</span><span class="nv"> </span><span class="s">timeout</span><span class="nv"> </span><span class="s">0.5s</span><span class="nv"> </span><span class="s">yes</span><span class="nv"> </span><span class="s">&gt;/dev/null;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">0.5s;</span><span class="nv"> </span><span class="s">done"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>當你執行以上 Deployment 與 VPA 之後，過一陣子你會發現到，你的 Pod 的資源使用情況會被 VPA 調整<br />
注意到是 Pod 的 resources 被調整，而非 Deployment 的 resources 被調整</p>

<h4 id="vpa-operate-mode">VPA Operate Mode</h4>
<p>上述的例子中你可以看到 VPA 有所謂的運作模式</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Mode</th>
      <th style="text-align: left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Off</code></td>
      <td style="text-align: left">VPA 不會調整 Pod 的資源</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Initial</code></td>
      <td style="text-align: left">VPA 會在 <strong>資源建立的當下</strong> 調整 Pod 的資源，之後不會調整</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Recreate</code></td>
      <td style="text-align: left">會動態的調整資源，不論是建立還是更新都是 <strong>重新建立</strong> 新的 Pod</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Auto</code></td>
      <td style="text-align: left">目前是 Recreate Operate Mode</td>
    </tr>
  </tbody>
</table>

<p>重新建立 Pod 這個行為有可能會影響到你應用程式的執行，所以他其實沒有那麼的適合<br />
於是 Kubernetes VPA 團隊正在整合 <strong>In-place Pod Vertical Scaling</strong> 的技術<br />
旨在不重新建立 Pod 的情況下調整其資源</p>

<blockquote>
  <p>恩？ 整合？<br />
Kubernetes 本身已經有支援 Pod 的資源的 In-place 調整(可以參考 <a href="#resize-container-resources">Resize Container Resources</a>)<br />
也就是說其實 Pod 的資源的 In-place 調整已經支援了，只是 VPA 的整合還沒有完成</p>
</blockquote>

<h4 id="resize-container-resources">Resize Container Resources</h4>
<p>具體來說，Pod 的資源可以不需要重新啟動就可以調整資源<br />
事實上在 Kubernetes 早在 <code class="language-plaintext highlighter-rouge">1.27</code> 中引入了 <code class="language-plaintext highlighter-rouge">InPlacePodVerticalScaling</code> feature gate<br />
並於 <code class="language-plaintext highlighter-rouge">1.33</code> 正式進入 <code class="language-plaintext highlighter-rouge">beta</code> 階段</p>

<blockquote>
  <p>然後 kubectl 也需要至少 <code class="language-plaintext highlighter-rouge">v1.32</code> 才能使用 <code class="language-plaintext highlighter-rouge">--subresource=resize</code> 這個參數</p>
</blockquote>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl get <span class="nt">--raw</span> /metrics | <span class="nb">grep </span>InPlacePodVerticalScaling
kubernetes_feature_enabled<span class="o">{</span><span class="nv">name</span><span class="o">=</span><span class="s2">"InPlacePodVerticalScaling"</span>,stage<span class="o">=</span><span class="s2">"ALPHA"</span><span class="o">}</span> 0
</pre></td></tr></tbody></table></code></pre></div></div>

<p>所以要怎麼 resize 資源呢？</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl patch pod resize-demo <span class="nt">--subresource</span> resize <span class="nt">--patch</span> <span class="se">\</span>
  <span class="s1">'{"spec":{"containers":[{"name":"pause", "resources":{"requests":{"cpu":"800m"}, "limits":{"cpu":"800m"}}}]}}'</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>或者是直接 <code class="language-plaintext highlighter-rouge">apply -f --subresource resize --server-side</code> 會比較直覺</p>
</blockquote>

<p>同一時間你會需要所謂的 resize policy<br />
一個新定義的欄位 <code class="language-plaintext highlighter-rouge">spec.containers[].resizePolicy</code></p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="na">resizePolicy</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">resourceName</span><span class="pi">:</span> <span class="s">cpu</span>
  <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">NotRequired</span>
<span class="pi">-</span> <span class="na">resourceName</span><span class="pi">:</span> <span class="s">memory</span>
  <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">RestartContainer</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>以上兩個資源的 restartPolicy 不一樣的情況下<br />
會 fallback 成 <code class="language-plaintext highlighter-rouge">RestartContainer</code>，一個要重啟一個不要，那當然就是重啟囉(比較嚴格的 policy)</p>
</blockquote>

<p>目前來說，Kubernetes 1.34 含以前，你只能更改 <code class="language-plaintext highlighter-rouge">cpu</code> 以及 <code class="language-plaintext highlighter-rouge">memory</code> 的資源<br />
然後指定要不要進行重啟，如果沒指定，預設會是 <code class="language-plaintext highlighter-rouge">NotRequired</code><br />
會需要重啟的原因，比如說你的 application 需要重啟才能拿到更多 memory 之類的</p>

<blockquote>
  <p>而這個重啟很有意思的是，如果 Pod 等級的 <code class="language-plaintext highlighter-rouge">restartPolicy</code> 是 <code class="language-plaintext highlighter-rouge">Never</code><br />
在 <code class="language-plaintext highlighter-rouge">resizePolicy.restartPolicy</code> 就 <strong>只能指定為</strong> <code class="language-plaintext highlighter-rouge">NotRequired</code><br />
resize 要重啟但是 Pod 不重啟顯然這樣會衝突<br />
<br />
init container 這種沒辦法重啟的是無法使用 resize 功能的(但是 sidecar 可以，可參考 <a href="../../kubernetes/kubernetes-sidecar">Kubernetes 從零開始 - Sidecar 與 Lifecycle Hook 組合技 | Shawn Hsu</a>)</p>
</blockquote>

<p>不過這個 resize 的要求很大程度上是看目前的狀態而定<br />
不能說你要求了 1 個 CPU，結果現在只有 0.5 個 CPU，這樣是不行的<br />
你可以根據 Pod 回給你的狀態來確認這件事情</p>

<p>Pod status condition 的內容會有以下新增</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">PodResizePending</code> type
    <ul>
      <li>kubelet 已經確認了你的要求，但不能馬上滿足，根據 <code class="language-plaintext highlighter-rouge">message</code> 的內容你可以確切地知道為什麼會 pending</li>
      <li><code class="language-plaintext highlighter-rouge">message</code>
        <ul>
          <li><code class="language-plaintext highlighter-rouge">reason: Infeasible</code>: :arrow_right: 你的要求根本不可能滿足(比方說你要求的 CPU 資源超過該節點的總量)</li>
          <li><code class="language-plaintext highlighter-rouge">reason: Deferred</code> :arrow_right: 你的要求目前不可能滿足，但我可以重試(我把某某 Pod 刪掉就可以滿足你的需求之類的)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">PodResizeInProgress</code> type
    <ul>
      <li>kubelet 已經確認你的要求並且正在調動資源，如果有出什麼意外，也會在 <code class="language-plaintext highlighter-rouge">message</code> 中告訴你</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/posts/resize1.png" alt="" /></p>

<p>你會發現說，其實上面的狀態也不夠，因為完成是不會有狀態的，上述只會跟你講失敗的情況<br />
所以另外一個欄位 <code class="language-plaintext highlighter-rouge">status.observedGeneration</code> 被引入了(他是 <code class="language-plaintext highlighter-rouge">PodObservedGenerationTracking</code> feature gate，於 <code class="language-plaintext highlighter-rouge">1.33</code> 引入)<br />
generation 的目的是在於紀錄每一次的改動(i.e. <code class="language-plaintext highlighter-rouge">metadata.generation</code>)<br />
而 <code class="language-plaintext highlighter-rouge">status.observedGeneration</code> 則是紀錄 kubelet 已經確認並完成的 generation</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><code class="language-plaintext highlighter-rouge">.metadata.generation</code></th>
      <th style="text-align: center"><code class="language-plaintext highlighter-rouge">.status.observedGeneration</code> 以及 <code class="language-plaintext highlighter-rouge">.status.conditions[].observedGeneration</code></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/posts/generation1.png" alt="" /></td>
      <td style="text-align: center"><img src="/assets/img/posts/generation2.png" alt="" /></td>
    </tr>
  </tbody>
</table>

<p>如果你更改的 resource 間接改動到 QOS class 也是不行的</p>

<p><img src="/assets/img/posts/qos.png" alt="" /></p>

<blockquote>
  <p>簡單來說，Quality of Service(QOS) Class 會根據 <code class="language-plaintext highlighter-rouge">requests</code>, <code class="language-plaintext highlighter-rouge">limits</code> 以及 container 的數量來決定<br />
所以說你更改 resource 可能會間接改動到 QOS class</p>
</blockquote>

<blockquote>
  <p>可以用以下指令開一台 cluster 來測試</p>
  <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>k3d cluster create mycluster <span class="se">\</span>
    <span class="nt">--image</span> rancher/k3s:v1.33.4-k3s1 <span class="se">\</span>
    <span class="nt">--k3s-arg</span> <span class="s1">'--kube-apiserver-arg=feature-gates=PodObservedGenerationTracking=true@server:*'</span> <span class="se">\</span>
    <span class="nt">--k3s-arg</span> <span class="s1">'--kube-apiserver-arg=feature-gates=InPlacePodVerticalScaling=true@server:*'</span> <span class="se">\</span>
    <span class="nt">--k3s-arg</span> <span class="s1">'--kubelet-arg=feature-gates=InPlacePodVerticalScaling=true@agent:*'</span> <span class="se">\</span>
    <span class="nt">--k3s-arg</span> <span class="s1">'--kubelet-arg=feature-gates=PodObservedGenerationTracking=true@agent:*'</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>
</blockquote>

<h3 id="event-driven-autoscaling">Event Driven Autoscaling</h3>
<p>利用 <a href="https://github.com/kedacore/keda">Kubernetes-based Event Driven Autoscaling</a> 可以實現 event based 的自動擴展<br />
比方說可以根據 message queue 內的資料量、API 請求數量或是 <a href="https://github.com/kubernetes-sigs/metrics-server">metrics server</a> 提供的資訊等等所謂 <a href="https://keda.sh/docs/2.17/scalers/">Scalers</a> 來自動擴展</p>

<p>KEDA 並不是用來取代 <a href="#horizontal-pod-autoscalerhpa">HPA</a> 或是 <a href="#vertical-pod-autoscalervpa">VPA</a>，而是用來補足他們的不足<br />
這個工具能夠提供多樣化的 scaler 讓你根據不同的資源進行調節<br />
所以 KEDA 是沒辦法自己獨立運行的</p>

<p>更甚至你可以利用 KEDA 做到 off-peak hour 的調整<br />
就是比如說，在晚上的時候因為大家都在睡覺，所以上網的人可能會比較少，然後你就可以把資源降低<br />
KEDA 的 <a href="https://keda.sh/docs/2.17/scalers/cron/">Cron Scaler</a> 就滿適合的</p>

<blockquote>
  <p>Scaler 其實有很多種，包含我有看到 Redis, Kafka, PostgreSQL 等等的<br />
你甚至可以自己客製化 scaler</p>
</blockquote>

<h1 id="different-deployment-strategies">Different Deployment Strategies</h1>
<p>現在的服務基本上講究一個 zero downtime，要給使用者不間斷的服務<br />
而為了達成這個目標，部署策略就需要經過設計</p>

<p>最簡單的部署方式就是停機維護<br />
而停機維護是相對不友善的選擇，卻也是對開發者最友善的模式<br />
龐大的資料升級，資料庫遷移等等的，停機維護可以將所有的風險降到最低<br />
雖然仍然有辦法達成 zero downtime，但這部分的操作會需要團隊更細心的安排與規劃</p>

<blockquote>
  <p>有關 migration 可以參考 <a href="../../database/database-migration">資料庫 - 新手做 Data Migration 資料遷移 | Shawn Hsu</a></p>
</blockquote>

<p>比較保險的方式會是擁有多台機器逐台更新，也就是要求你的服務具備一定 scaling 的能力<br />
因為至少在你更新 A 機器的時候，BCD 依然可以服務使用者<br />
多台機器的情況下事情就變得有趣了，你會有不同的策略比如說 <a href="#canary-deployment">Canary Deployment</a> 或者 <a href="#blue-green-deployment">Blue Green Deployment</a></p>

<h2 id="recreate-and-rolling-update">Recreate and Rolling Update</h2>
<p>停機維護最主要是指你的系統沒辦法兼容兩個不同版本同時運行<br />
因為他有可能使用的 database schema 不同，同時運行會造成資料毀損等問題<br />
次要則是一些比如說底層作業系統更新、網路設備更新抑或是硬體設備維修更新等等<br />
雖然通常這會比較偏向 <code class="language-plaintext highlighter-rouge">排程維護更新</code> 的範疇，但廣義上仍然是屬於 <code class="language-plaintext highlighter-rouge">Recreate</code>(因為服務對使用者不可用)</p>

<p>與 <code class="language-plaintext highlighter-rouge">Recreate</code> 會造成所謂的 downtime 不同，<code class="language-plaintext highlighter-rouge">Rolling Update</code> 則是會確保系統一直是可用的狀態<br />
我們提到，多台機器逐步更新是這類操作的關鍵，因為有不同機器繼續撐著運行，在使用者的角度看來，系統依然是可用的<br />
使用 <code class="language-plaintext highlighter-rouge">Rolling Update</code> 需要確保你的系統有做好 “向後相容” 或 “向前相容” 的設計<br />
這樣才能確保在更新過程中，系統依然可以正常運行</p>

<p>在 Kubernetes 中，你可以透過設定 <code class="language-plaintext highlighter-rouge">spec.strategy.type</code> 來決定使用哪種策略</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Recreate</code>: 先砍再建</li>
  <li><code class="language-plaintext highlighter-rouge">RollingUpdate</code>: 邊建邊砍
    <ul>
      <li>你也可以控制新舊 Pod 的數量，目的在於確保在更新過程中，系統依然可以正常運行
        <ul>
          <li><code class="language-plaintext highlighter-rouge">spec.strategy.rollingUpdate.maxSurge</code> 表示最多可以 <strong>比原本多出多少 Pod</strong>(預設 25%, 至多 125% 的 Pod 會是可用的)</li>
          <li><code class="language-plaintext highlighter-rouge">spec.strategy.rollingUpdate.maxUnavailable</code> 表示最多可以有多少 Pod <strong>不可用</strong>(預設 25%, 至少 75% 的 Pod 會是可用的)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>預設的策略會是 <code class="language-plaintext highlighter-rouge">RollingUpdate</code></p>
</blockquote>

<p>他執行起來會長這樣<br />
你可以很清楚的看出他的差別，Rolling Update 的過程中，系統依然是可用的<br />
而 Recreate 的過程中，系統是不可用的(全部都下去)</p>

<blockquote>
  <p>Recreate 即使下線的時間很短，仍然會造成影響，因此也視為有 downtime</p>
</blockquote>

<p><img src="/assets/img/posts/rolling.gif" alt="" /></p>

<p><img src="/assets/img/posts/recreate.gif" alt="" /></p>

<h2 id="canary-deployment">Canary Deployment</h2>
<p>基本上 Rolling Update 是相對常見的策略<br />
逐步的更新你的服務，使得其永遠可用</p>

<blockquote>
  <p>Rolling Update 的 use case，比方説我公司內部開發機的更新就是直接 rolling 上去，反正掛了也是內部不可用而已</p>
</blockquote>

<p>但這個可用其實是相對薄弱的<br />
你的服務是起來的，並不代表他有好好工作<br />
比方說，服務內部有一個 bug, 他並不會讓服務直接掛掉，但是會造成結果錯誤<br />
這種時候如果 Liveness 以及 Readiness 沒有設定好，就會造成 silent error<br />
這並不是我們樂見的</p>

<blockquote>
  <p>有關 Liveness 以及 Readiness 可以參考 <a href="../../kubernetes/kubernetes-self-healing">Kubernetes 從零開始 - Self Healing 是如何運作的 | Shawn Hsu</a></p>
</blockquote>

<p>我們當然不希望全部都上了之後才發現有問題<br />
最簡單的就是分流囉，有多套版本的服務，一部分的人用新的，一部分的用舊的<br />
<code class="language-plaintext highlighter-rouge">少部分的人先使用新版本，如果都沒有問題，逐步開放至全部使用者</code> 是 Canary Deployment 的精髓<br />
所以同一時間會有不同版本的服務在線上，透過 <strong>分流機制</strong> 將部分使用者導向新版本<br />
為了避免 silent error 這種事情，分流可以很好的限縮錯誤範圍，當發現新版本有問題，影響也會是最小的</p>

<p>同一時間多版本在線上服務，一個重點是要確保服務本身是 <strong>向後相容的</strong><br />
不然你的資料會損毀，而這是最不想發生的狀況<br />
預先執行資料遷移是個選擇，或者是用 <a href="#blue-green-deployment">Blue Green Deployment</a> 來達成</p>

<blockquote>
  <p>有關 data migration 可以參考 <a href="../../database/database-migration">資料庫 - 新手做 Data Migration 資料遷移 | Shawn Hsu</a></p>
</blockquote>

<h2 id="blue-green-deployment">Blue Green Deployment</h2>
<p>他跟 <a href="#canary-deployment">Canary Deployment</a> 類似都是使用多版本的部署策略</p>

<p>差別在於，<code class="language-plaintext highlighter-rouge">Blue Green</code> 是一瞬間切換的<br />
他 <strong><em>並不是逐步更新</em></strong>，而是將流量瞬間切換到新版本的系統上<br />
所以你其實沒辦法小規模測試</p>

<p>因為不想要有多個資料來源，所以 <code class="language-plaintext highlighter-rouge">Blue Green</code> 事實上是維護兩套完全獨立的系統<br />
一套舊系統(<code class="language-plaintext highlighter-rouge">Blue</code>)，一套新系統(<code class="language-plaintext highlighter-rouge">Green</code>)，兩者獨立運行<br />
等到你確定新版本沒問題之後，更改路由設定，將全部的流量都導入新版本</p>

<!-- TODO ingress post -->

<p>你可能會問，兩套系統運行，那資料要怎麼同步？<br />
最終的目的都是減少 downtime, 而 Blue Green 的舊系統會繼續服務<br />
為了新系統切換的時候資料是近新的，所以通常會用 <em>Kafka</em> 之類的進行資料同步</p>

<blockquote>
  <p>有關 Kafka 可以參考 <a href="../../database/database-message-queue">資料庫 - 從 Apache Kafka 認識 Message Queue | Shawn Hsu</a></p>
</blockquote>

<blockquote>
  <p>有關 data migration 可以參考 <a href="../../database/database-migration">資料庫 - 新手做 Data Migration 資料遷移 | Shawn Hsu</a></p>
</blockquote>

<h2 id="ab-testing">A/B Testing</h2>
<p>另外一種部署策略我覺得是比較特殊的<br />
他的目的不在於發布新的系統，而是為了測試方面的部署策略</p>

<p>A/B Testing 的目的，是 <em>藉由部署不同的系統版本，窺探使用者的反應</em><br />
當然，還是有新版本的系統被部署，只是要注意他的本質是 <strong>測試</strong><br />
比方說，有新版本的 UI，你想要知道使用者對於新版本的 UI 的反應如何<br />
所以可以將 Ingress 的流量分切，讓小部分的人體驗新功能，搭配個問卷調查之類的</p>
<ul>
  <li>8 成的人依舊是使用舊版本</li>
  <li>而 2 成的人是使用新版本</li>
</ul>

<p>當你測試完成之後，再把流量復原然後就可以根據測試結果決定後續</p>

<h2 id="shadow-deployment">Shadow Deployment</h2>
<p>Shadow 類似於 <a href="#a-b-testing">A/B Testing</a>，只是他不需要分流<br />
他也是用於測試，只不過是將 production 流量複製一份出來測試<br />
這樣的好處就是你可以很直接的觀察新版本的表現，而 <em>完全不會影響到舊版本</em><br />
response 則會全部被丟棄</p>

<h2 id="conclusion">Conclusion</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Strategy</th>
      <th style="text-align: right"><a href="#recreate-and-rolling-update">Recreate</a></th>
      <th style="text-align: right"><a href="#recreate-and-rolling-update">Rolling Update</a></th>
      <th style="text-align: right"><a href="#blue-green-deployment">Blue Green Deployment</a></th>
      <th style="text-align: right"><a href="#canary-deployment">Canary Deployment</a></th>
      <th style="text-align: right"><a href="#a-b-testing">A/B Testing</a></th>
      <th style="text-align: right"><a href="#shadow-deployment">Shadow Deployment</a></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Purpose</td>
      <td style="text-align: right">部署</td>
      <td style="text-align: right">部署</td>
      <td style="text-align: right">部署</td>
      <td style="text-align: right">部署</td>
      <td style="text-align: right">測試</td>
      <td style="text-align: right">測試</td>
    </tr>
    <tr>
      <td style="text-align: left">Downtime</td>
      <td style="text-align: right">:heavy_check_mark:</td>
      <td style="text-align: right">:x:</td>
      <td style="text-align: right">:x:</td>
      <td style="text-align: right">:x:</td>
      <td style="text-align: right"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: left">Risk Level</td>
      <td style="text-align: right">High</td>
      <td style="text-align: right">Medium</td>
      <td style="text-align: right">Low</td>
      <td style="text-align: right">Low</td>
      <td style="text-align: right">Low</td>
      <td style="text-align: right">Low</td>
    </tr>
    <tr>
      <td style="text-align: left">Rollback Difficulty</td>
      <td style="text-align: right">High</td>
      <td style="text-align: right">Medium</td>
      <td style="text-align: right">Low</td>
      <td style="text-align: right">Low</td>
      <td style="text-align: right">Low</td>
      <td style="text-align: right">Low</td>
    </tr>
    <tr>
      <td style="text-align: left">Release Unit</td>
      <td style="text-align: right">完整服務</td>
      <td style="text-align: right">單台機器</td>
      <td style="text-align: right">兩個不同環境</td>
      <td style="text-align: right">部分流量</td>
      <td style="text-align: right">部分流量</td>
      <td style="text-align: right">複製流量</td>
    </tr>
  </tbody>
</table>

<h1 id="how-kubernetes-handle-deployment-strategy">How Kubernetes Handle Deployment Strategy</h1>
<p>上述我們提到的部署策略中，有一些是同時部署兩個版本然後透過分流的方式達成<br />
在 Kubernetes 中，如果不考慮其他的工具，基本上依靠 Service 就可以做到八成像了</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="na">name</span><span class="pi">:</span> <span class="s">frontend</span>
<span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
<span class="nn">...</span>
<span class="na">labels</span><span class="pi">:</span>
  <span class="na">app</span><span class="pi">:</span> <span class="s">guestbook</span>
  <span class="na">tier</span><span class="pi">:</span> <span class="s">frontend</span>
  <span class="na">track</span><span class="pi">:</span> <span class="s">stable</span>
<span class="nn">...</span>
<span class="na">image</span><span class="pi">:</span> <span class="s">gb-frontend:v3</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="na">name</span><span class="pi">:</span> <span class="s">frontend-canary</span>
<span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
<span class="nn">...</span>
<span class="na">labels</span><span class="pi">:</span>
  <span class="na">app</span><span class="pi">:</span> <span class="s">guestbook</span>
  <span class="na">tier</span><span class="pi">:</span> <span class="s">frontend</span>
  <span class="na">track</span><span class="pi">:</span> <span class="s">canary</span>
<span class="nn">...</span>
<span class="na">image</span><span class="pi">:</span> <span class="s">gb-frontend:v4</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>上述兩個不同的 Deployment 分別對應到新舊版本的應用程式(v3 以及 v4)<br />
然後在 label 的部分，你可以看到他有共享相同的 label(i.e. <code class="language-plaintext highlighter-rouge">frontend</code> 以及 <code class="language-plaintext highlighter-rouge">guestbook</code>)<br />
在 Service 的部分就可以使用這些相同的 label 選取<br />
就能夠達成基本的分流，以 replica 的數量來判斷就是 <code class="language-plaintext highlighter-rouge">3:1</code> 的流量</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="na">selector</span><span class="pi">:</span>
   <span class="na">app</span><span class="pi">:</span> <span class="s">guestbook</span>
   <span class="na">tier</span><span class="pi">:</span> <span class="s">frontend</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="argo-rollouts">Argo Rollouts</h2>
<p>就如同我們上述討論的，Kubernetes 內建的 Rollout 功能雖然強大但是仍然有許多改進空間<br />
比如說</p>
<ol>
  <li>沒辦法控制 Rollout 的速度</li>
  <li>Liveness 以及 Readiness 沒辦法做更深度且全面的檢查</li>
  <li>沒辦法依靠外部 Metrics 衡量更新</li>
</ol>

<p>基於以上考量點，實務上在正式環境內部還是有太多的隱患存在<br />
所以 <a href="https://argoproj.github.io/rollouts/">Argo Rollouts</a> 正是為了解決以上痛點而誕生的</p>

<p>本質上也是透過 Kubernetes Controller 以及 <a href="#rollout-crd">CRD</a> 來實現的<br />
比如說 <a href="#rollout-crd">Rollout CRD</a> 就是 Deployment 的包裝，並且額外提供了一些功能<br />
前面提到 <a href="#blue-green-deployment">Blue Green Deployment</a> 以及 <a href="#canary-deployment">Canary Deployment</a> 都是有支援的，但是也只支援這兩個</p>

<blockquote>
  <p>有關 CRD 可以參考 <a href="../../kubernetes/kubernetes-crd">Kubernetes 從零開始 - client-go 實操 CRD | Shawn Hsu</a></p>
</blockquote>

<blockquote>
  <p>有關 Kubernetes Controller 可以參考 <a href="../../kubernetes/kubernetes-controller-concept">Kubernetes 從零開始 - Informer 架構以及 Controller Pattern | Shawn Hsu</a></p>
</blockquote>

<h3 id="architecture">Architecture</h3>
<p><img src="https://argoproj.github.io/argo-rollouts/architecture-assets/argo-rollout-architecture.png" alt="" /></p>
<blockquote>
  <p>ref: <a href="https://argoproj.github.io/argo-rollouts/architecture/">Architecture</a></p>
</blockquote>

<p>基本上如果你熟悉 Kubernetes Controller 的運作方式，就不難理解<br />
本質上，Controller 會監聽 <code class="language-plaintext highlighter-rouge">Rollout CRD</code> 的任何變化，並根據其內容調整相對應的資源<br />
前面提到，雖然說他是包裝 Deployment，但是 Controller 並不會對原生 Deployment 有任何反應</p>

<blockquote>
  <p>有關 Kubernetes Controller 可以參考 <a href="../../kubernetes/kubernetes-controller-concept">Kubernetes 從零開始 - Informer 架構以及 Controller Pattern | Shawn Hsu</a></p>
</blockquote>

<p>也跟 Deployment 一樣，底層 Argo Rollouts 會使用 ReplicaSet 來管理 Pod<br />
為了能方便管理不同的版本，一些額外的 metadata 以及 labels 會被套用上去<br />
並且需要搭配 Service 進行分流(Controller 會指派 unique hash 確保選擇到正確的 ReplicaSet)，Service Mesh 或者 Ingress 的 solution 如 <a href="https://traefik.io/traefik/">Traefik</a>、<a href="https://kubernetes.github.io/ingress-nginx/">Nginx Ingress Controller</a> 或 <a href="https://istio.io/">Istio</a> 等等也可以搭配使用</p>

<p>另外你也可以將 Metrics 整合進來，檢查 Rollout 的狀態</p>

<h3 id="rollout-crd">Rollout CRD</h3>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">argoproj.io/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Rollout</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">example-rollout-canary</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="c1"># Number of desired pods.</span>
  <span class="c1"># Defaults to 1.</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">5</span>
  <span class="na">analysis</span><span class="pi">:</span>
    <span class="c1"># limits the number of successful analysis runs and experiments to be stored in a history</span>
    <span class="c1"># Defaults to 5.</span>
    <span class="na">successfulRunHistoryLimit</span><span class="pi">:</span> <span class="m">10</span>
    <span class="c1"># limits the number of unsuccessful analysis runs and experiments to be stored in a history.</span>
    <span class="c1"># Stages for unsuccessful: "Error", "Failed", "Inconclusive"</span>
    <span class="c1"># Defaults to 5.</span>
    <span class="na">unsuccessfulRunHistoryLimit</span><span class="pi">:</span> <span class="m">10</span>

  <span class="c1"># Label selector for pods. Existing ReplicaSets whose pods are selected by</span>
  <span class="c1"># this will be the ones affected by this rollout. It must match the pod</span>
  <span class="c1"># template's labels.</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">guestbook</span>

  <span class="c1"># WorkloadRef holds a references to a workload that provides Pod template</span>
  <span class="c1"># (e.g. Deployment). If used, then do not use Rollout template property.</span>
  <span class="na">workloadRef</span><span class="pi">:</span>
    <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
    <span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">rollout-ref-deployment</span>
    <span class="c1"># Specifies if the workload (Deployment) is scaled down after migrating to Rollout.</span>
    <span class="c1"># The possible options are:</span>
    <span class="c1"># "never": the Deployment is not scaled down</span>
    <span class="c1"># "onsuccess": the Deployment is scaled down after the Rollout becomes healthy</span>
    <span class="c1"># "progressively": as the Rollout is scaled up the Deployment is scaled down</span>
    <span class="c1"># If the Rollout fails the Deployment will be scaled back up.</span>
    <span class="na">scaleDown</span><span class="pi">:</span> <span class="s">never|onsuccess|progressively</span>

  <span class="c1"># Template describes the pods that will be created. Same as deployment.</span>
  <span class="c1"># If used, then do not use Rollout workloadRef property.</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">guestbook</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">argoproj/rollouts-demo:blue</span>

  <span class="c1"># Minimum number of seconds for which a newly created pod should be ready</span>
  <span class="c1"># without any of its container crashing, for it to be considered available.</span>
  <span class="c1"># Defaults to 0 (pod will be considered available as soon as it is ready)</span>
  <span class="na">minReadySeconds</span><span class="pi">:</span> <span class="m">30</span>

  <span class="c1"># The number of old ReplicaSets to retain.</span>
  <span class="c1"># Defaults to 10</span>
  <span class="na">revisionHistoryLimit</span><span class="pi">:</span> <span class="m">3</span>

  <span class="c1"># Pause allows a user to manually pause a rollout at any time. A rollout</span>
  <span class="c1"># will not advance through its steps while it is manually paused, but HPA</span>
  <span class="c1"># auto-scaling will still occur. Typically not explicitly set the manifest,</span>
  <span class="c1"># but controlled via tools (e.g. kubectl argo rollouts pause). If true at</span>
  <span class="c1"># initial creation of Rollout, replicas are not scaled up automatically</span>
  <span class="c1"># from zero unless manually promoted.</span>
  <span class="na">paused</span><span class="pi">:</span> <span class="no">true</span>

  <span class="c1"># The maximum time in seconds in which a rollout must make progress during</span>
  <span class="c1"># an update, before it is considered to be failed. Argo Rollouts will</span>
  <span class="c1"># continue to process failed rollouts and a condition with a</span>
  <span class="c1"># ProgressDeadlineExceeded reason will be surfaced in the rollout status.</span>
  <span class="c1"># Note that progress will not be estimated during the time a rollout is</span>
  <span class="c1"># paused.</span>
  <span class="c1"># Defaults to 600s</span>
  <span class="na">progressDeadlineSeconds</span><span class="pi">:</span> <span class="m">600</span>

  <span class="c1"># Whether to abort the update when ProgressDeadlineSeconds is exceeded.</span>
  <span class="c1"># Optional and default is false.</span>
  <span class="na">progressDeadlineAbort</span><span class="pi">:</span> <span class="no">false</span>

  <span class="c1"># UTC timestamp in which a Rollout should sequentially restart all of</span>
  <span class="c1"># its pods. Used by the `kubectl argo rollouts restart ROLLOUT` command.</span>
  <span class="c1"># The controller will ensure all pods have a creationTimestamp greater</span>
  <span class="c1"># than or equal to this value.</span>
  <span class="na">restartAt</span><span class="pi">:</span> <span class="s1">'</span><span class="s">2020-03-30T21:19:35Z'</span>

  <span class="c1"># The rollback window provides a way to fast track deployments to</span>
  <span class="c1"># previously deployed versions.</span>
  <span class="c1"># Optional, and by default is not set.</span>
  <span class="na">rollbackWindow</span><span class="pi">:</span>
    <span class="na">revisions</span><span class="pi">:</span> <span class="m">3</span>

  <span class="na">strategy</span><span class="pi">:</span>
    <span class="c1"># Blue-green update strategy</span>
    <span class="na">blueGreen</span><span class="pi">:</span>
      <span class="c1"># Reference to service that the rollout modifies as the active service.</span>
      <span class="c1"># Required.</span>
      <span class="na">activeService</span><span class="pi">:</span> <span class="s">active-service</span>

      <span class="c1"># Pre-promotion analysis run which performs analysis before the service</span>
      <span class="c1"># cutover. +optional</span>
      <span class="na">prePromotionAnalysis</span><span class="pi">:</span>
        <span class="na">templates</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">templateName</span><span class="pi">:</span> <span class="s">success-rate</span>
        <span class="na">args</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">service-name</span>
            <span class="na">value</span><span class="pi">:</span> <span class="s">guestbook-svc.default.svc.cluster.local</span>

      <span class="c1"># Post-promotion analysis run which performs analysis after the service</span>
      <span class="c1"># cutover. +optional</span>
      <span class="na">postPromotionAnalysis</span><span class="pi">:</span>
        <span class="na">templates</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">templateName</span><span class="pi">:</span> <span class="s">success-rate</span>
        <span class="na">args</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">service-name</span>
            <span class="na">value</span><span class="pi">:</span> <span class="s">guestbook-svc.default.svc.cluster.local</span>

      <span class="c1"># Name of the service that the rollout modifies as the preview service.</span>
      <span class="c1"># +optional</span>
      <span class="na">previewService</span><span class="pi">:</span> <span class="s">preview-service</span>

      <span class="c1"># The number of replicas to run under the preview service before the</span>
      <span class="c1"># switchover. Once the rollout is resumed the new ReplicaSet will be fully</span>
      <span class="c1"># scaled up before the switch occurs +optional</span>
      <span class="na">previewReplicaCount</span><span class="pi">:</span> <span class="m">1</span>

      <span class="c1"># Indicates if the rollout should automatically promote the new ReplicaSet</span>
      <span class="c1"># to the active service or enter a paused state. If not specified, the</span>
      <span class="c1"># default value is true. +optional</span>
      <span class="na">autoPromotionEnabled</span><span class="pi">:</span> <span class="no">false</span>

      <span class="c1"># Automatically promotes the current ReplicaSet to active after the</span>
      <span class="c1"># specified pause delay in seconds after the ReplicaSet becomes ready.</span>
      <span class="c1"># If omitted, the Rollout enters and remains in a paused state until</span>
      <span class="c1"># manually resumed by resetting spec.Paused to false. +optional</span>
      <span class="na">autoPromotionSeconds</span><span class="pi">:</span> <span class="m">30</span>

      <span class="c1"># Adds a delay before scaling down the previous ReplicaSet. If omitted,</span>
      <span class="c1"># the Rollout waits 30 seconds before scaling down the previous ReplicaSet.</span>
      <span class="c1"># A minimum of 30 seconds is recommended to ensure IP table propagation</span>
      <span class="c1"># across the nodes in a cluster.</span>
      <span class="na">scaleDownDelaySeconds</span><span class="pi">:</span> <span class="m">30</span>

      <span class="c1"># Limits the number of old RS that can run at once before getting scaled</span>
      <span class="c1"># down. Defaults to nil</span>
      <span class="na">scaleDownDelayRevisionLimit</span><span class="pi">:</span> <span class="m">2</span>

      <span class="c1"># Add a delay in second before scaling down the preview replicaset</span>
      <span class="c1"># if update is aborted. 0 means not to scale down. Default is 30 second</span>
      <span class="na">abortScaleDownDelaySeconds</span><span class="pi">:</span> <span class="m">30</span>

      <span class="c1"># Anti Affinity configuration between desired and previous ReplicaSet.</span>
      <span class="c1"># Only one must be specified</span>
      <span class="na">antiAffinity</span><span class="pi">:</span>
        <span class="na">requiredDuringSchedulingIgnoredDuringExecution</span><span class="pi">:</span> <span class="pi">{}</span>
        <span class="na">preferredDuringSchedulingIgnoredDuringExecution</span><span class="pi">:</span>
          <span class="na">weight</span><span class="pi">:</span> <span class="m">1</span> <span class="c1"># Between 1 - 100</span>

      <span class="c1"># activeMetadata will be merged and updated in-place into the ReplicaSet's spec.template.metadata</span>
      <span class="c1"># of the active pods. +optional</span>
      <span class="na">activeMetadata</span><span class="pi">:</span>
        <span class="na">labels</span><span class="pi">:</span>
          <span class="na">role</span><span class="pi">:</span> <span class="s">active</span>

      <span class="c1"># Metadata which will be attached to the preview pods only during their preview phase.</span>
      <span class="c1"># +optional</span>
      <span class="na">previewMetadata</span><span class="pi">:</span>
        <span class="na">labels</span><span class="pi">:</span>
          <span class="na">role</span><span class="pi">:</span> <span class="s">preview</span>

    <span class="c1"># Canary update strategy</span>
    <span class="na">canary</span><span class="pi">:</span>
      <span class="c1"># Reference to a service which the controller will update to select</span>
      <span class="c1"># canary pods. Required for traffic routing.</span>
      <span class="na">canaryService</span><span class="pi">:</span> <span class="s">canary-service</span>

      <span class="c1"># Reference to a service which the controller will update to select</span>
      <span class="c1"># stable pods. Required for traffic routing.</span>
      <span class="na">stableService</span><span class="pi">:</span> <span class="s">stable-service</span>

      <span class="c1"># Metadata which will be attached to the canary pods. This metadata will</span>
      <span class="c1"># only exist during an update, since there are no canary pods in a fully</span>
      <span class="c1"># promoted rollout.</span>
      <span class="na">canaryMetadata</span><span class="pi">:</span>
        <span class="na">annotations</span><span class="pi">:</span>
          <span class="na">role</span><span class="pi">:</span> <span class="s">canary</span>
        <span class="na">labels</span><span class="pi">:</span>
          <span class="na">role</span><span class="pi">:</span> <span class="s">canary</span>

      <span class="c1"># metadata which will be attached to the stable pods</span>
      <span class="na">stableMetadata</span><span class="pi">:</span>
        <span class="na">annotations</span><span class="pi">:</span>
          <span class="na">role</span><span class="pi">:</span> <span class="s">stable</span>
        <span class="na">labels</span><span class="pi">:</span>
          <span class="na">role</span><span class="pi">:</span> <span class="s">stable</span>

      <span class="c1"># The maximum number of pods that can be unavailable during the update.</span>
      <span class="c1"># Value can be an absolute number (ex: 5) or a percentage of total pods</span>
      <span class="c1"># at the start of update (ex: 10%). Absolute number is calculated from</span>
      <span class="c1"># percentage by rounding down. This can not be 0 if  MaxSurge is 0. By</span>
      <span class="c1"># default, a fixed value of 1 is used. Example: when this is set to 30%,</span>
      <span class="c1"># the old RC can be scaled down by 30% immediately when the rolling</span>
      <span class="c1"># update starts. Once new pods are ready, old RC can be scaled down</span>
      <span class="c1"># further, followed by scaling up the new RC, ensuring that at least 70%</span>
      <span class="c1"># of original number of pods are available at all times during the</span>
      <span class="c1"># update. +optional</span>
      <span class="na">maxUnavailable</span><span class="pi">:</span> <span class="m">1</span>

      <span class="c1"># The maximum number of pods that can be scheduled above the original</span>
      <span class="c1"># number of pods. Value can be an absolute number (ex: 5) or a</span>
      <span class="c1"># percentage of total pods at the start of the update (ex: 10%). This</span>
      <span class="c1"># can not be 0 if MaxUnavailable is 0. Absolute number is calculated</span>
      <span class="c1"># from percentage by rounding up. By default, a value of 1 is used.</span>
      <span class="c1"># Example: when this is set to 30%, the new RC can be scaled up by 30%</span>
      <span class="c1"># immediately when the rolling update starts. Once old pods have been</span>
      <span class="c1"># killed, new RC can be scaled up further, ensuring that total number</span>
      <span class="c1"># of pods running at any time during the update is at most 130% of</span>
      <span class="c1"># original pods. +optional</span>
      <span class="na">maxSurge</span><span class="pi">:</span> <span class="s1">'</span><span class="s">20%'</span>

      <span class="c1"># Adds a delay before scaling down the previous ReplicaSet when the</span>
      <span class="c1"># canary strategy is used with traffic routing (default 30 seconds).</span>
      <span class="c1"># A delay in scaling down the previous ReplicaSet is needed after</span>
      <span class="c1"># switching the stable service selector to point to the new ReplicaSet,</span>
      <span class="c1"># in order to give time for traffic providers to re-target the new pods.</span>
      <span class="c1"># This value is ignored with basic, replica-weighted canary without</span>
      <span class="c1"># traffic routing.</span>
      <span class="na">scaleDownDelaySeconds</span><span class="pi">:</span> <span class="m">30</span>

      <span class="c1"># The minimum number of pods that will be requested for each ReplicaSet</span>
      <span class="c1"># when using traffic routed canary. This is to ensure high availability</span>
      <span class="c1"># of each ReplicaSet. Defaults to 1. +optional</span>
      <span class="na">minPodsPerReplicaSet</span><span class="pi">:</span> <span class="m">2</span>

      <span class="c1"># Limits the number of old RS that can run at one time before getting</span>
      <span class="c1"># scaled down. Defaults to nil</span>
      <span class="na">scaleDownDelayRevisionLimit</span><span class="pi">:</span> <span class="m">2</span>

      <span class="c1"># Background analysis to run during a rollout update. Skipped upon</span>
      <span class="c1"># initial deploy of a rollout. +optional</span>
      <span class="na">analysis</span><span class="pi">:</span>
        <span class="na">templates</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">templateName</span><span class="pi">:</span> <span class="s">success-rate</span>
        <span class="na">args</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">service-name</span>
            <span class="na">value</span><span class="pi">:</span> <span class="s">guestbook-svc.default.svc.cluster.local</span>

          <span class="c1"># valueFrom.podTemplateHashValue is a convenience to supply the</span>
          <span class="c1"># rollouts-pod-template-hash value of either the Stable ReplicaSet</span>
          <span class="c1"># or the Latest ReplicaSet</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">stable-hash</span>
            <span class="na">valueFrom</span><span class="pi">:</span>
              <span class="na">podTemplateHashValue</span><span class="pi">:</span> <span class="s">Stable</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">latest-hash</span>
            <span class="na">valueFrom</span><span class="pi">:</span>
              <span class="na">podTemplateHashValue</span><span class="pi">:</span> <span class="s">Latest</span>

          <span class="c1"># valueFrom.fieldRef allows metadata about the rollout to be</span>
          <span class="c1"># supplied as arguments to analysis.</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">region</span>
            <span class="na">valueFrom</span><span class="pi">:</span>
              <span class="na">fieldRef</span><span class="pi">:</span>
                <span class="na">fieldPath</span><span class="pi">:</span> <span class="s">metadata.labels['region']</span>

      <span class="c1"># Steps define sequence of steps to take during an update of the</span>
      <span class="c1"># canary. Skipped upon initial deploy of a rollout. +optional</span>
      <span class="na">steps</span><span class="pi">:</span>
        <span class="c1"># Sets the ratio of canary ReplicaSet to 20%</span>
        <span class="pi">-</span> <span class="na">setWeight</span><span class="pi">:</span> <span class="m">20</span>

        <span class="c1"># Pauses the rollout for an hour. Supported units: s, m, h</span>
        <span class="pi">-</span> <span class="na">pause</span><span class="pi">:</span>
            <span class="na">duration</span><span class="pi">:</span> <span class="s">1h</span>

        <span class="c1"># Pauses indefinitely until manually resumed</span>
        <span class="pi">-</span> <span class="na">pause</span><span class="pi">:</span> <span class="pi">{}</span>

        <span class="c1"># set canary scale to an explicit count without changing traffic weight</span>
        <span class="c1"># (supported only with trafficRouting)</span>
        <span class="pi">-</span> <span class="na">setCanaryScale</span><span class="pi">:</span>
            <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>

        <span class="c1"># set canary scale to spec.Replica * (setweight / maxTrafficWeight) without changing traffic weight</span>
        <span class="c1"># if maxTrafficWeight unspecified, it defaults to 100</span>
        <span class="c1"># (supported only with trafficRouting)</span>
        <span class="pi">-</span> <span class="na">setCanaryScale</span><span class="pi">:</span>
            <span class="na">weight</span><span class="pi">:</span> <span class="m">25</span>

        <span class="c1"># set canary scale to match the canary traffic weight (default behavior)</span>
        <span class="pi">-</span> <span class="na">setCanaryScale</span><span class="pi">:</span>
            <span class="na">matchTrafficWeight</span><span class="pi">:</span> <span class="no">true</span>

        <span class="c1"># The percentage or number of replica pods within the applications ReplicaSet</span>
        <span class="c1"># that are available and ready when a rollout is ready to be promoted. Useful if your application</span>
        <span class="c1"># configured an HPA to help handle different loads of traffic, but you still want quick promotions.</span>
        <span class="c1"># Defaults to 100% if replicaProgressThreshold is not specified.</span>
        <span class="c1"># The 'type' field should be either "Percent" | "Pod"</span>
        <span class="c1"># Current percentage that is checked against the input percent value is calculated by the following:</span>
        <span class="c1"># CURRENT PERCENTAGE = available replicas / desired replicas for the current step</span>
        <span class="c1"># +optional</span>
        <span class="pi">-</span> <span class="na">replicaProgressThreshold</span><span class="pi">:</span>
            <span class="na">type</span><span class="pi">:</span> <span class="s">Percent</span>
            <span class="na">value</span><span class="pi">:</span> <span class="m">90</span>


        <span class="c1"># executes the configured plugin by name with the provided configuration</span>
        <span class="pi">-</span> <span class="na">plugin</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">example</span>
            <span class="na">config</span><span class="pi">:</span>
              <span class="na">key</span><span class="pi">:</span> <span class="s">value</span>

        <span class="c1"># Sets header based route with specified header values</span>
        <span class="c1"># Setting header based route will send all traffic to the canary for the requests</span>
        <span class="c1"># with a specified header, in this case request header "version":"2"</span>
        <span class="c1"># (supported only with trafficRouting, for Istio only at the moment)</span>
        <span class="pi">-</span> <span class="na">setHeaderRoute</span><span class="pi">:</span>
            <span class="c1"># Name of the route that will be created by argo rollouts this must also be configured</span>
            <span class="c1"># in spec.strategy.canary.trafficRouting.managedRoutes</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">header-route-1'</span>
            <span class="c1"># The matching rules for the header route, if this is missing it acts as a removal of the route.</span>
            <span class="na">match</span><span class="pi">:</span>
              <span class="c1"># headerName The name of the header to apply the match rules to.</span>
              <span class="pi">-</span> <span class="na">headerName</span><span class="pi">:</span> <span class="s1">'</span><span class="s">version'</span>
                <span class="c1"># headerValue must contain exactly one field of exact, regex, or prefix. Not all traffic routers support</span>
                <span class="c1"># all types</span>
                <span class="na">headerValue</span><span class="pi">:</span>
                  <span class="c1"># Exact will only match if the header value is exactly the same</span>
                  <span class="na">exact</span><span class="pi">:</span> <span class="s1">'</span><span class="s">2'</span>
                  <span class="c1"># Will match the rule if the regular expression matches</span>
                  <span class="na">regex</span><span class="pi">:</span> <span class="s1">'</span><span class="s">2.0.(.*)'</span>
                  <span class="c1"># prefix will be a prefix match of the header value</span>
                  <span class="na">prefix</span><span class="pi">:</span> <span class="s1">'</span><span class="s">2.0'</span>

          <span class="c1"># Sets up a mirror/shadow based route with the specified match rules</span>
          <span class="c1"># The traffic will be mirrored at the configured percentage to the canary service</span>
          <span class="c1"># during the rollout</span>
          <span class="c1"># (supported only with trafficRouting, for Istio only at the moment)</span>
        <span class="pi">-</span> <span class="na">setMirrorRoute</span><span class="pi">:</span>
            <span class="c1"># Name of the route that will be created by argo rollouts this must also be configured</span>
            <span class="c1"># in spec.strategy.canary.trafficRouting.managedRoutes</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">header-route-1'</span>
            <span class="c1"># The percentage of the matched traffic to mirror to the canary</span>
            <span class="na">percentage</span><span class="pi">:</span> <span class="m">100</span>
            <span class="c1"># The matching rules for the header route, if this is missing it acts as a removal of the route.</span>
            <span class="c1"># All conditions inside a single match block have AND semantics, while the list of match blocks have OR semantics.</span>
            <span class="c1"># Each type within a match (method, path, headers) must have one and only one match type (exact, regex, prefix)</span>
            <span class="c1"># Not all match types (exact, regex, prefix) will be supported by all traffic routers.</span>
            <span class="na">match</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="c1"># What HTTP method to match</span>
                  <span class="na">exact</span><span class="pi">:</span> <span class="s1">'</span><span class="s">GET'</span>
                  <span class="na">regex</span><span class="pi">:</span> <span class="s1">'</span><span class="s">P.*'</span>
                  <span class="na">prefix</span><span class="pi">:</span> <span class="s1">'</span><span class="s">POST'</span>
                <span class="na">path</span><span class="pi">:</span> <span class="c1"># What HTTP url paths to match.</span>
                  <span class="na">exact</span><span class="pi">:</span> <span class="s1">'</span><span class="s">/test'</span>
                  <span class="na">regex</span><span class="pi">:</span> <span class="s1">'</span><span class="s">/test/.*'</span>
                  <span class="na">prefix</span><span class="pi">:</span> <span class="s1">'</span><span class="s">/'</span>
                <span class="na">headers</span><span class="pi">:</span>
                  <span class="na">agent-1b</span><span class="pi">:</span> <span class="c1"># What HTTP header name to use in the match.</span>
                    <span class="na">exact</span><span class="pi">:</span> <span class="s1">'</span><span class="s">firefox'</span>
                    <span class="na">regex</span><span class="pi">:</span> <span class="s1">'</span><span class="s">firefox2(.*)'</span>
                    <span class="na">prefix</span><span class="pi">:</span> <span class="s1">'</span><span class="s">firefox'</span>

        <span class="c1"># an inline analysis step</span>
        <span class="pi">-</span> <span class="na">analysis</span><span class="pi">:</span>
            <span class="na">templates</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">templateName</span><span class="pi">:</span> <span class="s">success-rate</span>

        <span class="c1"># an inline experiment step</span>
        <span class="pi">-</span> <span class="na">experiment</span><span class="pi">:</span>
            <span class="na">duration</span><span class="pi">:</span> <span class="s">1h</span>
            <span class="na">templates</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">baseline</span>
                <span class="na">specRef</span><span class="pi">:</span> <span class="s">stable</span>
                <span class="c1"># optional, creates a service for the experiment if set</span>
                <span class="na">service</span><span class="pi">:</span>
                  <span class="c1"># optional, service: {} is also acceptable if name is not included</span>
                  <span class="na">name</span><span class="pi">:</span> <span class="s">test-service</span>
              <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">canary</span>
                <span class="na">specRef</span><span class="pi">:</span> <span class="s">canary</span>
                <span class="c1"># optional, set the weight of traffic routed to this version</span>
                <span class="na">weight</span><span class="pi">:</span> <span class="m">10</span>
            <span class="na">analyses</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">mann-whitney</span>
                <span class="na">templateName</span><span class="pi">:</span> <span class="s">mann-whitney</span>
                <span class="c1"># Metadata which will be attached to the AnalysisRun.</span>
                <span class="na">analysisRunMetadata</span><span class="pi">:</span>
                  <span class="na">labels</span><span class="pi">:</span>
                    <span class="na">app.service.io/analysisType</span><span class="pi">:</span> <span class="s">smoke-test</span>
                  <span class="na">annotations</span><span class="pi">:</span>
                    <span class="na">link.argocd.argoproj.io/external-link</span><span class="pi">:</span> <span class="s">http://my-loggin-platform.com/pre-generated-link</span>

      <span class="c1"># Anti-affinity configuration between desired and previous ReplicaSet.</span>
      <span class="c1"># Only one must be specified.</span>
      <span class="na">antiAffinity</span><span class="pi">:</span>
        <span class="na">requiredDuringSchedulingIgnoredDuringExecution</span><span class="pi">:</span> <span class="pi">{}</span>
        <span class="na">preferredDuringSchedulingIgnoredDuringExecution</span><span class="pi">:</span>
          <span class="na">weight</span><span class="pi">:</span> <span class="m">1</span> <span class="c1"># Between 1 - 100</span>

      <span class="c1"># Traffic routing specifies the ingress controller or service mesh</span>
      <span class="c1"># configuration to achieve advanced traffic splitting. If omitted,</span>
      <span class="c1"># will achieve traffic split via a weighted replica counts between</span>
      <span class="c1"># the canary and stable ReplicaSet.</span>
      <span class="na">trafficRouting</span><span class="pi">:</span>
        <span class="c1"># Supports nginx and plugins only: This lets you control the denominator or total weight of traffic.</span>
        <span class="c1"># The total weight of traffic. If unspecified, it defaults to 100</span>
        <span class="na">maxTrafficWeight</span><span class="pi">:</span> <span class="m">1000</span>
        <span class="c1"># This is a list of routes that Argo Rollouts has the rights to manage it is currently only required for</span>
        <span class="c1"># setMirrorRoute and setHeaderRoute. The order of managedRoutes array also sets the precedence of the route</span>
        <span class="c1"># in the traffic router. Argo Rollouts will place these routes in the order specified above any routes already</span>
        <span class="c1"># defined in the used traffic router if something exists. The names here must match the names from the</span>
        <span class="c1"># setHeaderRoute and setMirrorRoute steps.</span>
        <span class="na">managedRoutes</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">set-header</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">mirror-route</span>
        <span class="c1"># Istio traffic routing configuration</span>
        <span class="na">istio</span><span class="pi">:</span>
          <span class="c1"># Either virtualService or virtualServices can be configured.</span>
          <span class="na">virtualService</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">rollout-vsvc</span> <span class="c1"># required</span>
            <span class="na">routes</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="s">primary</span> <span class="c1"># optional if there is a single route in VirtualService, required otherwise</span>
          <span class="na">virtualServices</span><span class="pi">:</span>
            <span class="c1"># One or more virtualServices can be configured</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">rollouts-vsvc1</span> <span class="c1"># required</span>
              <span class="na">routes</span><span class="pi">:</span>
                <span class="pi">-</span> <span class="s">primary</span> <span class="c1"># optional if there is a single route in VirtualService, required otherwise</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">rollouts-vsvc2</span> <span class="c1"># required</span>
              <span class="na">routes</span><span class="pi">:</span>
                <span class="pi">-</span> <span class="s">secondary</span> <span class="c1"># optional if there is a single route in VirtualService, required otherwise</span>

        <span class="c1"># NGINX Ingress Controller routing configuration</span>
        <span class="na">nginx</span><span class="pi">:</span>
          <span class="c1"># Either stableIngress or stableIngresses must be configured, but not both.</span>
          <span class="na">stableIngress</span><span class="pi">:</span> <span class="s">primary-ingress</span>
          <span class="na">stableIngresses</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="s">primary-ingress</span>
            <span class="pi">-</span> <span class="s">secondary-ingress</span>
            <span class="pi">-</span> <span class="s">tertiary-ingress</span>
          <span class="na">annotationPrefix</span><span class="pi">:</span> <span class="s">customingress.nginx.ingress.kubernetes.io</span> <span class="c1"># optional</span>
          <span class="na">additionalIngressAnnotations</span><span class="pi">:</span> <span class="c1"># optional</span>
            <span class="na">canary-by-header</span><span class="pi">:</span> <span class="s">X-Canary</span>
            <span class="na">canary-by-header-value</span><span class="pi">:</span> <span class="s">iwantsit</span>
          <span class="na">canaryIngressAnnotations</span><span class="pi">:</span> <span class="c1"># optional</span>
            <span class="na">my-custom-annotation.mygroup.com/key</span><span class="pi">:</span> <span class="s">value</span>

        <span class="c1"># ALB Ingress Controller routing configuration</span>
        <span class="na">alb</span><span class="pi">:</span>
          <span class="na">ingress</span><span class="pi">:</span> <span class="s">ingress</span> <span class="c1"># required</span>
          <span class="na">servicePort</span><span class="pi">:</span> <span class="m">443</span> <span class="c1"># required</span>
          <span class="na">annotationPrefix</span><span class="pi">:</span> <span class="s">custom.alb.ingress.kubernetes.io</span> <span class="c1"># optional</span>

        <span class="c1"># Service Mesh Interface routing configuration</span>
        <span class="na">smi</span><span class="pi">:</span>
          <span class="na">rootService</span><span class="pi">:</span> <span class="s">root-svc</span> <span class="c1"># optional</span>
          <span class="na">trafficSplitName</span><span class="pi">:</span> <span class="s">rollout-example-traffic-split</span> <span class="c1"># optional</span>

      <span class="c1"># Add a delay in second before scaling down the canary pods when update</span>
      <span class="c1"># is aborted for canary strategy with traffic routing (not applicable for basic canary).</span>
      <span class="c1"># 0 means canary pods are not scaled down. Default is 30 seconds.</span>
      <span class="na">abortScaleDownDelaySeconds</span><span class="pi">:</span> <span class="m">30</span>

      <span class="c1"># Automatically reduce the number of stable pods as the number of canary pods increases</span>
      <span class="c1"># Only available when traffic routing is used. Default value is false meaning that as more canary pods</span>
      <span class="c1"># are created the number of stable pods stays the same. </span>
      <span class="na">dynamicStableScale</span><span class="pi">:</span> <span class="no">false</span>

<span class="na">status</span><span class="pi">:</span>
  <span class="na">pauseConditions</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">reason</span><span class="pi">:</span> <span class="s">StepPause</span>
      <span class="na">startTime</span><span class="pi">:</span> <span class="s">2019-10-00T1234</span>
    <span class="pi">-</span> <span class="na">reason</span><span class="pi">:</span> <span class="s">BlueGreenPause</span>
      <span class="na">startTime</span><span class="pi">:</span> <span class="s">2019-10-00T1234</span>
    <span class="pi">-</span> <span class="na">reason</span><span class="pi">:</span> <span class="s">AnalysisRunInconclusive</span>
      <span class="na">startTime</span><span class="pi">:</span> <span class="s">2019-10-00T1234</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="blue-green-and-canary-deployment">Blue Green and Canary Deployment</h4>
<p>一切都始於使用者發出指令(i.e. 更新 Rollout CRD)，要求進行上版</p>

<p>針對 <a href="#blue-green-deployment">Blue Green Deployment</a><br />
<code class="language-plaintext highlighter-rouge">activeService</code> 以及 <code class="language-plaintext highlighter-rouge">previewService</code> 會是這次更新過程中的主要角色</p>

<p>一開始</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">activeService</code> 會指向 <em>revision 1 RS</em></li>
  <li><code class="language-plaintext highlighter-rouge">previewService</code> 會指向 <em>revision 1 RS</em></li>
</ul>

<p>然後開始進行更新，<em>revision 2 RS</em> 建立</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">activeService</code> 會指向 <em>revision 1 RS</em></li>
  <li><code class="language-plaintext highlighter-rouge">previewService</code> 會指向 <em>revision 2 RS</em></li>
</ul>

<blockquote>
  <p>在 Blue Green 中，previewService 是類似於 funnel traffic(漏斗流量)</p>
</blockquote>

<p>當 <em>revision 2 RS</em> 已經準備好了<br />
就會開始執行 <code class="language-plaintext highlighter-rouge">prePromotionAnalysis</code> 執行升級檢查<br />
在正式 “promotion” 之前，你可以讓他先暫停一下(e.g. <code class="language-plaintext highlighter-rouge">autoPromotionEnabled</code> 以及 <code class="language-plaintext highlighter-rouge">autoPromotionSeconds</code>)<br />
進到 promotion 階段就是將 <code class="language-plaintext highlighter-rouge">activeService</code> 指向 <em>revision 2 RS</em><br />
最後就剩下 <code class="language-plaintext highlighter-rouge">postPromotionAnalysis</code> 再次執行升級檢查</p>

<p>而 <a href="#canary-deployment">Canary Deployment</a> 比較不一樣<br />
因為說實在的，他並沒有一個統一的做法<br />
所以 Argo Rollouts 針對 Canary 反而是讓你自定義他該怎麼做</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="na">strategy</span><span class="pi">:</span>
  <span class="na">canary</span><span class="pi">:</span>
    <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">setWeight</span><span class="pi">:</span> <span class="m">20</span>
    <span class="pi">-</span> <span class="na">pause</span><span class="pi">:</span> <span class="pi">{}</span>
    <span class="pi">-</span> <span class="na">setWeight</span><span class="pi">:</span> <span class="m">40</span>
    <span class="pi">-</span> <span class="na">setCanaryScale</span><span class="pi">:</span>
      <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
    <span class="pi">-</span> <span class="na">pause</span><span class="pi">:</span> <span class="pi">{</span> <span class="nv">duration</span><span class="pi">:</span> <span class="nv">1m</span> <span class="pi">}</span>
    <span class="pi">-</span> <span class="na">setWeight</span><span class="pi">:</span> <span class="m">60</span>
    <span class="pi">-</span> <span class="na">pause</span><span class="pi">:</span> <span class="pi">{</span> <span class="nv">duration</span><span class="pi">:</span> <span class="nv">1h</span> <span class="pi">}</span>
    <span class="pi">-</span> <span class="na">setWeight</span><span class="pi">:</span> <span class="m">80</span>
    <span class="pi">-</span> <span class="na">pause</span><span class="pi">:</span> <span class="pi">{</span> <span class="nv">duration</span><span class="pi">:</span> <span class="nv">30m</span> <span class="pi">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>如果沒有指定 steps，就會 fallback 到 Rolling update</p>
</blockquote>

<p>透過一系列的 <strong>steps</strong> 來控制 canary 該怎麼執行<br />
所以上述可以這樣理解</p>
<ol>
  <li>設定 canary 吃 20% 的流量</li>
  <li>等待直到手動恢復</li>
  <li>設定 canary 吃 40% 的流量</li>
  <li>調整 canary replicas 的數量到 3(他並不會影響流量佔比)</li>
  <li>… 以此類推</li>
</ol>

<h4 id="hpa-and-vpa">HPA and VPA</h4>
<p><code class="language-plaintext highlighter-rouge">Rollout</code> CRD 都可以跟現有的 <a href="#horizontal-pod-autoscalerhpa">HorizontalPodAutoscaler</a> 以及 <a href="#vertical-pod-autoscalervpa">VerticalPodAutoscaler</a> 相容</p>

<p>主要的原因在於 Argo Rollouts v0.3.0 有揭露 <code class="language-plaintext highlighter-rouge">/scale</code> 這個 subresource(跟原本的 Kubernetes Deployment 相同)<br />
也因為如此，HPA 可以透過 <code class="language-plaintext highlighter-rouge">/scale</code> 讀取 current replicas(從 scale subresource 取得)並與 <code class="language-plaintext highlighter-rouge">status.replicas</code> 比較來決定要如何調整</p>

<p>以前是 <code class="language-plaintext highlighter-rouge">HPA ➡️ replica set</code><br />
現在是 <code class="language-plaintext highlighter-rouge">HPA ➡️ Rollout ➡️ replica set</code></p>

<p>有了 Rollout 這層包裝，replica set 的操作就會落到 Rollout Controller 的身上</p>

<blockquote>
  <p>決定數量依然是 HPA 的責任，Argo Rollouts 則負責實際的調整</p>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">autoscaling/v2</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">HorizontalPodAutoscaler</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">demo-hpa</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">demo</span>
<span class="na">spec</span><span class="pi">:</span>      <span class="c1"># The min and max number of pods the HPA can scale</span>
  <span class="na">minReplicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">maxReplicas</span><span class="pi">:</span> <span class="m">10</span>
  <span class="na">scaleTargetRef</span><span class="pi">:</span>       <span class="c1"># The HPA targets the Rollout object for scaling.</span>
    <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">argoproj.io/v1alpha1</span>
    <span class="na">kind</span><span class="pi">:</span> <span class="s">Rollout</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">rollout-hpa-example</span>
<span class="nn">...</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>VPA 也是可以照 HPA 的寫法，只不過官方文件並未說明是否也是因為 <code class="language-plaintext highlighter-rouge">/scale</code> subresource 的關係</p>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">autoscaling.k8s.io/v1beta2"</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VerticalPodAutoscaler</span>  
<span class="na">metadata</span><span class="pi">:</span>  
  <span class="na">name</span><span class="pi">:</span> <span class="s">vpa-rollout-example</span>  
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">test-vpa</span>  
<span class="na">spec</span><span class="pi">:</span>  
  <span class="na">targetRef</span><span class="pi">:</span>  
    <span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">argoproj.io/v1alpha1"</span>  
    <span class="na">kind</span><span class="pi">:</span> <span class="s">Rollout</span>  
    <span class="na">name</span><span class="pi">:</span> <span class="s">vpa-demo-rollout</span>  
  <span class="na">updatePolicy</span><span class="pi">:</span>  
    <span class="na">updateMode</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Auto"</span>
<span class="nn">...</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/autoscaling/">Autoscaling Workloads</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments">Managing Workloads</a></li>
  <li><a href="https://jefflin1982.medium.com/software-%E8%BB%9F%E9%AB%94%E7%89%88%E6%9C%ACcanary%E6%98%AF%E4%BB%80%E9%BA%BC%E6%84%8F%E6%80%9D-470b645829cd">Software — 軟體版本Canary是什麼意思?</a></li>
  <li><a href="https://ithelp.ithome.com.tw/m/articles/10292369">Day08 - 使用 Kubernetes 實現藍綠部屬 (Blue/Green Deployment)</a></li>
  <li><a href="https://ithelp.ithome.com.tw/articles/10289913">從異世界歸來的第十三天 - Kubernetes Deployment Strategies - Rolling Update &amp; Recreate (二)</a></li>
  <li><a href="https://ithelp.ithome.com.tw/articles/10290317">從異世界歸來的第十四天 - Kubernetes Deployment Strategies - Blue/Green Deployment 藍綠部署 (三)</a></li>
  <li><a href="https://ithelp.ithome.com.tw/articles/10290852">從異世界歸來的第十五天 - Kubernetes Deployment Strategies - Canary Deployment 金絲雀部署 (四)</a></li>
  <li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/resize-container-resources/">Resize CPU and Memory Resources assigned to Containers</a></li>
  <li><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaling</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/cluster-administration/node-autoscaling/">Node Autoscaling</a></li>
  <li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/">Configure Quality of Service for Pods</a></li>
  <li><a href="https://keda.sh/docs/2.17/concepts/">KEDA Concepts</a></li>
  <li><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">HorizontalPodAutoscaler Walkthrough</a></li>
  <li><a href="https://medium.com/@muppedaanvesh/rolling-update-recreate-deployment-strategies-in-kubernetes-%EF%B8%8F-327b59f27202">⎈ Rolling Update &amp; Recreate Deployment Strategies in Kubernetes ⚙️</a></li>
  <li><a href="https://medium.com/@vinoji2005/day-29-kubernetes-a-b-testing-126f260f7006">Day 29: Kubernetes A/B Testing</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments">Managing Workloads</a></li>
  <li><a href="https://argoproj.github.io/argo-rollouts/features/hpa-support/#bluegreen-deployments-with-hpa">Horizontal Pod Autoscaling</a></li>
  <li><a href="https://argoproj.github.io/argo-rollouts/features/bluegreen/">BlueGreen Deployment Strategy</a></li>
  <li><a href="https://argoproj.github.io/argo-rollouts/features/canary/">Canary Deployment Strategy</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="kubernetes" /><category term="scaling" /><category term="scale out" /><category term="scale up" /><category term="hpa" /><category term="vpa" /><category term="rolling update" /><category term="recreate" /><category term="blue green" /><category term="canary" /><category term="shadow" /><category term="deployment" /><category term="rollout" /><category term="controller" /><category term="argo rollouts" /><category term="keda" /><category term="keda concepts" /><category term="horizontal pod autoscaler" /><category term="vertical pod autoscaler" /><category term="hpa and vpa" /><category term="rollout crd" /><category term="manual scaling" /><category term="auto scaling" /><category term="stabilization window" /><category term="tolerance" /><category term="scaling policy" /><category term="metric data" /><category term="resize container resources" /><category term="observed generation" /><category term="ab testing" /><category term="shadow deployment" /><summary type="html"><![CDATA[隨著軟體服務日漸複雜，你需要清楚的了解不同的部署策略會如何影響你的服務，他是否會造成 downtime，他會不會導致錯誤的資料以及發生致命錯誤時，你該如何應對。部署策略需要配合好軟體層級的架構設計，兩者缺一不可。本篇文章將帶你認識不同的部署策略，優缺點以及如何實作。]]></summary></entry><entry><title type="html">資料庫 - Delayed Queue 的設計與考量</title><link href="https://ambersuncreates.com/database/database-delayed-queue/" rel="alternate" type="text/html" title="資料庫 - Delayed Queue 的設計與考量" /><published>2025-08-18T00:00:00+08:00</published><updated>2025-08-20T02:42:54+08:00</updated><id>https://ambersuncreates.com/database/database-delayed-queue</id><content type="html" xml:base="https://ambersuncreates.com/database/database-delayed-queue/"><![CDATA[<h1 id="what-is-delayed-queue">What is Delayed Queue?</h1>
<p>Delayed Queue 是一種特殊的 message queue<br />
與一般的 message queue 不同，Delayed Queue 裡面的資料並不會被立即取出<br />
你可以對每個 message 設定一個延遲時間<br />
只有當時間到了之後，資料才可以被 consumer 消費</p>

<h2 id="cronjob-and-at-command">CronJob and At Command</h2>
<p>既然主要的目的是執行 “一次性的任務”，linux 的 <a href="https://linux.die.net/man/1/at">at</a> 指令很適合在這個場景下使用<br />
<a href="https://linux.die.net/man/1/at">at</a> 本身就允許所謂的 later execution<br />
使用者可以排定一個一次性任務並等待執行</p>

<p>但是對於分散式系統來說，<a href="https://linux.die.net/man/1/at">at</a> 並不能很好地滿足需求<br />
原因在於它本身並沒有試錯重試的機制，失敗的會直接消失</p>

<p>到這裡，另一個想法是透過 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">CronJob</a> 來實現<br />
問題是我們需要的是 <strong>一次性的任務</strong>，而不是 <strong>定時的任務</strong><br />
你可能會說一樣設定 CronJob 但等他完成之後就刪除，這其實也是一種 anti-pattern<br />
並且與 <a href="https://linux.die.net/man/1/at">at</a> 的缺點類似，你無法追蹤失敗的任務</p>

<h1 id="delayed-queue-implementation">Delayed Queue Implementation</h1>
<p>Delayed Queue 的實作是非常看不同需求而定的<br />
不過本質上，他們都需要一個不間斷的機制來監控資料本身(不論是主動推播還是使用 polling 的機制)</p>

<blockquote>
  <p>有關 polling 可以參考 <a href="../../random/real-time-communication">淺談 Polling, Long Polling 以及其他即時通訊方法論 | Shawn Hsu</a></p>
</blockquote>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Name</th>
      <th style="text-align: left">Concerns</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="#rabbitmq-delayed-message-exchange-plugin">RabbitMQ Delayed Message Exchange Plugin</a></td>
      <td style="text-align: left">實作本身有單點失效的問題</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#rabbitmq-ttl-with-dlx">RabbitMQ TTL with DLX</a></td>
      <td style="text-align: left">per-message TTL 的彈性不夠, queue TTL 也同樣受限於 FIFO 的特性</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#netflix-dyno-queues">Netflix Dyno Queues</a></td>
      <td style="text-align: left">Dynomite 會使得整個系統變得相對厚重</td>
    </tr>
  </tbody>
</table>

<h2 id="rabbitmq-delayed-message-exchange-plugin">RabbitMQ Delayed Message Exchange Plugin</h2>
<p>RabbitMQ 官方有提供 <a href="https://github.com/rabbitmq/rabbitmq-delayed-message-exchange">rabbitmq-delayed-message-exchange</a> plugin 用於實現 Delayed Queue 的功能</p>

<p>這個 delay 功能是做在 exchange 上面的<br />
時間到了之後才會被往後丟到 queue 中(如果他沒辦法 route 到 queue 則會被丟棄, i.e. <code class="language-plaintext highlighter-rouge">unroutable message</code>)<br />
而 delay 並非無限制的，最多大概可以到一兩天這樣，更久的就不建議<br />
而你可以設定從 秒，分鐘，小時 等等的區間</p>

<h3 id="erlang-mnesia">Erlang Mnesia</h3>
<p>套件 <a href="https://github.com/rabbitmq/rabbitmq-delayed-message-exchange">rabbitmq-delayed-message-exchange</a> 是基於 Erlang Mnesia Database 實現的</p>

<p>Mnesia 速度快、效率高並且支援 transaction 以及 cluster replication<br />
但是其缺點是故障恢復的機制較差</p>

<p>delay 的資料是儲存在 <code class="language-plaintext highlighter-rouge">Mnesia table</code> 之上的(Mnesia 本來是用於儲存 metadata 而非資料本身)<br />
plugin 本身的實作是 single disk replica 的機制(注意到並非 Mnesia 本身的限制)<br />
意味著，如果節點失效，所有 delay 的資料都會遺失<br />
雖然 <code class="language-plaintext highlighter-rouge">Mnesia table</code> 對於節點重啟有良好的恢復機制<br />
scheduled delivery 的 timer 會被重新安裝，所以在這個情況下還是會動的<br />
只不過，<strong>單一節點失效</strong> 仍然是一個很大的問題</p>

<h2 id="rabbitmq-ttl-with-dlx">RabbitMQ TTL with DLX</h2>
<p>根據 <a href="https://www.rabbitmq.com/blog/2015/04/16/scheduling-messages-with-rabbitmq">Scheduling Messages with RabbitMQ</a> 的說法</p>

<blockquote>
  <p>For a while people have looked for ways of implementing delayed messaging with RabbitMQ. So far the accepted solution was to use a mix of message TTL and Dead Letter Exchanges as implemented by NServiceBus here.</p>
</blockquote>

<p>在還沒有 <a href="#rabbitmq-delayed-message-exchange-plugin">rabbitmq-delayed-message-exchange</a> 之前<br />
delayed message 的實作是透過 <a href="#ttl-time-to-live">TTL</a> 以及 <a href="#dlx-dead-letter-exchange">DLX</a> 實現的</p>

<p>將 message 設定 TTL 放到 queue 中<br />
不要取出，等待其到期之後由 DLX 將資料轉送到 DLQ 中<br />
就可以達到 delayed message 的效果</p>

<h3 id="ttl-time-to-live">TTL (Time-to-Live)</h3>
<p>在 RabbitMQ 中，你可以設定所謂的 Time-to-Live(TTL)，顧名思義，就是 messages 可以在 queue 中存活多久<br />
當超過 TTL 的時間，message 會被丟棄<br />
所謂的丟棄就是訊息不會被路由到 consumer 身上</p>

<blockquote>
  <p>TTL 可以設定在 single queue, multiple queue 或是 per-message</p>
</blockquote>

<p>至於說，哪時候會被丟棄呢？</p>
<ul>
  <li><a href="https://www.rabbitmq.com/quorum-queues.html">Quorum Queue</a>
    <ol>
      <li>訊息變成 Queue 的第一個元素的時候(Head of Queue)</li>
    </ol>
  </li>
  <li><a href="https://www.rabbitmq.com/classic-queues.html">Classic Queue</a>
    <ol>
      <li>訊息變成 Queue 的第一個元素的時候(Head of Queue)</li>
      <li>policy 設定的改變間接影響</li>
    </ol>
  </li>
</ul>

<blockquote>
  <p>無論是 <a href="#quorum-queue">Quorum Queue</a> 還是 <a href="#classic-queue">Classic Queue</a><br />
他們都是 FIFO 的 queue</p>
</blockquote>

<p>如果 TTL 是設定在 queue 上，那麼訊息就會依照順序被 TTL 掉<br />
如果是在 message 上，事情就會比較複雜，因為每個 message 的 TTL 都不盡相同<br />
比方說 <code class="language-plaintext highlighter-rouge">E1 是 30 秒</code>，<code class="language-plaintext highlighter-rouge">E2 是 10 秒</code><br />
即使 E2 的 TTL 比較短，他仍然需要等到 E1 被移除之後才會被丟棄</p>

<p>在這樣的情況下，E2 會多等 30 秒才會被丟棄<br />
在使用 per-message TTL 的情況下需要額外注意</p>

<h3 id="dlx-dead-letter-exchange">DLX (Dead Letter Exchange)</h3>
<p>在 <a href="../../database/database-message-queue#dlqdead-letter-queue">資料庫 - 從 Apache Kafka 認識 Message Queue | Shawn Hsu</a> 中我們提到，DLQ 是將那些執行執行失敗的 message 最終要去的地方<br />
而 RabbitMQ 內是透過 DLX 這個 exchange 將資料路由到 DLQ 的</p>

<blockquote>
  <p>沒有指定 exchange 會使用 default exchange<br />
資料流會是 exchange 到 queue</p>
</blockquote>

<p>一個 message 可以被 dead letter 的情況有</p>
<ol>
  <li>被 nack 掉(成功收到但是沒有辦法處理)</li>
  <li>超過 TTL 的時間</li>
  <li>因為超過 Queue 的長度導致 message 被丟棄</li>
  <li>在 <a href="#quorum-queue">Quorum Queue</a> 的情況下，message 被回傳的次數超過 delivery limit</li>
</ol>

<blockquote>
  <p>如果是 Queue 本身 expired, 則 messages <strong><em>並不會</em></strong> 被 dead letter</p>
</blockquote>

<p>被 dead letter 的 message 會被轉送到指定的 routing key 上<br />
如果沒有指定，就是原本的 routing key</p>

<h2 id="apache-activemq">Apache ActiveMQ</h2>
<p>針對兩種實作 <a href="#activemq-classic">ActiveMQ Classic</a> 以及 <a href="#activemq-artemis">ActiveMQ Artemis</a> 都支援 delayed message，只是實作方式不同</p>

<h3 id="activemq-classic">ActiveMQ Classic</h3>
<p><a href="https://activemq.apache.org/components/classic/documentation/delay-and-schedule-message-delivery">ActiveMQ Classic</a> 本身是採用 polling 的機制實現</p>

<p><a href="https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/JobSchedulerImpl.java#L720">mainloop</a> 是一個無窮迴圈的 while loop<br />
他並非有固定的 interval 去檢查，而是會根據資料狀態動態的調整<br />
<a href="https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/JobSchedulerImpl.java#L905">預設是 500ms</a>, 但是他也會改成比如說，剩餘等待時間<br />
既然是 polling 的機制，他有可能會 miss 掉 real time 的特性，透過動態調整 interval 可以很好的避免這個問題</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="kt">long</span> <span class="n">waitTime</span> <span class="o">=</span> <span class="n">nextExecutionTime</span> <span class="o">-</span> <span class="n">currentTime</span><span class="o">;</span>
<span class="k">this</span><span class="o">.</span><span class="na">scheduleTime</span><span class="o">.</span><span class="na">setWaitTime</span><span class="o">(</span><span class="n">waitTime</span><span class="o">);</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="activemq-artemis">ActiveMQ Artemis</h3>
<p><a href="https://activemq.apache.org/components/artemis/documentation/latest/scheduled-messages.html#scheduled-messages">ActiveMQ Artemis</a> 則是使用 Java 內建的 <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ScheduledThreadPoolExecutor.html">ScheduledThreadPoolExecutor</a> 實現<br />
簡單來說呢，他可以排程一個 command，在</p>
<ol>
  <li>指定的時間執行一次</li>
  <li>進行排程重複執行</li>
</ol>

<p>當收到一個 delay message 的時候，就會計算出 delay 然後 schedule 下去<br />
在 <a href="https://github.com/apache/activemq-artemis/blob/main/artemis-server/src/main/java/org/apache/activemq/artemis/core/server/impl/ScheduledDeliveryHandlerImpl.java#L190">ScheduledDeliveryHandlerImpl.java#L190</a></p>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="rouge-code"><pre><span class="kd">private</span> <span class="kt">void</span> <span class="nf">scheduleDelivery</span><span class="o">(</span><span class="kd">final</span> <span class="kt">long</span> <span class="n">deliveryTime</span><span class="o">)</span> <span class="o">{</span>
      <span class="kd">final</span> <span class="kt">long</span> <span class="n">now</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>

      <span class="kd">final</span> <span class="kt">long</span> <span class="n">delay</span> <span class="o">=</span> <span class="n">deliveryTime</span> <span class="o">-</span> <span class="n">now</span><span class="o">;</span>

      <span class="k">if</span> <span class="o">(</span><span class="n">delay</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
         <span class="k">if</span> <span class="o">(</span><span class="n">logger</span><span class="o">.</span><span class="na">isTraceEnabled</span><span class="o">())</span> <span class="o">{</span>
            <span class="n">logger</span><span class="o">.</span><span class="na">trace</span><span class="o">(</span><span class="s">"calling another scheduler now as deliverTime {} &lt; now={}"</span><span class="o">,</span> <span class="n">deliveryTime</span><span class="o">,</span> <span class="n">now</span><span class="o">);</span>
         <span class="o">}</span>
         <span class="c1">// if delay == 0 we will avoid races between adding the scheduler and finishing it</span>
         <span class="nc">ScheduledDeliveryRunnable</span> <span class="n">runnable</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ScheduledDeliveryRunnable</span><span class="o">(</span><span class="n">deliveryTime</span><span class="o">);</span>
         <span class="n">scheduledExecutor</span><span class="o">.</span><span class="na">schedule</span><span class="o">(</span><span class="n">runnable</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="nc">TimeUnit</span><span class="o">.</span><span class="na">MILLISECONDS</span><span class="o">);</span>
      <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(!</span><span class="n">runnables</span><span class="o">.</span><span class="na">containsKey</span><span class="o">(</span><span class="n">deliveryTime</span><span class="o">))</span> <span class="o">{</span>
         <span class="nc">ScheduledDeliveryRunnable</span> <span class="n">runnable</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ScheduledDeliveryRunnable</span><span class="o">(</span><span class="n">deliveryTime</span><span class="o">);</span>

         <span class="k">if</span> <span class="o">(</span><span class="n">logger</span><span class="o">.</span><span class="na">isTraceEnabled</span><span class="o">())</span> <span class="o">{</span>
            <span class="n">logger</span><span class="o">.</span><span class="na">trace</span><span class="o">(</span><span class="s">"Setting up scheduler for {} with a delay of {} as now={}"</span><span class="o">,</span> <span class="n">deliveryTime</span><span class="o">,</span> <span class="n">delay</span><span class="o">,</span> <span class="n">now</span><span class="o">);</span>
         <span class="o">}</span>

         <span class="n">runnables</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">deliveryTime</span><span class="o">,</span> <span class="n">runnable</span><span class="o">);</span>
         <span class="n">scheduledExecutor</span><span class="o">.</span><span class="na">schedule</span><span class="o">(</span><span class="n">runnable</span><span class="o">,</span> <span class="n">delay</span><span class="o">,</span> <span class="nc">TimeUnit</span><span class="o">.</span><span class="na">MILLISECONDS</span><span class="o">);</span>
      <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
         <span class="k">if</span> <span class="o">(</span><span class="n">logger</span><span class="o">.</span><span class="na">isTraceEnabled</span><span class="o">())</span> <span class="o">{</span>
            <span class="n">logger</span><span class="o">.</span><span class="na">trace</span><span class="o">(</span><span class="s">"Couldn't make another scheduler as {} is already set, now is {}"</span><span class="o">,</span> <span class="n">deliveryTime</span><span class="o">,</span> <span class="n">now</span><span class="o">);</span>
         <span class="o">}</span>
      <span class="o">}</span>
   <span class="o">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>這個 <code class="language-plaintext highlighter-rouge">scheduledExecutor</code> 往上追</p>
<ul>
  <li><a href="https://github.com/apache/activemq-artemis/blob/main/artemis-server/src/main/java/org/apache/activemq/artemis/core/server/impl/QueueImpl.java#L376">QueueImpl.java#L376</a></li>
  <li><a href="https://github.com/apache/activemq-artemis/blob/main/artemis-server/src/main/java/org/apache/activemq/artemis/core/server/impl/QueueFactoryImpl.java#L54">QueueFactoryImpl.java#L54</a></li>
  <li><a href="https://github.com/apache/activemq-artemis/blob/main/artemis-server/src/main/java/org/apache/activemq/artemis/core/server/impl/ActiveMQServerImpl.java#L3234">ActiveMQServerImpl.java#L3234</a></li>
</ul>

<p>就是一個 <code class="language-plaintext highlighter-rouge">ScheduledThreadPoolExecutor</code><br />
相比於 <a href="#activemq-classic">ActiveMQ Classic</a> 的 polling 機制，ActiveMQ Artemis 的實作依賴於語言本身的實作，可以避免 polling 帶來的 overhead</p>

<h2 id="netflix-dyno-queues">Netflix Dyno Queues</h2>
<p>Netflix 的 Content Platform Engineering 也有使用 Delayed Queue 的需求<br />
原本他們是使用 <a href="https://cassandra.apache.org/_/index.html">Cassandra</a> 搭配 <a href="https://zookeeper.apache.org/">Zookeeper</a> 實現的<br />
不過他們很快發現了問題所在</p>

<ol>
  <li>Cassandra 使用 queue 的資料結構是 anti pattern</li>
  <li>Distributed Lock 導致效能不佳(一次只能有一個 consumer，即使使用 shard，問題也只能暫時緩解)</li>
</ol>

<p>而 <a href="https://github.com/Netflix/dyno-queues">Dyno Queue</a> 的設計很好的解決了以上的問題<br />
基於 <a href="https://github.com/Netflix/dynomite">Dynomite</a> 搭配 <a href="#redis-sorted-set">Redis Sorted Set</a> 的設計可以擁有以下特性</p>
<ol>
  <li>分散式的系統</li>
  <li>不需要外部 lock 機制</li>
  <li>非強制 FIFO</li>
  <li>支援 sharding</li>
  <li>At least once delivery</li>
</ol>

<blockquote>
  <p>基本上 Dynomite 就是一個抽象封裝，底下可以替換不同的 storage engine<br />
支援 multi-datacenter replication 達到高可用性</p>
</blockquote>

<h3 id="redis-sorted-set">Redis Sorted Set</h3>
<p>具體來說資料是儲存在 <code class="language-plaintext highlighter-rouge">Sorted Set</code> 之上的<br />
因為我們要做 Delayed Queue 嘛，本質上就是根據時間排序的 Priority Queue<br />
那要怎麼查詢 Delayed 的資料呢？</p>

<blockquote>
  <p>有關 priority queue 可以參考 <a href="../../algorithm/alogrithm-priority-queue">神奇的演算法 - 為什麼你的 Priority Queue 那麼慢！ | Shawn Hsu</a></p>
</blockquote>

<p>其實問題比想像中還簡單<br />
在 Sorted Set 裡面的 key 肯定是跟時間有關<br />
Dyno Queue 是將 <code class="language-plaintext highlighter-rouge">時間</code> 以及 <code class="language-plaintext highlighter-rouge">priority</code> 組合起來當作 key<br />
要判斷一個資料是否 delay 就將 <code class="language-plaintext highlighter-rouge">當前時間</code> 與 max priority 做計算<br />
並拿取 <code class="language-plaintext highlighter-rouge">0 ~ score</code> 之間的資料</p>

<p>為什麼是 <code class="language-plaintext highlighter-rouge">0 ~ score</code> 之間的資料呢？<br />
因為你的 score 是當前時間，所以小於 score 的資料就是 delay 的資料<br />
拿出來之後，為了避免資料遺失，所以他需要手動進行 ACK</p>

<p>也就是說，當你 pop 資料的時候，他會被移動到所謂的 <code class="language-plaintext highlighter-rouge">unack set</code> 中(並不是直接被移除)<br />
手動 ACK 代表你已經處理完了這個資料，<code class="language-plaintext highlighter-rouge">unack set</code> 中的資料會被移除<br />
如果你沒有 ACK 會發生什麼事情？</p>

<p>因為不確定你是否處理完這個資料，所以過一段時間之後<br />
<code class="language-plaintext highlighter-rouge">unack set</code> 中的資料會被放回 Delayed Queue 當中(這是透過一個 background job 定期去檢查的)<br />
有了這種機制，基本上就可以保證 <code class="language-plaintext highlighter-rouge">At least once delivery</code> 的特性</p>

<p>而 Redis In memory 以及 Single Thread 的特性，使得其滿足 Netflix 團隊對於 Delayed Queue 的需求</p>

<blockquote>
  <p>有關 Redis 可以參考 <a href="../../database/database-cache">資料庫 - Cache Strategies 與常見的 Solutions | Shawn Hsu</a></p>
</blockquote>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://blog.gslin.org/archives/2016/08/20/6755/netflix-%E9%96%8B%E7%99%BC%E7%9A%84-delayed-queue/">Netflix 開發的 Delayed Queue</a></li>
  <li><a href="https://netflixtechblog.com/distributed-delay-queues-based-on-dynomite-6b31eca37fbc">Distributed delay queues based on Dynomite</a></li>
  <li><a href="https://www.rabbitmq.com/blog/2015/04/16/scheduling-messages-with-rabbitmq">Scheduling Messages with RabbitMQ</a></li>
  <li><a href="https://www.rabbitmq.com/docs/metadata-store">Metadata store</a></li>
  <li><a href="https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/issues/72">Delay interval predictability</a></li>
  <li><a href="https://github.com/rabbitmq/rabbitmq-delayed-message-exchange">rabbitmq-delayed-message-exchange</a></li>
  <li><a href="https://www.rabbitmq.com/docs/ttl">Time-to-Live and Expiration</a></li>
  <li><a href="https://www.cloudamqp.com/blog/rabbitmq-queue-types.html">RabbitMQ Queue Types Explained</a></li>
  <li><a href="https://www.rabbitmq.com/docs/dlx">Dead Letter Exchanges</a></li>
  <li><a href="https://activemq.apache.org/components/artemis/migration-documentation/key-differences.html">Differences From ActiveMQ 5</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="database" /><category term="delayed queue" /><category term="message queue" /><category term="rabbitmq" /><category term="redis" /><category term="linux at" /><category term="cronjob" /><category term="linux atd" /><category term="dynomite" /><category term="cassandra" /><category term="zookeeper" /><category term="mnesia" /><category term="erlang" /><category term="ttl" /><category term="dlq" /><category term="dlx" /><category term="quorum queue" /><category term="classic queue" /><category term="priority queue" /><category term="polling" /><category term="transaction" /><category term="cluster replication" /><category term="ack" /><category term="nack" /><category term="dead letter" /><category term="dyno queue" /><category term="sorted set" /><category term="fifo" /><category term="sharding" /><category term="activemq" /><category term="activemq classic" /><category term="activemq artemis" /><category term="java" /><category term="scheduledthreadpoolexecutor" /><category term="mainloop" /><summary type="html"><![CDATA[當你需要解耦你會想到 message queue，而當你需要在解耦的基礎下提供延遲的機制，你會怎麼做？ Delayed Queue 的設計就是為了滿足這樣的需求。本文將會帶你瞭解市面上的解決方案，點出其優缺點，並且學習早期 Netflix Dyno Queues 的設計。]]></summary></entry><entry><title type="html">玩轉 Syslog 第一次就上手</title><link href="https://ambersuncreates.com/random/syslog/" rel="alternate" type="text/html" title="玩轉 Syslog 第一次就上手" /><published>2025-06-23T00:00:00+08:00</published><updated>2025-06-23T17:00:47+08:00</updated><id>https://ambersuncreates.com/random/syslog</id><content type="html" xml:base="https://ambersuncreates.com/random/syslog/"><![CDATA[<h1 id="introduction-to-syslog">Introduction to Syslog</h1>
<p>任何運行中的系統都會有 Log，主要是為了方便除錯、監控以及分析等等的<br />
可以說沒有 Log 的系統是沒有辦法運作的</p>

<p>在 <a href="../../website/website-log">網頁程式設計三兩事 - Logging 最佳實踐 | Shawn Hsu</a> 中我們已經知道說針對 application 怎麼設計良好的 Log 系統<br />
而光是擁有 application log 其實是不足的<br />
你可能會需要更底層的 Log 來幫助你監控整體系統</p>

<p>比方說你也需要知道 Kernel 的 Log, 更甚至是 Router 的 Log<br />
也就是說，擁有一個統整的 Log 系統在某些時候是重要的</p>

<p>Syslog 的概念就是，我擁有一個統一的系統，可以處理不同來源的 Log<br />
將它統一收集，封存(audit 相關)起來，方便後續的分析與追蹤<br />
這個統一的系統由於需要跨網路收集，因此是屬於 <code class="language-plaintext highlighter-rouge">client-server</code> 的架構<br />
Syslog Server 負責接收 Client 的 Log 並做後續處理</p>

<h2 id="background">Background</h2>
<p>我個人覺得 Syslog 的歷史其實滿曲折的<br />
當初是在 University of California, BSD TCP/IP 的系統上實作的<br />
在後來 Syslog 的標準被廣泛的系統採納並支持，逐漸成為行業的標準<br />
話雖如此，該 “標準” 其實並沒有正式成為 IETF 的標準<br />
<a href="https://datatracker.ietf.org/doc/html/rfc3164">RFC 3164</a> 中僅僅只是記錄了當時的實作方式</p>

<blockquote>
  <p>所以你可以看到 Category 歸類為 <code class="language-plaintext highlighter-rouge">Informational</code></p>
</blockquote>

<p>而真正納入 IETF 標準的是 <a href="https://datatracker.ietf.org/doc/html/rfc5424">RFC 5424</a><br />
不過由於 <a href="https://datatracker.ietf.org/doc/html/rfc3164">RFC 3164</a> 是當時的實作方式，為了相容性，現今仍然兩者並存居多</p>

<h3 id="rfc-3164"><a href="https://datatracker.ietf.org/doc/html/rfc3164">RFC 3164</a></h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>&lt;PRI&gt;TIMESTAMP HOSTNAME TAG: MESSAGE
</pre></td></tr></tbody></table></code></pre></div></div>

<p>當時為了能夠區分哪一種資訊是 Syslog，因此他們刻意了定義了上述的格式<br />
只要看到這種格式的資料，哦你就可以確定說他是 Syslog 這樣</p>

<p>整個 Log 分三段，分別是 <code class="language-plaintext highlighter-rouge">PRI</code>, <code class="language-plaintext highlighter-rouge">HEADER</code>, <code class="language-plaintext highlighter-rouge">MESSAGE</code></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">PRI</code> 是 Priority Value，可以參考 <a href="#syslog-priority">Syslog Priority</a></li>
  <li><code class="language-plaintext highlighter-rouge">HEADER</code>，包含 <code class="language-plaintext highlighter-rouge">TIMESTAMP</code>(format: <code class="language-plaintext highlighter-rouge">MMM DD hh:mm:ss</code>), <code class="language-plaintext highlighter-rouge">HOSTNAME</code></li>
  <li><code class="language-plaintext highlighter-rouge">MESSAGE</code>，包含 <code class="language-plaintext highlighter-rouge">TAG</code>(service name 或是 process id), <code class="language-plaintext highlighter-rouge">CONTENT</code></li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Section</th>
      <th style="text-align: right">Field</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">PRI</td>
      <td style="text-align: right">Priority Value</td>
      <td>可參考 <a href="#syslog-priority">Syslog Priority</a></td>
    </tr>
    <tr>
      <td style="text-align: left">HEADER</td>
      <td style="text-align: right">TIMESTAMP</td>
      <td>格式: <code class="language-plaintext highlighter-rouge">MMM DD hh:mm:ss</code></td>
    </tr>
    <tr>
      <td style="text-align: left">HEADER</td>
      <td style="text-align: right">HOSTNAME</td>
      <td>只能是 <code class="language-plaintext highlighter-rouge">hostname</code>, <code class="language-plaintext highlighter-rouge">ipv4</code> 或是 <code class="language-plaintext highlighter-rouge">ipv6</code>，不能是 <code class="language-plaintext highlighter-rouge">domain name</code></td>
    </tr>
    <tr>
      <td style="text-align: left">MESSAGE</td>
      <td style="text-align: right">TAG</td>
      <td>服務名稱或是 process id，只能是 <code class="language-plaintext highlighter-rouge">字母數字</code></td>
    </tr>
    <tr>
      <td style="text-align: left">MESSAGE</td>
      <td style="text-align: right">CONTENT</td>
      <td>有用的資訊</td>
    </tr>
  </tbody>
</table>

<p>舉例來說一個合法的 RFC 3164 的 Log 是這樣</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>&lt;34&gt;Oct 11 22:14:15 mymachine su: 'su root' failed for lonvick on /dev/pts/8
</pre></td></tr></tbody></table></code></pre></div></div>

<p>可以看到說，上述的 Message Tag 為 <code class="language-plaintext highlighter-rouge">su</code><br />
因為他只能包含字母數字，所以 <code class="language-plaintext highlighter-rouge">:</code> 會被歸類在 content 裡面</p>

<h3 id="rfc-5424"><a href="https://datatracker.ietf.org/doc/html/rfc5424">RFC 5424</a></h3>
<p>我們提到 <a href="#rfc-3164">RFC 3164</a> 僅僅只是個紀錄，他其實不算是一個標準<br />
非標準的壞處就是大家各自有各自的實作方式，久而久之其實就會有相容性的問題<br />
RFC 5424 的出現旨在淘汰舊的實作方式，並提供業界一套標準的格式</p>

<p>除了更改格式，RFC 5424 抽離了對 transport protocol 的依賴<br />
在 <a href="#rfc-3164">RFC 3164</a> 中，預設是走 UDP 傳輸<br />
而這大大的限縮了 Syslog 的應用場景 應該說不夠彈性<br />
RFC 5424 中，並沒有規定一定要使用哪一種傳輸協議<br />
但是為了相容性，他還是支持 UDP 的傳輸方式</p>

<p>因為 <a href="#rfc-3164">RFC 3164</a> 的格式其實能夠表達的東西不夠多<br />
改良後的格式為</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>&lt;PRI&gt; VERSION TIMESTAMP HOSTNAME APP-NAME PROCID MSGID [SD-ID * (SD-PARAM-NAME="SD-PARAM-VALUE")] MSG
</pre></td></tr></tbody></table></code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Section</th>
      <th style="text-align: right">Field</th>
      <th>Description</th>
      <th style="text-align: right">Nil Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">PRI</td>
      <td style="text-align: right">Priority Value</td>
      <td>可參考 <a href="#syslog-priority">Syslog Priority</a></td>
      <td style="text-align: right">:x:</td>
    </tr>
    <tr>
      <td style="text-align: left">VERSION</td>
      <td style="text-align: right">Version</td>
      <td><code class="language-plaintext highlighter-rouge">1</code> 用以標示 Syslog Protocol 的版本, 5424 是 <code class="language-plaintext highlighter-rouge">1</code></td>
      <td style="text-align: right">:x:</td>
    </tr>
    <tr>
      <td style="text-align: left">TIMESTAMP</td>
      <td style="text-align: right">Timestamp</td>
      <td>格式為 <a href="https://datatracker.ietf.org/doc/html/rfc3339">RFC 3339</a></td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: left">HOSTNAME</td>
      <td style="text-align: right">Hostname</td>
      <td>格式為 <a href="https://datatracker.ietf.org/doc/html/rfc1034">RFC 1034</a>，或是部分資料如 hostname, ip 等</td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: left">APP-NAME</td>
      <td style="text-align: right">Application Name</td>
      <td>服務名稱或是 process id，只能是 <code class="language-plaintext highlighter-rouge">字母數字</code></td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: left">PROCID</td>
      <td style="text-align: right">Process ID</td>
      <td>只能是 <code class="language-plaintext highlighter-rouge">字母數字</code></td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: left">MSGID</td>
      <td style="text-align: right">Message ID</td>
      <td>只能是 <code class="language-plaintext highlighter-rouge">字母數字</code></td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: left">SD-ID</td>
      <td style="text-align: right">Structured Data ID</td>
      <td>只能是 <code class="language-plaintext highlighter-rouge">字母數字</code></td>
      <td style="text-align: right">:x:</td>
    </tr>
    <tr>
      <td style="text-align: left">SD-PARAM-NAME</td>
      <td style="text-align: right">Structured Data Parameter Name</td>
      <td>只能是 <code class="language-plaintext highlighter-rouge">字母數字</code></td>
      <td style="text-align: right">:x:</td>
    </tr>
    <tr>
      <td style="text-align: left">SD-PARAM-VALUE</td>
      <td style="text-align: right">Structured Data Parameter Value</td>
      <td>只能是 <code class="language-plaintext highlighter-rouge">字母數字</code></td>
      <td style="text-align: right">:x:</td>
    </tr>
    <tr>
      <td style="text-align: left">MSG</td>
      <td style="text-align: right">Message</td>
      <td>log 訊息</td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
  </tbody>
</table>

<p>額外的補充資料是一個 array 的結構，本身可以是空的</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>[exampleSDID@32473 iut="3" eventSource="Application" eventID="1011"][examplePriority@32473 class="high"]
</pre></td></tr></tbody></table></code></pre></div></div>

<p>比方說上述擁有兩個部分 <code class="language-plaintext highlighter-rouge">exampleSDID@32473</code> 以及 <code class="language-plaintext highlighter-rouge">examplePriority@32473</code><br />
分組的用意在於說他底下的 key-value pair 都是屬於該區段的，給予較高的可讀性</p>

<p>舉例來說一個合法的 RFC 5424 的 Log 是這樣</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>&lt;34&gt;1 2025-06-20T01:27:42Z myhostname myapp 12345 99 - [exampleSDID@32473 iut="1" eventSource="application" eventID="1011"] Test message content
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="syslog-priority">Syslog Priority</h2>
<p>Priority Value 是由 <code class="language-plaintext highlighter-rouge">Facility</code> 以及 <code class="language-plaintext highlighter-rouge">Severity</code> 組成<br />
這個欄位的用意是告訴你這個 Log 的優先程度，哪個服務，有多嚴重這樣<br />
你可以透過 PRI 的數值決定你的 Syslog 要怎麼處理</p>

<blockquote>
  <p>針對服務的數值，如果你沒有一個可以選，他有 reserved facility 可以使用，是 <code class="language-plaintext highlighter-rouge">16 ~ 23</code></p>
</blockquote>

<p>問題是，兩個數字怎麼組合起來<br />
公式是 <code class="language-plaintext highlighter-rouge">(Facility * 8) + Severity</code><br />
所以你會得到一個 <code class="language-plaintext highlighter-rouge">0 ~ 191</code> 的數值<br />
這個數值就是 PRI 的值</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Facility</th>
      <th style="text-align: right">Numerical Code</th>
      <th> </th>
      <th style="text-align: center">Severity</th>
      <th style="text-align: right">Numerical Code</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: right">kernel messages</td>
      <td> </td>
      <td style="text-align: center">0</td>
      <td style="text-align: right">emergency</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: right">user-level messages</td>
      <td> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: right">alert</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: right">mail system</td>
      <td> </td>
      <td style="text-align: center">2</td>
      <td style="text-align: right">critical</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: right">system daemons</td>
      <td> </td>
      <td style="text-align: center">3</td>
      <td style="text-align: right">error</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: right">security/authorization messages</td>
      <td> </td>
      <td style="text-align: center">4</td>
      <td style="text-align: right">warning</td>
    </tr>
    <tr>
      <td style="text-align: center">5</td>
      <td style="text-align: right">messages generated internally by syslogd</td>
      <td> </td>
      <td style="text-align: center">5</td>
      <td style="text-align: right">notice</td>
    </tr>
    <tr>
      <td style="text-align: center">6</td>
      <td style="text-align: right">line printer subsystem</td>
      <td> </td>
      <td style="text-align: center">6</td>
      <td style="text-align: right">informational</td>
    </tr>
    <tr>
      <td style="text-align: center">7</td>
      <td style="text-align: right">network news subsystem</td>
      <td> </td>
      <td style="text-align: center">7</td>
      <td style="text-align: right">debug</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: right">UUCP subsystem</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">9</td>
      <td style="text-align: right">clock daemon</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">10</td>
      <td style="text-align: right">security/authorization messages</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">11</td>
      <td style="text-align: right">FTP daemon</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">12</td>
      <td style="text-align: right">NTP subsystem</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">13</td>
      <td style="text-align: right">log audit</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">14</td>
      <td style="text-align: right">log alert</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">15</td>
      <td style="text-align: right">clock daemon</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">16 ~ 23</td>
      <td style="text-align: right">local use</td>
      <td> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
    </tr>
  </tbody>
</table>

<h1 id="syslog-transport">Syslog Transport</h1>
<p>既然他是 client-server 的架構，並且需要跨網路收集，很明顯傳輸是一項重要的事情</p>

<p><a href="#rfc-3164">RFC 3164</a> 中提到說，預設是走 <a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">UDP</a> 傳輸<br />
預設是 <code class="language-plaintext highlighter-rouge">514</code> 的 port，然後建議 server 以及 client 都使用這個 port</p>

<blockquote>
  <p>ref: <a href="https://datatracker.ietf.org/doc/html/rfc5426">RFC 5426</a>(Transmission of Syslog Messages over UDP)</p>
</blockquote>

<p>至於 <a href="#rfc-5424">RFC 5424</a> 中，並沒有規定一定要使用哪一種傳輸協議<br />
所以 <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol">TCP</a> 或 <a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">UDP</a> 都是可以的<br />
不過標準提到他 <strong>必須支援</strong> <code class="language-plaintext highlighter-rouge">TLS-based</code> 的傳輸方式(ref: <a href="https://datatracker.ietf.org/doc/html/rfc5425">RFC 5425</a>)<br />
但他只說要支援，你也可以 <strong>不要使用</strong> <code class="language-plaintext highlighter-rouge">TLS</code> 的傳輸方式</p>

<blockquote>
  <p>ref: <a href="https://datatracker.ietf.org/doc/html/rfc6587">RFC 6587</a>(Transmission of Syslog Messages over TCP)</p>
</blockquote>

<h2 id="acknowledgment-and-reliability">Acknowledgment and Reliability</h2>
<p>Syslog 本身是一個相對簡單的 protocol<br />
所以它本身其實沒有任何關於 Acknowledgement 的機制<br />
可靠性傳輸實際上是依靠上層傳輸協議的實作而定<br />
如果不依賴 <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol">TCP</a> 之類的，他其實是沒有辦法保證傳輸的可靠性</p>

<p>比如說 legacy 的 Syslog protocol 指定使用 <a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">UDP</a> 傳輸<br />
除此之外，數據正確性也是沒有保障的<br />
即使擁有 Checksum 機制，由於 hash 碰撞的特性，同樣的 Checksum 也無法保證相同資料</p>

<h2 id="data-fragmentation">Data Fragmentation</h2>
<p>凡事碰到網路傳輸，我們其實最害怕的就是掉資料<br />
Syslog 其實也會遇到這種問題，而前面提過說他實際上是依賴上層傳輸協議的實作<br />
Syslog protocol 本身並沒有提供任何的機制來保證傳輸的可靠性</p>

<p>為了應對這種辦法，<a href="#rfc-3164">RFC 3164</a> 中提到說<br />
你應該盡量將資料縮小，建議的大小是 <code class="language-plaintext highlighter-rouge">1024 bytes</code>(在很古老的 Syslog 系統下小於 1024 會出問題)<br />
雖然 <a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">UDP</a> 理論上可以吃到 <code class="language-plaintext highlighter-rouge">65535 bytes</code><br />
不過他會遇到 Fragmentation 的問題</p>

<blockquote>
  <p>傳統 Syslog server/receiver 需要能夠處理 480 ~ 2048 bytes 的資料</p>
</blockquote>

<p>UDP 是 IP 層以上的傳輸協議，他底層依賴於 IP 層的機制<br />
雖然 UDP 可以一次送 65535 bytes 的資料<br />
但是 IP 層會有 MTU 的限制，也就是說太大的資料本質上會被拆成很多小份資料傳輸<br />
這其實會對 Syslog 有一定的影響，因為 會掉資料</p>

<p>還是要強調 Syslog 是很簡單的協定，他也不希望為了處理這種事情而變得複雜<br />
不想掉資料又想要在一定程度上保持簡潔，所以他會建議每一筆的資料大小限制在 <code class="language-plaintext highlighter-rouge">1024 bytes</code><br />
這個大小是需要調整的，跨網路傳輸要設定成 <strong>網路上最小的 MTU 大小</strong>(因為要大家都能傳，所以是最小)<br />
一次只傳一筆，一筆資料剛好是路徑上最小的 MTU 大小<br />
這可以在最大程度上避免 Fragmentation 的問題<br />
多筆資料也是不建議的，雖然 Syslog 本身有 Timestamp，不過如果遇到相同時間戳記仍然會有問題<br />
也無法保證順序</p>

<p>那 <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol">TCP</a> 呢？
Syslog 將所有他不想做的事情外包給 TCP 處理<br />
事實上他也做得挺好的</p>

<p>UDP 是 message based 的傳輸協議，也就是傳一筆收一筆<br />
TCP 則是 stream based 的傳輸協議，也就是傳一坨收一坨<br />
你需要有一個辦法分別他的斷點在哪，常見的就是使用 <code class="language-plaintext highlighter-rouge">換行</code> 區隔<br />
稱為 <a href="#non-transparent-framing">Non-transparent Framing</a></p>

<h3 id="non-transparent-framing">Non-transparent Framing</h3>
<p>採用換行符號來區隔不同的資料實務上會有問題<br />
因為傳統上那些特殊字元是沒有跳脫的<br />
導致接收端在處理的時候會錯誤</p>

<p>比如說如果一筆資料裡面有多個換行符號<br />
他就會被誤拆成多筆資料</p>

<h3 id="octet-counting">Octet Counting</h3>
<p>怎麼解決 <a href="#non-transparent-framing">Non-transparent Framing</a> 的問題其實也滿簡單的<br />
既然換行符號不嚴謹，我是不是能夠告訴你這個資料長度，然後再給你開頭<br />
無論資料裡面是啥，都能夠正確處理？</p>

<p>具體來說就只是在開頭加上資料長度<br />
而這出乎意料的好用，並且簡單</p>

<h1 id="syslog-ng">syslog-ng</h1>
<p>接下來就讓我們使用 <a href="https://www.syslog-ng.com/">syslog-ng</a> 把 Server 架設起來觀察<br />
syslog-ng 預設的 config 是使用 <code class="language-plaintext highlighter-rouge">default-network-drivers</code>(可參考 <a href="https://support.oneidentity.com/technical-documents/syslog-ng-open-source-edition/3.16/release-notes/default-network-drivers-receive-and-parse-common-syslog-messages">syslog-ng Open Source Edition 3.16 - Release Notes</a>)<br />
長這樣</p>

<blockquote>
  <p>注意到你不需要額外撰寫 config, 這是預設的<br />
阿如果要更改也一樣是改 <code class="language-plaintext highlighter-rouge">/etc/syslog-ng/syslog-ng.conf</code> 這個檔案</p>
</blockquote>

<div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre></td><td class="rouge-code"><pre>@<span class="n">version</span>: <span class="m">4</span>.<span class="m">8</span>
@<span class="n">include</span> <span class="s2">"scl.conf"</span>

<span class="n">source</span> <span class="n">s_local</span> {
        <span class="n">internal</span>();
};

<span class="n">source</span> <span class="n">s_network</span> {
        <span class="n">default</span>-<span class="n">network</span>-<span class="n">drivers</span>(
                <span class="c"># NOTE: TLS support
</span>                <span class="c">#
</span>                <span class="c"># the default-network-drivers() source driver opens the TLS
</span>                <span class="c"># enabled ports as well, however without an actual key/cert
</span>                <span class="c"># pair they will not operate and syslog-ng would display a
</span>                <span class="c"># warning at startup.
</span>                <span class="c">#
</span>                <span class="c">#tls(key-file("/path/to/ssl-private-key") cert-file("/path/to/ssl-cert"))
</span>        );
};

<span class="n">destination</span> <span class="n">d_local</span> {
        <span class="n">file</span>(<span class="s2">"/var/log/messages"</span>);
        <span class="n">file</span>(<span class="s2">"/var/log/messages-kv.log"</span> <span class="n">template</span>(<span class="s2">"$ISODATE $HOST $(format-welf --scope all-nv-pairs)\n"</span>) <span class="n">frac</span>-<span class="n">digits</span>(<span class="m">3</span>));
};

<span class="n">log</span> {
        <span class="n">source</span>(<span class="n">s_local</span>);
        <span class="n">source</span>(<span class="n">s_network</span>);
        <span class="n">destination</span>(<span class="n">d_local</span>);
};
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>要使用 <code class="language-plaintext highlighter-rouge">default-network-drivers</code> 需要有 <code class="language-plaintext highlighter-rouge">@include "scl.conf"</code> 這行</p>
</blockquote>

<p>這個 default-network-drivers 可以接收來自以下的設定</p>
<ul>
  <li>514/tcp, 514/udp <a href="#rfc-3164">RFC 3164</a></li>
  <li>601/tcp <a href="#rfc-5424">RFC 5424</a></li>
  <li>6514/tls</li>
</ul>

<p>跑起來就會是這樣</p>

<blockquote>
  <p>注意到同一個 port 可以 forward TCP 以及 UDP</p>
</blockquote>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="se">\</span>
    <span class="nt">--name</span> syslog-ng-server <span class="se">\</span>
    <span class="nt">-p</span> 514:514/tcp <span class="se">\</span>
    <span class="nt">-p</span> 515:514/udp <span class="se">\</span>
    <span class="nt">-p</span> 601:601 <span class="se">\</span>
    balabit/syslog-ng:latest <span class="se">\</span>
    <span class="nt">--no-caps</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="everything-compatible-with-rfc-3164">Everything Compatible with RFC 3164?</h2>
<p>測試基本的 3164 格式</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"&lt;34&gt;Oct 11 22:14:15 mymachine su: 'su root' failed for lonvick on /dev/pts/8"</span> | nc localhost 514
</pre></td></tr></tbody></table></code></pre></div></div>
<p><img src="/assets/img/posts/syslog-3164-1.png" alt="" /></p>

<p><img src="/assets/img/posts/syslog-3164-2.png" alt="" /></p>

<p>可以看到說他有被正確的讀取為 3164 的格式 TCP<br />
然後各個欄位都有正確的被解析</p>

<p><img src="/assets/img/posts/syslog-3164-3.png" alt="" /></p>

<p>可以看到 UDP 也是妥妥的</p>

<hr />

<p>然後我就很好奇，如果只傳一個 <code class="language-plaintext highlighter-rouge">hello world</code> 過去會發生什麼事情<br />
為了觀察沒有給定 PRI 的資料，config 要稍微更改一下</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>$ISODATE $PRI $HOST $(format-welf --scope all-nv-pairs)\n
</pre></td></tr></tbody></table></code></pre></div></div>
<p>多加一個 <code class="language-plaintext highlighter-rouge">\$PRI</code> 讓我們觀察</p>

<p><img src="/assets/img/posts/syslog-3164-4.png" alt="" /></p>

<p><img src="/assets/img/posts/syslog-3164-5.png" alt="" /></p>

<p>神奇了！ 居然會過？？？？<br />
你可以看到說，<code class="language-plaintext highlighter-rouge">timestamp</code>、<code class="language-plaintext highlighter-rouge">priority</code> 甚至是 <code class="language-plaintext highlighter-rouge">hostname</code> 都有被正確的指派<br />
這肯定是我們漏掉了什麼</p>

<p>其實 <a href="#rfc-3164">RFC 3164</a> 中提到說，如果沒有給定以上三者的資料 他會自己幫你補齊</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">hostname</code> 會填自己的 hostname(而 <code class="language-plaintext highlighter-rouge">192.168.215.1</code> 正是我的 container 的 IP)</li>
  <li><code class="language-plaintext highlighter-rouge">timestamp</code> 會填現在的時間(你可以看到資料時間其實是早於 Syslog connection accepted 的時間)</li>
  <li><code class="language-plaintext highlighter-rouge">priority</code> 會填 <code class="language-plaintext highlighter-rouge">13</code>(user-level + notice)</li>
</ul>

<blockquote>
  <p>取得 container 的 IP 可以用 <code class="language-plaintext highlighter-rouge">$ docker inspect &lt;container_id&gt;</code></p>
</blockquote>

<p>也就是說，其實你隨便打都會過 3164 的格式<br />
因為他會幫你自動帶入這些資料<br />
所以其實不是不會驗格式，是他會幫你補齊</p>

<h2 id="invalid-frame-header-with-rfc-5424">Invalid Frame Header with RFC 5424?</h2>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"&lt;34&gt;1 2025-06-20T01:27:42Z myhostname myapp 12345 99 - [exampleSDID@32473 iut="</span>1<span class="s2">" eventSource="</span>application<span class="s2">" eventID="</span>1011<span class="s2">"] Test message content"</span> | nc localhost 601
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/assets/img/posts/syslog-5424-1.png" alt="" /></p>

<p>恩？ Invalid Frame Header<br />
這其實是因為稍早我們提過的 <a href="#non-transparent-framing">Non-transparent Framing</a> 的問題<br />
所以我們要新增長度方便進行切割(i.e. <a href="#octet-counting">Octet Counting</a>)</p>

<p>上述資料長度可以透過以下指令取得</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"&lt;34&gt;1 2025-06-20T01:27:42Z myhostname myapp 12345 99 - [exampleSDID@32473 iut="</span>1<span class="s2">" eventSource="</span>application<span class="s2">" eventID="</span>1011<span class="s2">"] Test message content"</span> | <span class="nb">wc</span> <span class="nt">-c</span>
139
</pre></td></tr></tbody></table></code></pre></div></div>

<p>所以完整的指令會是</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-n</span> <span class="s2">"139 &lt;34&gt;1 2025-06-20T01:27:42Z myhostname myapp 12345 99 - [exampleSDID@32473 iut="</span>1<span class="s2">" eventSource="</span>application<span class="s2">" eventID="</span>1011<span class="s2">"] Test aessage content"</span> | nc localhost 601
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/assets/img/posts/syslog-5424-2.png" alt="" /></p>

<p><img src="/assets/img/posts/syslog-5424-3.png" alt="" /></p>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://betterstack.com/community/questions/what-are-the-syslog-formats/">What are Syslog formats?</a></li>
  <li><a href="https://support.oneidentity.com/technical-documents/syslog-ng-open-source-edition/3.16/release-notes/default-network-drivers-receive-and-parse-common-syslog-messages">syslog-ng Open Source Edition 3.16 - Release Notes</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Syslog">Syslog</a></li>
  <li><a href="https://superuser.com/questions/59093/difference-between-host-name-and-domain-name">Difference between host name and domain name</a></li>
  <li><a href="https://stackoverflow.com/questions/17446491/tcp-stream-vs-udp-message">TCP stream vs UDP message</a></li>
  <li><a href="https://networkengineering.stackexchange.com/questions/76459/what-is-the-minimum-mtu-of-ipv4-68-bytes-or-576-bytes">What is the minimum MTU of IPv4 68 bytes or 576 bytes?</a></li>
  <li><a href="https://hackmd.io/@hiiii/SklQV_JtR">Syslog 和 RFC 5424 分類的實際用途</a></li>
  <li><a href="https://stackoverflow.com/questions/17157721/how-to-get-a-docker-containers-ip-address-from-the-host">How to get a Docker container’s IP address from the host</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="random" /><category term="syslog" /><category term="network" /><category term="tcp" /><category term="udp" /><category term="syslog-ng" /><category term="rfc" /><category term="rfc3164" /><category term="rfc5424" /><category term="fragmentation" /><category term="non-transparent framing" /><category term="octet counting" /><category term="priority" /><category term="facility" /><category term="severity" /><category term="timestamp" /><category term="hostname" /><category term="app-name" /><category term="procid" /><category term="msgid" /><category term="sd-id" /><category term="sd-param-name" /><category term="sd-param-value" /><category term="msg" /><category term="rfc-3339" /><category term="rfc-1034" /><category term="rfc-5426" /><category term="rfc-6587" /><category term="client-server" /><category term="docker" /><category term="nc" /><category term="wc" /><summary type="html"><![CDATA[只有 application log 在某些情況下是不足的，為了能夠監控整體系統，我們需要 Syslog 來幫助我們。本篇文章將會帶你了解 Syslog 的歷史，以及如何使用 syslog-ng 架設 Server 並觀察 Log 的傳輸]]></summary></entry><entry><title type="html">神奇的演算法 - 分組的好朋友 Union Find</title><link href="https://ambersuncreates.com/algorithm/algorithm-union-find/" rel="alternate" type="text/html" title="神奇的演算法 - 分組的好朋友 Union Find" /><published>2025-06-12T00:00:00+08:00</published><updated>2025-06-12T01:50:02+08:00</updated><id>https://ambersuncreates.com/algorithm/algorithm-union-find</id><content type="html" xml:base="https://ambersuncreates.com/algorithm/algorithm-union-find/"><![CDATA[<h1 id="introduction-to-union-find">Introduction to Union Find</h1>
<p><code class="language-plaintext highlighter-rouge">Disjoint Set</code> 是一種資料結構，用來管理一組互不相交的集合（disjoint sets）。每個集合中的元素都是唯一的，且不同集合之間沒有共同的元素。</p>

<p>而 <code class="language-plaintext highlighter-rouge">Union Find</code> 是 <code class="language-plaintext highlighter-rouge">Disjoint Set</code> 的另一個名稱，因為這個資料結構主要支援兩種操作：</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">Find</code>: 查詢某個元素屬於哪個集合</li>
  <li><code class="language-plaintext highlighter-rouge">Union</code>: 將兩個集合合併成一個新的集合</li>
</ol>

<h2 id="grouping-with-hash-map">Grouping with Hash Map</h2>
<p>而如果只是單純分組，是不是能透過 hash map 達成就行了？<br />
是沒錯，但是單純的 hash map 在處理不同組別合併的時候就會很麻煩</p>

<p>比如說 <code class="language-plaintext highlighter-rouge">group 1</code> 要跟 <code class="language-plaintext highlighter-rouge">group 2</code> 合併<br />
你需要找出所有 <code class="language-plaintext highlighter-rouge">group 2</code> 的人，然後一一更改至 <code class="language-plaintext highlighter-rouge">group 1</code><br />
這部分是需要找尋所有的 element 然後更新分組號碼</p>

<p>每一次都需要 $O(n)$，這個效能並不好<br />
並且多個群組的合併也需要更小心的操作<br />
比如說 (<code class="language-plaintext highlighter-rouge">group 0</code>, <code class="language-plaintext highlighter-rouge">group 1</code>) 要跟 (<code class="language-plaintext highlighter-rouge">group 2</code>, <code class="language-plaintext highlighter-rouge">group 3</code>) 合併<br />
這就會需要手動處理更多 corner case</p>

<h2 id="how-disjoint-set-works">How Disjoint Set Works</h2>
<p>Disjoint Set 採取了不同的做法<br />
既然是分組嘛，所以核心的思想是，<strong>相同組別的人，其編號必定相同</strong><br />
一開始每個元素都是自己一組的，每一組都有編號(可以假設 element <code class="language-plaintext highlighter-rouge">n</code> 是 group <code class="language-plaintext highlighter-rouge">n</code>)</p>

<p>那要怎麼合併呢？<br />
前面提到相同組別一定擁有相同的編號<br />
考慮以下例子，<code class="language-plaintext highlighter-rouge">element 1</code> 與 <code class="language-plaintext highlighter-rouge">element 2</code> 合併就會是</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>element 1: group 1
element 2: group 2

to

element 1: group 1
element 2: group 1
</pre></td></tr></tbody></table></code></pre></div></div>

<p>我們是不是可以把這個看做是 <code class="language-plaintext highlighter-rouge">Tree</code> 呢？<br />
每一個組別都是一個巨大的樹狀結構，而編號就是 <strong>根節點</strong><br />
也就是說，合併的過程其實就只是將 node 新增到該樹而已</p>

<p>不過要注意的是，要相連的是 <strong><em>兩元素的根節點</em></strong><br />
並不是單純的兩元素的 group number<br />
原因在於 group number 有可能只是 <code class="language-plaintext highlighter-rouge">child node</code> :heavy_check_mark:</p>

<p>針對多個群組合併</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>element 1: group 1
element 2: group 1

element 3: group 3
element 4: group 3
</pre></td></tr></tbody></table></code></pre></div></div>

<p>假設 <code class="language-plaintext highlighter-rouge">element 2</code> 跟 <code class="language-plaintext highlighter-rouge">element 3</code> 合併<br />
也就是會變成全部的元素都在同一組別底下</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>element 1: group 1
element 2: group 1
element 3: group 1
element 4: group 3 &lt;-- child node
</pre></td></tr></tbody></table></code></pre></div></div>

<p>但是你可以發現 <code class="language-plaintext highlighter-rouge">element 4</code> 的組別還沒更新<br />
這個就呼應到說 group number 有可能只是 <code class="language-plaintext highlighter-rouge">child node</code> 的 case 了<br />
所以在查詢 <code class="language-plaintext highlighter-rouge">element 4</code> 的組別的時候依然要查詢 <strong>根節點</strong><br />
這部分偏向 lazy loading 啦，有用到的才更新</p>

<blockquote>
  <p>那如果是更新 <code class="language-plaintext highlighter-rouge">element 4</code> 呢？ <code class="language-plaintext highlighter-rouge">element 3</code> 的組別號碼是不是也會出問題？<br />
搭配 <a href="#tree-compression">Tree Compression</a> 會是正確的</p>
</blockquote>

<h2 id="tree-compression">Tree Compression</h2>
<p>雖然說組別內部可能會存在 child node<br />
他最終都會指向 <strong>根節點</strong> 沒錯，但如果子節點過多會導致查詢效率低落<br />
因此我們需要對他做一定的優化</p>

<p>這個方法稱為 <code class="language-plaintext highlighter-rouge">路徑壓縮</code><br />
因為我們其實不太在乎 <strong>根節點以外的節點</strong><br />
我只想知道組別號碼是多少而已</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="k">func</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span> <span class="p">[]</span><span class="kt">int</span><span class="p">,</span> <span class="n">root</span> <span class="kt">int</span><span class="p">)</span> <span class="p">([]</span><span class="kt">int</span><span class="p">,</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">]</span> <span class="o">==</span> <span class="n">root</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">m</span><span class="p">,</span> <span class="n">root</span>
    <span class="p">}</span>

    <span class="k">var</span> <span class="n">parent</span> <span class="kt">int</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">parent</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">])</span>
    <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">]</span> <span class="o">=</span> <span class="n">parent</span>
    <span class="k">return</span> <span class="n">m</span><span class="p">,</span> <span class="n">parent</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>透過遞迴的方式逐一尋找根節點的數值，然後一一更新回去所有路徑上的子節點<br />
這樣可以保證說查詢的時候只需要 look up 一次就可以得到正確答案</p>

<h2 id="leetcode-1061-lexicographically-smallest-equivalent-string"><a href="https://leetcode.com/problems/lexicographically-smallest-equivalent-string/description/">LeetCode 1061. Lexicographically Smallest Equivalent String</a></h2>
<p>這題給定你兩個字串陣列，<code class="language-plaintext highlighter-rouge">s1</code> 與 <code class="language-plaintext highlighter-rouge">s2</code> 是可以互相置換的，也就是說 <code class="language-plaintext highlighter-rouge">s1[i] == s2[i]</code><br />
然後在給定你一個字串 <code class="language-plaintext highlighter-rouge">baseStr</code>，要求你使用上述置換陣列轉換 <code class="language-plaintext highlighter-rouge">baseStr</code> 使其結果為字典序最小</p>

<p>因為這個置換陣列是有可能存在 chaining 的關係的<br />
比如說 <code class="language-plaintext highlighter-rouge">'e' == 'o'</code> 然後 <code class="language-plaintext highlighter-rouge">'a' == 'e'</code>，可以得到 <code class="language-plaintext highlighter-rouge">'a' == 'o'</code><br />
也因此你可以將置換陣列的內容分組，以上述來說 <code class="language-plaintext highlighter-rouge">'a', 'e' 以及 'o'</code> 為同一組<br />
然後答案要是字典序最小的，那也很容易，分組編號設定為字典序最小的即可</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
</pre></td><td class="rouge-code"><pre><span class="k">func</span> <span class="n">smallestEquivalentString</span><span class="p">(</span><span class="n">s1</span> <span class="kt">string</span><span class="p">,</span> <span class="n">s2</span> <span class="kt">string</span><span class="p">,</span> <span class="n">base</span> <span class="kt">string</span><span class="p">)</span> <span class="kt">string</span> <span class="p">{</span>
    <span class="n">m</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">([]</span><span class="kt">int</span><span class="p">,</span> <span class="m">26</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">:=</span> <span class="m">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="m">26</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span> <span class="p">{</span>
        <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">i</span> <span class="o">:=</span> <span class="m">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span> <span class="p">{</span>
        <span class="n">c1</span> <span class="o">:=</span> <span class="kt">int</span><span class="p">(</span><span class="n">s1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="sc">'a'</span><span class="p">)</span>
        <span class="n">c2</span> <span class="o">:=</span> <span class="kt">int</span><span class="p">(</span><span class="n">s2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="sc">'a'</span><span class="p">)</span>

        <span class="n">rootC1</span> <span class="o">:=</span> <span class="n">get</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">c1</span><span class="p">)</span>
        <span class="n">rootC2</span> <span class="o">:=</span> <span class="n">get</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">c2</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">rootC1</span> <span class="o">&lt;</span> <span class="n">rootC2</span> <span class="p">{</span>
            <span class="n">m</span><span class="p">[</span><span class="n">rootC2</span><span class="p">]</span> <span class="o">=</span> <span class="n">rootC1</span>
            <span class="n">m</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">rootC2</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">m</span><span class="p">[</span><span class="n">rootC1</span><span class="p">]</span> <span class="o">=</span> <span class="n">rootC2</span>
            <span class="n">m</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">rootC1</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="n">result</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">([]</span><span class="kt">string</span><span class="p">,</span> <span class="m">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">:=</span> <span class="m">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">base</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span> <span class="p">{</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">append</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="kt">string</span><span class="p">(</span><span class="n">get</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="kt">int</span><span class="p">(</span><span class="n">base</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="sc">'a'</span><span class="p">))</span> <span class="o">+</span> <span class="sc">'a'</span><span class="p">))</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">strings</span><span class="o">.</span><span class="n">Join</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">get</span><span class="p">(</span><span class="n">m</span> <span class="p">[]</span><span class="kt">int</span><span class="p">,</span> <span class="n">root</span> <span class="kt">int</span><span class="p">)</span> <span class="kt">int</span> <span class="p">{</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">]</span> <span class="o">==</span> <span class="n">root</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">root</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">get</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">])</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span> <span class="p">[]</span><span class="kt">int</span><span class="p">,</span> <span class="n">root</span> <span class="kt">int</span><span class="p">)</span> <span class="p">([]</span><span class="kt">int</span><span class="p">,</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">]</span> <span class="o">==</span> <span class="n">root</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">m</span><span class="p">,</span> <span class="n">root</span>
    <span class="p">}</span>

    <span class="k">var</span> <span class="n">parent</span> <span class="kt">int</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">parent</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">])</span>
    <span class="n">m</span><span class="p">[</span><span class="n">root</span><span class="p">]</span> <span class="o">=</span> <span class="n">parent</span>
    <span class="k">return</span> <span class="n">m</span><span class="p">,</span> <span class="n">parent</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>你可以看到說，為了找到組別內字典序最小的字母，因此在合併的時候其實是有多了一個判斷的</p>
<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="k">if</span> <span class="n">rootC1</span> <span class="o">&lt;</span> <span class="n">rootC2</span> <span class="p">{</span>
    <span class="n">m</span><span class="p">[</span><span class="n">rootC2</span><span class="p">]</span> <span class="o">=</span> <span class="n">rootC1</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">rootC2</span><span class="p">)</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="n">m</span><span class="p">[</span><span class="n">rootC1</span><span class="p">]</span> <span class="o">=</span> <span class="n">rootC2</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">rootC1</span><span class="p">)</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>如果今天沒有這個限制，隨便指派一個並不會出問題<br />
也就是針對一般的 Union Find 來說，你只需要 <code class="language-plaintext highlighter-rouge">m[rootC1] = rootC2</code> 即可<br />
因為是更改最上層的組別編號，所以在查詢的時候依然可以得到正確答案</p>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Disjoint-set_data_structure">Disjoint-set data structure</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Minimum_spanning_tree">Minimum spanning tree</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="algorithm" /><category term="union find" /><category term="disjoint set" /><category term="tree compression" /><category term="leetcode-1061" /><category term="leetcode-1584" /><summary type="html"><![CDATA[考慮到分組的問題，如果需要複雜的操作，Hash Map 可能會有點麻煩，因此我們需要一個更有效率的方式來管理分組，Union Find 就是一個很好的選擇。本篇將介紹 Union Find 的原理與實作，並且透過實際的題目來加深理解。]]></summary></entry><entry><title type="html">Kubernetes 從零開始 - Sidecar 與 Lifecycle Hook 組合技</title><link href="https://ambersuncreates.com/kubernetes/kubernetes-sidecar/" rel="alternate" type="text/html" title="Kubernetes 從零開始 - Sidecar 與 Lifecycle Hook 組合技" /><published>2025-05-18T00:00:00+08:00</published><updated>2025-11-23T22:32:20+08:00</updated><id>https://ambersuncreates.com/kubernetes/kubernetes-sidecar</id><content type="html" xml:base="https://ambersuncreates.com/kubernetes/kubernetes-sidecar/"><![CDATA[<h1 id="multiple-container-in-pod">Multiple Container in Pod</h1>
<p>誠如我們之前在 <a href="../../kubernetes/kubernetes-pod">Kubernetes 從零開始 - 容器基本抽象 Pod | Shawn Hsu</a> 裡面提到的<br />
Pod 本身其實可以執行多個 Container，只是說平常大家習慣是一個 Pod 一個 Container 而已</p>

<p>不過也是有 use case 是會需要使用到多個 Container 的<br />
比方說你可能會需要一個額外的 Container 負責執行背景程序，輔助功能取向的任務<br />
Logging 或者是監控等任務就非常適合使用多個 Container 的架構</p>

<p>也有可能是因為 legacy 的關係，導致多個 Container 必須共用同一個 Pod 的資源</p>

<h2 id="multiple-container-pattern">Multiple Container Pattern</h2>
<p>而多 Container 的架構在 Kubernetes 來說有幾個常見的 pattern</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Ambassador</th>
      <th>Adapter</th>
      <th>Sidecar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Description</td>
      <td>透過 Ambassador Container 負責轉發對外請求，封裝內部邏輯</td>
      <td>將 Container 的輸出進行轉換，類似攔截器的設計</td>
      <td>擴充現有 Container 的功能</td>
    </tr>
    <tr>
      <td>Example</td>
      <td><img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Ha7oD8m7La4EEdYGs2s4eg.png" alt="" /> <br /> ref: <a href="https://medium.com/@techiemanoj4/multi-container-pod-design-patterns-4a085d376965">Multi-Container Pod Design Patterns</a></td>
      <td><img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*V_Aa09VQbXsQEuQlyVPaMg.png" alt="" /> <br /> ref: <a href="https://medium.com/@techiemanoj4/multi-container-pod-design-patterns-4a085d376965">Multi-Container Pod Design Patterns</a></td>
      <td><img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*9VKzudK0vSxYzroCEgFa7Q.png" alt="" /> <br /> ref: <a href="https://medium.com/@techiemanoj4/multi-container-pod-design-patterns-4a085d376965">Multi-Container Pod Design Patterns</a></td>
    </tr>
  </tbody>
</table>

<p>其實你會發現說，每一種 Container Pattern 都長得很像<br />
注意到，他們只是實作的方式很像，但最終要達成的目的是不同的</p>

<h1 id="introduction-to-sidecar-container">Introduction to Sidecar Container</h1>
<p>Sidecar Container 是與 main application container 一起執行的 <strong>輔助容器</strong><br />
他們多半使用提供輔助功能如 Logging, Monitoring 等等的任務</p>

<p>其實不論是 <code class="language-plaintext highlighter-rouge">Ambassador</code> 還是 <code class="language-plaintext highlighter-rouge">Adapter</code>, 他們皆使用多個 Container 的架構<br />
你可以說，<code class="language-plaintext highlighter-rouge">Sidecar</code> 是最常見的一種，因為 <code class="language-plaintext highlighter-rouge">Ambassador</code> 與 <code class="language-plaintext highlighter-rouge">Adapter</code> 某種程度上來說也是 <strong>擴充了原本 Container 的功能</strong></p>

<blockquote>
  <p>也因此現在 Sidecar Container 有點變成是個統稱了</p>
</blockquote>

<p>他要怎麼達到擴充的功能？<br />
別忘了，在同一個 Pod 底下，所有的 Container 共享所有的資源，包含 Network, CPU/Memory 以及 Volume 等等<br />
因此，<code class="language-plaintext highlighter-rouge">Sidecar</code> Container 可以透過存取其共享資源以達到擴充的目的<br />
舉例來說，如果要擴充 Logging 的功能，你可以設定 Logger 除了顯示在 console 上，也可以額外 Fan-out 到檔案裡頭，然後透過 <code class="language-plaintext highlighter-rouge">Sidecar</code> Container 負責後續的處理<br />
或是以攔截封包來說，可以額外掛一個 <code class="language-plaintext highlighter-rouge">tcpdump</code> 截取所有執行過程中的封包</p>

<h2 id="different-ways-to-implement-sidecar">Different Ways to Implement Sidecar</h2>
<h3 id="the-old-way">The Old Way</h3>
<p>在 Kubernetes <code class="language-plaintext highlighter-rouge">1.28</code> 之前，你能夠定義多個 container 在 <code class="language-plaintext highlighter-rouge">spec.containers</code> 底下<br />
不過這樣的問題在於，假設你需要控制啟動順序，你是沒辦法透過內建的機制來達成的<br />
這種做法只適合他們必須要一起 co-work 的場景</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
      <span class="s">image</span><span class="err">:</span> <span class="s">nginx</span>
      <span class="s">ports</span><span class="err">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">http</span>
          <span class="s">containerPort</span><span class="err">:</span> <span class="m">80</span>
      <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">web</span>
          <span class="s">mountPath</span><span class="err">:</span> <span class="s1">'</span><span class="s">/usr/share/nginx/html'</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">refresh</span>
      <span class="s">image</span><span class="err">:</span> <span class="s">alpine/git</span>
      <span class="s">command</span><span class="err">:</span>
      <span class="pi">-</span> <span class="s">sh</span>
      <span class="pi">-</span> <span class="s">-c</span>
      <span class="pi">-</span> <span class="s">watch -n 60 git pull</span>
      <span class="na">workingDir</span><span class="pi">:</span> <span class="s">/usr/share/nginx/html</span>
      <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">web</span>
          <span class="s">mountPath</span><span class="err">:</span> <span class="s1">'</span><span class="s">/usr/share/nginx/html'</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="the-new-way">The New Way</h3>
<p>新版本的 Sidecar Container 則是屬於 <code class="language-plaintext highlighter-rouge">initContainer</code> 的 special case<br />
與其讓他執行完就退出，Sidecar Container 引入了 <strong>container-level 的 restartPolicy</strong> 的欄位<br />
將其設定為 <code class="language-plaintext highlighter-rouge">Always</code> 就可以讓他一直存活下去<br />
其餘寫法則與一般的 initContainer 一樣</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">myapp</span>
      <span class="s">image</span><span class="err">:</span> <span class="s">alpine:latest</span>
      <span class="s">command</span><span class="err">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">sh'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">-c'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">while</span><span class="nv"> </span><span class="s">true;</span><span class="nv"> </span><span class="s">do</span><span class="nv"> </span><span class="s">echo</span><span class="nv"> </span><span class="s">"logging"</span><span class="nv"> </span><span class="s">&gt;&gt;</span><span class="nv"> </span><span class="s">/opt/logs.txt;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">1;</span><span class="nv"> </span><span class="s">done'</span><span class="pi">]</span>
      <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
          <span class="s">mountPath</span><span class="err">:</span> <span class="s">/opt</span>
  <span class="na">initContainers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">logshipper</span>
      <span class="s">image</span><span class="err">:</span> <span class="s">alpine:latest</span>
      <span class="s">restartPolicy</span><span class="err">:</span> <span class="s">Always</span>
      <span class="s">command</span><span class="err">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">sh'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">-c'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">tail</span><span class="nv"> </span><span class="s">-F</span><span class="nv"> </span><span class="s">/opt/logs.txt'</span><span class="pi">]</span>
      <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
          <span class="s">mountPath</span><span class="err">:</span> <span class="s">/opt</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
      <span class="s">emptyDir</span><span class="err">:</span> <span class="pi">{}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="sidecar-container-imagepullpolicy">Sidecar Container ImagePullPolicy</h2>
<p>我們知道，設定為 <code class="language-plaintext highlighter-rouge">Always</code> 的 <code class="language-plaintext highlighter-rouge">initContainer</code> 是 Sidecar Container<br />
如果你沒有指定 ImagePullPolicy 會發生什麼事情？</p>

<p>根據 <a href="https://kubernetes.io/docs/concepts/containers/images/#imagepullpolicy-defaulting">Default image pull policy</a> 所述</p>

<blockquote>
  <p>if you omit the <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> field, and you specify the digest for the container image, the <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> is automatically set to <code class="language-plaintext highlighter-rouge">IfNotPresent</code>.<br />
if you omit the <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> field, and the tag for the container image is <code class="language-plaintext highlighter-rouge">:latest</code>, <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> is automatically set to <code class="language-plaintext highlighter-rouge">Always</code>.<br />
if you omit the <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> field, and you don’t specify the tag for the container image, <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> is automatically set to <code class="language-plaintext highlighter-rouge">Always</code>.<br />
if you omit the <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> field, and you specify a tag for the container image that isn’t :latest, the <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> is automatically set to <code class="language-plaintext highlighter-rouge">IfNotPresent</code>.</p>
</blockquote>

<p>簡易好讀版就是</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">digest</code> :arrow_right: <code class="language-plaintext highlighter-rouge">IfNotPresent</code></li>
  <li><code class="language-plaintext highlighter-rouge">:latest</code> :arrow_right: <code class="language-plaintext highlighter-rouge">Always</code></li>
  <li>沒有 tag :arrow_right: <code class="language-plaintext highlighter-rouge">Always</code></li>
  <li>指定 tag 但不是 <code class="language-plaintext highlighter-rouge">:latest</code> :arrow_right: <code class="language-plaintext highlighter-rouge">IfNotPresent</code></li>
</ul>

<p>如果你的 initContainer 剛好使用 <code class="language-plaintext highlighter-rouge">:latest</code> tag, 你又剛好沒設定 <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> 的話<br />
那麼 <code class="language-plaintext highlighter-rouge">imagePullPolicy</code> 會被自動設定為 <code class="language-plaintext highlighter-rouge">Always</code><br />
換句話說，本來你可能是拿來做啟動檢查的 initContainer 會被自動升級成 Sidecar Container</p>

<p>而這顯然是有問題的，所以在使用 Sidecar Container 的時候，建議你還是明確的設定 <code class="language-plaintext highlighter-rouge">imagePullPolicy</code></p>

<h2 id="sidecar-container-feature-gate">Sidecar Container Feature Gate</h2>
<p>不過注意到，Kubernetes <code class="language-plaintext highlighter-rouge">1.28</code> 仍需要手動開啟相對應的 feature gate 才能使用</p>

<blockquote>
  <p>Kubernetes 1.28 adds a new restartPolicy field to init containers that is available when the SidecarContainers feature gate is enabled.</p>
</blockquote>

<p>你可以透過以下指令檢查是否已經開啟</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl get <span class="nt">--raw</span> /metrics | <span class="nb">grep </span>kubernetes_feature_enabled | <span class="nb">grep </span>Sidecar
kubernetes_feature_enabled<span class="o">{</span><span class="nv">name</span><span class="o">=</span><span class="s2">"SidecarContainers"</span>,stage<span class="o">=</span><span class="s2">"ALPHA"</span><span class="o">}</span> 0

<span class="nv">$ </span>kubectl version 
Client Version: v1.30.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.15+k3s1
</pre></td></tr></tbody></table></code></pre></div></div>
<p>可以看到說這台機器是 <code class="language-plaintext highlighter-rouge">1.28</code> 的版本，並且 feature gate 是關閉的(0: off, 1: on)</p>

<p><img src="/assets/img/posts/sidecar-1.28.png" alt="" /></p>

<p>至於說 <code class="language-plaintext highlighter-rouge">1.29</code> 版本，則是預設開啟的</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>kubectl get <span class="nt">--raw</span> /metrics | <span class="nb">grep </span>kubernetes_feature_enabled | <span class="nb">grep </span>Sidecar
kubernetes_feature_enabled<span class="o">{</span><span class="nv">name</span><span class="o">=</span><span class="s2">"SidecarContainers"</span>,stage<span class="o">=</span><span class="s2">"BETA"</span><span class="o">}</span> 1
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/assets/img/posts/sidecar-1.29.png" alt="" /></p>

<p>如果你是使用 <a href="https://k3d.io/">k3d</a> 來建立 cluster 的話，可以透過以下指令來手動開啟 feature gate</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>k3d cluster create mycluster <span class="se">\</span>
    <span class="nt">--image</span> rancher/k3s:v1.28.15-k3s1 <span class="se">\</span>
    <span class="nt">--k3s-arg</span> <span class="s1">'--kube-apiserver-arg=feature-gates=SidecarContainers=true@server:*'</span> <span class="se">\</span>
    <span class="nt">--k3s-arg</span> <span class="s1">'--kubelet-arg=feature-gates=SidecarContainers=true@agent:*'</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>如果是 K3s 只要開 <code class="language-plaintext highlighter-rouge">--kube-apiserver-arg</code> 即可</p>
</blockquote>

<p><img src="/assets/img/posts/sidecar-1.28-overwrite.png" alt="" /></p>

<h2 id="sidecar-container-lifecycle">Sidecar Container Lifecycle</h2>
<p>既然是作為輔助容器，很多時候你會要求</p>
<ol>
  <li>在主容器啟動之前就先啟動</li>
  <li>在主容器退出之後才退出</li>
</ol>

<blockquote>
  <p>比方說你要監聽所有出入封包，你肯定是不想要漏掉最前面以及最後面那幾個封包的<br />
這時候啟動順序就很重要了</p>
</blockquote>

<p>注意到 Sidecar Container 的生命週期是與 main application container 脫鉤的<br />
Sidecar Container <strong>擁有自己獨立的生命週期</strong>，他是可以被單獨啟動，終止甚至重啟的<br />
他沒辦法影響到其他 initContainer 的狀態，也沒辦法影響到 main application container 的狀態<br />
但是可以被反過來影響(可參考 <a href="#pod-termination">Pod Termination</a>)</p>

<h3 id="pod-initialization">Pod Initialization</h3>
<p>針對啟動的部分，因為 Sidecar Container 作為 initContainer 的 special case<br />
他本質上也是繼承了 initContainer 的特性，也就是說</p>
<ol>
  <li>他一定會按照 <code class="language-plaintext highlighter-rouge">spec.initContainers</code> 的正順序來啟動</li>
  <li>也表示他一定會在主容器之前啟動(因為只有 initContainer 都執行完畢，主容器才會啟動)</li>
</ol>

<blockquote>
  <p>你甚至可以將 一般 Init Container 與 Sidecar Container 混合在一起</p>
</blockquote>

<h3 id="pod-termination">Pod Termination</h3>
<p>當 main application container 要被終止的時候，<code class="language-plaintext highlighter-rouge">Kubelet</code> 會先處理 main application container 的終止流程<br />
直到它完成之後，才會開始處理 Sidecar Container 的終止流程</p>

<p>terminate 的流程剛好是 <strong>反過來的</strong>，會是 <code class="language-plaintext highlighter-rouge">spec.initContainers</code> 的逆順序(也就是先進後出)<br />
一個一個的停止，直到所有的 Sidecar Container 都終止為止</p>

<blockquote>
  <p>Sidecar Container 的 terminate 流程並不一定能完整執行<br />
Container 終止是有一個 deadline 的(稱為 <code class="language-plaintext highlighter-rouge">terminationGracePeriodSeconds</code>)<br />
如果超過這個時間，Kubernetes 會強制終止 Container</p>
</blockquote>

<h2 id="sidecar-container-probes">Sidecar Container Probes</h2>
<p>Sidecar Container 是支援 Probe 的<br />
因為他是個 long live 的 container 嘛，所以該有的 Liveness, Readiness 都有</p>

<p>有關 Probe 的討論可以參考 <a href="../../kubernetes/kubernetes-self-healing">Kubernetes 從零開始 - Self Healing 是如何運作的 | Shawn Hsu</a></p>

<h2 id="sidecar-in-different-workloads">Sidecar in Different Workloads</h2>
<p>前面有提到說，Sidecar Container 的生命週期是與 main application container 脫鉤的<br />
<strong><em>Sidecar Container 不能影響到其他人，但別人可以影響到他</em></strong></p>

<blockquote>
  <p>可參考 <a href="#sidecar-container-lifecycle">Sidecar Container Lifecycle</a></p>
</blockquote>

<p>以 <code class="language-plaintext highlighter-rouge">Job</code> 來說，只要 main application container 終止了，Sidecar Container 也會跟著終止<br />
但如果是 <code class="language-plaintext highlighter-rouge">Deployment</code>，因為他會有重啟的機制，所以 Sidecar Container 也會跟著重啟<br />
你的 Sidecar Container 就會執行無數次</p>

<blockquote>
  <p>有關不同 Workload 的特性可以參考 <a href="../../kubernetes/kubernetes-workloads">Kubernetes 從零開始 - 高階抽象 Workload Resources | Shawn Hsu</a></p>
</blockquote>

<h1 id="container-lifecycle-hook">Container Lifecycle Hook</h1>
<p>Lifecycle Hook 就是可以允許你額外在特定階段執行一些額外的邏輯<br />
目前 Kubernetes 提供了兩種 Hook 的機制</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Type</th>
      <th style="text-align: left">Description</th>
      <th style="text-align: left">Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><code class="language-plaintext highlighter-rouge">postStart</code></td>
      <td style="text-align: left">在 Container 啟動之後執行</td>
      <td style="text-align: left">與 Container 的啟動流程同步，但不保證誰先執行完</td>
    </tr>
    <tr>
      <td style="text-align: center"><code class="language-plaintext highlighter-rouge">preStop</code></td>
      <td style="text-align: left">在 Container 被終止之前執行</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">preStop</code> Hook 會在 Container 終止之前執行，但不一定可以執行完</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>還有額外的一種 <code class="language-plaintext highlighter-rouge">stopSignal</code> 可以 overwrite 掉 container 的預設終止訊號<br />
ref: <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination-stop-signals">Define custom stop signals</a></p>
</blockquote>

<p>你能夠設定以下不同的 Hook Handler 在上述時間點上執行</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Type</th>
      <th style="text-align: left">Description</th>
      <th style="text-align: left">Executor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><code class="language-plaintext highlighter-rouge">Exec</code></td>
      <td style="text-align: left">執行一個命令</td>
      <td style="text-align: left">Container</td>
    </tr>
    <tr>
      <td style="text-align: center"><code class="language-plaintext highlighter-rouge">HTTP</code></td>
      <td style="text-align: left">對一個 HTTP 端點發送請求</td>
      <td style="text-align: left">Kubelet</td>
    </tr>
    <tr>
      <td style="text-align: center"><code class="language-plaintext highlighter-rouge">Sleep</code></td>
      <td style="text-align: left">暫停一段時間</td>
      <td style="text-align: left">Kubelet</td>
    </tr>
  </tbody>
</table>

<h2 id="lifecycle-hook-delivery">Lifecycle Hook Delivery</h2>
<p>以上兩種 lifecycle hook 的機制，保證會至少執行一次(i.e. <code class="language-plaintext highlighter-rouge">at least once</code>)<br />
在某些極端情況下，hook 會被執行超過一次<br />
也因此，在設計 hook 的時候，你需要將其設計為 idempotent 的</p>

<h2 id="example">Example</h2>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="na">volumeMounts</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
    <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/opt</span>
<span class="na">lifecycle</span><span class="pi">:</span>
  <span class="na">preStop</span><span class="pi">:</span>
    <span class="na">exec</span><span class="pi">:</span>
    <span class="na">command</span><span class="pi">:</span>
      <span class="pi">[</span>
        <span class="s2">"</span><span class="s">sh"</span><span class="pi">,</span>
        <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span>
        <span class="s1">'</span><span class="s">printf</span><span class="nv"> </span><span class="s">"$(date</span><span class="nv"> </span><span class="s">+"%T.%N")</span><span class="nv"> </span><span class="s">stopping</span><span class="nv"> </span><span class="s">prestop\n"</span><span class="nv"> </span><span class="s">&gt;&gt;</span><span class="nv"> </span><span class="s">/opt/logs.txt'</span><span class="pi">,</span>
      <span class="pi">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="lifecycle-hook-log">Lifecycle Hook Log</h2>
<p>你可能會發現說，<code class="language-plaintext highlighter-rouge">preStop</code> 的 printf 並不會顯示在 kubectl logs 上<br />
Kubernetes 並不會將 Hook Handler Log 接上 Pod Event<br />
所以無論如何你都看不到執行的 Log</p>

<p>取而代之的是會 broadcast 相對應的 Pod Event，如果失敗</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">preStop</code> 會 broadcast <code class="language-plaintext highlighter-rouge">FailedPreStopHook</code> event</li>
  <li><code class="language-plaintext highlighter-rouge">postStart</code> 會 broadcast <code class="language-plaintext highlighter-rouge">FailedPostStartHook</code> event</li>
</ul>

<p>怎麼觸發呢？ 把指令改成壞的就可以了</p>

<p><img src="/assets/img/posts/sidecar2.png" alt="" /></p>

<h1 id="tcpdump-sidecar-container-example">Tcpdump Sidecar Container Example</h1>
<h2 id="environment">Environment</h2>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>k3d <span class="nt">--version</span>
k3d version v5.7.1
k3s version v1.29.6-k3s1 <span class="o">(</span>default<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="example-1">Example</h2>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre></td><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">batch/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Job</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">myjob</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">main-container</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">curlimages/curl</span>
          <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">sh"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">curl</span><span class="nv"> </span><span class="s">google.com"</span><span class="pi">]</span>
          <span class="na">volumeMounts</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
              <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/opt</span>
      <span class="na">initContainers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">upload-logs</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">nicolaka/netshoot</span>
          <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Always</span>
          <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">sh"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">sleep</span><span class="nv"> </span><span class="s">86400"</span><span class="pi">]</span>
          <span class="na">volumeMounts</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
              <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/opt</span>
          <span class="na">lifecycle</span><span class="pi">:</span>
            <span class="na">preStop</span><span class="pi">:</span>
              <span class="na">exec</span><span class="pi">:</span>
                <span class="na">command</span><span class="pi">:</span>
                  <span class="pi">[</span>
                    <span class="s2">"</span><span class="s">sh"</span><span class="pi">,</span>
                    <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span>
                    <span class="s2">"</span><span class="s">curl</span><span class="nv"> </span><span class="s">-X</span><span class="nv"> </span><span class="s">POST</span><span class="nv"> </span><span class="s">https://webhook.site/bee40c4c-07a5-42bb-b2af-c24e3f4ea693</span><span class="nv"> </span><span class="s">--data-binary</span><span class="nv"> </span><span class="s">@/opt/tcpdump.pcap"</span><span class="pi">,</span>
                  <span class="pi">]</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">tcpdump</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">nicolaka/netshoot</span>
          <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Always</span>
          <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">sh"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">tcpdump</span><span class="nv"> </span><span class="s">-i</span><span class="nv"> </span><span class="s">any</span><span class="nv"> </span><span class="s">-w</span><span class="nv"> </span><span class="s">/opt/tcpdump.pcap"</span><span class="pi">]</span>
          <span class="na">volumeMounts</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
              <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/opt</span>
      <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
      <span class="na">volumes</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data</span>
          <span class="na">emptyDir</span><span class="pi">:</span> <span class="pi">{}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<blockquote>
  <p>Webhook 的測試站點可以參考 <a href="https://webhook.site/">Webhook.site</a></p>
</blockquote>

<p>以上是一個簡易的 Sidecar Container 的範例<br />
這裡我初始化了兩個 Sidecar, 一個是負責 tcpdump 的封包擷取，一個是負責將封包傳送到 Webhook 上<br />
而主容器則是負責發出請求</p>

<p>注意到 <code class="language-plaintext highlighter-rouge">upload-logs</code> 是排第一個<br />
前面提到 Sidecar Container 啟動以及終止的順序 <strong>是跟 <code class="language-plaintext highlighter-rouge">spec.initContainers</code> 的順序有關</strong><br />
這裡 <code class="language-plaintext highlighter-rouge">upload-logs</code> 是排第一個是因為我想要讓他在 terminate 的時候是 <strong>最後執行的</strong></p>

<h2 id="the-reason-killing">The Reason “Killing”</h2>
<p><img src="/assets/img/posts/sidecar1.png" alt="" /></p>

<p>在 describe pod 的時候<br />
奇怪？ 為什麼 <code class="language-plaintext highlighter-rouge">upload-logs</code> 以及 <code class="language-plaintext highlighter-rouge">tcpdump</code> 都有一個 <code class="language-plaintext highlighter-rouge">Killing</code> Event 呢？<br />
答案其實也挺簡單的，因為 Sidecar Container 也是會被 Terminate 的(在 main container 之後)<br />
所以他只是單純的通知 Sidecar Container 要終止了</p>

<h2 id="the-sigterm-and-sigkill-signal">The SIGTERM and SIGKILL Signal</h2>
<p>在 <a href="#lifecycle-hook-log">Lifecycle Hook Log</a> 有提到說，你是看不到任何的 log 的<br />
你頂多只能根據 Event 來判斷 Sidecar Container 的狀態<br />
但也只是知道有沒有失敗而已，很明顯這樣是不足以滿足我們的需求的</p>

<p>我就好奇啦 到底我的兩個 Sidecar 的狀態如何<br />
<code class="language-plaintext highlighter-rouge">$ kubectl get pod myjob-xxx -o yaml &gt; log.yaml</code> 指令可以更詳細的看到 Pod 的狀態</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
</pre></td><td class="rouge-code"><pre><span class="na">containerStatuses</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">containerID</span><span class="pi">:</span> <span class="s">containerd://83d436fad827bb0568994380dcc771abdfcf406366148560a6484e787a2ad2ea</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">docker.io/curlimages/curl:latest</span>
    <span class="na">imageID</span><span class="pi">:</span> <span class="s">docker.io/curlimages/curl@sha256:d43bdb28bae0be0998f3be83199bfb2b81e0a30b034b6d7586ce7e05de34c3fd</span>
    <span class="na">lastState</span><span class="pi">:</span> <span class="pi">{}</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">main-container</span>
    <span class="na">ready</span><span class="pi">:</span> <span class="no">false</span>
    <span class="na">restartCount</span><span class="pi">:</span> <span class="m">0</span>
    <span class="na">started</span><span class="pi">:</span> <span class="no">false</span>
    <span class="na">state</span><span class="pi">:</span>
      <span class="na">terminated</span><span class="pi">:</span>
        <span class="na">containerID</span><span class="pi">:</span> <span class="s">containerd://83d436fad827bb0568994380dcc771abdfcf406366148560a6484e787a2ad2ea</span>
        <span class="na">exitCode</span><span class="pi">:</span> <span class="m">0</span>
        <span class="na">finishedAt</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-05-17T19:40:44Z"</span>
        <span class="na">reason</span><span class="pi">:</span> <span class="s">Completed</span>
        <span class="na">startedAt</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-05-17T19:40:44Z"</span>
  <span class="na">hostIP</span><span class="pi">:</span> <span class="s">192.168.97.3</span>
  <span class="na">hostIPs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">ip</span><span class="pi">:</span> <span class="s">192.168.97.3</span>
  <span class="na">initContainerStatuses</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">containerID</span><span class="pi">:</span> <span class="s">containerd://7d9c1ee00a12e5e078f34a5acdb4c823f8640a66285833344436b13a10ba16b7</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">docker.io/nicolaka/netshoot:latest</span>
    <span class="na">imageID</span><span class="pi">:</span> <span class="s">docker.io/nicolaka/netshoot@sha256:a20c2531bf35436ed3766cd6cfe89d352b050ccc4d7005ce6400adf97503da1b</span>
    <span class="na">lastState</span><span class="pi">:</span> <span class="pi">{}</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">upload-logs</span>
    <span class="na">ready</span><span class="pi">:</span> <span class="no">false</span>
    <span class="na">restartCount</span><span class="pi">:</span> <span class="m">0</span>
    <span class="na">started</span><span class="pi">:</span> <span class="no">false</span>
    <span class="na">state</span><span class="pi">:</span>
      <span class="na">terminated</span><span class="pi">:</span>
        <span class="na">containerID</span><span class="pi">:</span> <span class="s">containerd://7d9c1ee00a12e5e078f34a5acdb4c823f8640a66285833344436b13a10ba16b7</span>
        <span class="na">exitCode</span><span class="pi">:</span> <span class="m">137</span>
        <span class="na">finishedAt</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-05-17T19:41:14Z"</span>
        <span class="na">reason</span><span class="pi">:</span> <span class="s">Error</span>
        <span class="na">startedAt</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-05-17T19:40:37Z"</span>
  <span class="pi">-</span> <span class="na">containerID</span><span class="pi">:</span> <span class="s">containerd://614b4873d23538f37d9f45cb26b084361d5da5a27bc943a149272ac876d58236</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">docker.io/nicolaka/netshoot:latest</span>
    <span class="na">imageID</span><span class="pi">:</span> <span class="s">docker.io/nicolaka/netshoot@sha256:a20c2531bf35436ed3766cd6cfe89d352b050ccc4d7005ce6400adf97503da1b</span>
    <span class="na">lastState</span><span class="pi">:</span> <span class="pi">{}</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">tcpdump</span>
    <span class="na">ready</span><span class="pi">:</span> <span class="no">false</span>
    <span class="na">restartCount</span><span class="pi">:</span> <span class="m">0</span>
    <span class="na">started</span><span class="pi">:</span> <span class="no">false</span>
    <span class="na">state</span><span class="pi">:</span>
      <span class="na">terminated</span><span class="pi">:</span>
        <span class="na">containerID</span><span class="pi">:</span> <span class="s">containerd://614b4873d23538f37d9f45cb26b084361d5da5a27bc943a149272ac876d58236</span>
        <span class="na">exitCode</span><span class="pi">:</span> <span class="m">0</span>
        <span class="na">finishedAt</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-05-17T19:40:44Z"</span>
        <span class="na">reason</span><span class="pi">:</span> <span class="s">Completed</span>
        <span class="na">startedAt</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-05-17T19:40:40Z"</span>
  <span class="na">phase</span><span class="pi">:</span> <span class="s">Succeeded</span>
  <span class="na">podIP</span><span class="pi">:</span> <span class="s">10.42.1.64</span>
  <span class="na">podIPs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">ip</span><span class="pi">:</span> <span class="s">10.42.1.64</span>
  <span class="na">qosClass</span><span class="pi">:</span> <span class="s">BestEffort</span>
  <span class="na">startTime</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2025-05-17T19:40:34Z"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>你要關心的是裡面的 <code class="language-plaintext highlighter-rouge">state</code><br />
可以看到說</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">main-container</code>: <strong>exitCode 0</strong>, 正常結束</li>
  <li><code class="language-plaintext highlighter-rouge">upload-logs</code>: <strong>exitCode 137</strong>, 被強制終止</li>
  <li><code class="language-plaintext highlighter-rouge">tcpdump</code>: <strong>exitCode 0</strong>, 正常結束</li>
</ul>

<p>恩？ 恩？？？<br />
為什麼 <code class="language-plaintext highlighter-rouge">upload-logs</code> 會被強制終止呢？</p>

<h3 id="pod-lifecycle">Pod Lifecycle</h3>
<p>我想要延伸一下 <a href="#pod-termination">Pod Termination</a> 的內容<br />
概念上還是一樣的，main container 結束之前，Sidecar Container 會繼續執行<br />
main container 結束之後才會開始處理 Sidecar Container</p>

<p>Kubernetes 要終止 Container 是發送 <code class="language-plaintext highlighter-rouge">SIGTERM</code> 的訊號(這也解釋了為什麼你在 describe pod 的時候會看到 <code class="language-plaintext highlighter-rouge">Killing</code> Event)<br />
而刪除這個動作並非是你可以慢慢做，他是有一個時間限制的(<code class="language-plaintext highlighter-rouge">terminationGracePeriodSeconds</code>, 預設 30 秒)</p>

<p>這個 terminationGracePeriodSeconds 是 <strong>所有 main container + 所有 Sidecar Container + 所有 lifecycle preStop 的終止時間總和</strong>，他們是共享的<br />
也就是說如果 main container 花了比較久的時間執行，那剩餘的時間就不多了<br />
如果真的執行不完怎麼辦？ Kubernetes 會強制終止(<code class="language-plaintext highlighter-rouge">SIGKILL</code>)</p>

<p>對於 Kubernetes 來說，Sidecar Container 能不能 Graceful shutdown 並沒那麼重要</p>

<p>所以整體流程會是</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">SIGTERM</code> 通知 Container 要終止了</li>
  <li>等待 <code class="language-plaintext highlighter-rouge">terminationGracePeriodSeconds</code> 的時間</li>
  <li>如果 Container 還沒結束，則強制終止(<code class="language-plaintext highlighter-rouge">SIGKILL</code>)</li>
</ol>

<h2 id="the-exit-code">The Exit Code</h2>
<p>所以顯然，<code class="language-plaintext highlighter-rouge">upload-logs</code> 的 exit code 並不是巧合<br />
而實際上也的確是因為他被強制終止了</p>

<blockquote>
  <p>注意到這裡的 exit code 是 Sidecar Container 本身的 exit code<br />
並不是 lifecycle hook 的 exit code(他會用 Event 表示, 可參考 <a href="#the-reason-killing">The Reason “Killing”</a>)</p>
</blockquote>

<ul>
  <li><code class="language-plaintext highlighter-rouge">SIGTERM</code> 的 exit code 是 <code class="language-plaintext highlighter-rouge">143</code> = <code class="language-plaintext highlighter-rouge">SIGNAL 15</code>(128 + 15)</li>
  <li><code class="language-plaintext highlighter-rouge">SIGKILL</code> 的 exit code 是 <code class="language-plaintext highlighter-rouge">137</code> = <code class="language-plaintext highlighter-rouge">SIGNAL 9</code>(128 + 9)</li>
</ul>

<p>雖然根據 <a href="https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/#differences-from-application-containers">Differences from application containers</a> 裡面它有提到說</p>

<blockquote>
  <p>So exit codes different from 0 (0 indicates successful exit), for sidecar containers are normal on Pod termination and should be generally ignored by the external tooling.</p>
</blockquote>

<p>但 沒道理啊<br />
為什麼單純的 sleep 會被強制終止？<br />
理應他會先收到 <code class="language-plaintext highlighter-rouge">SIGTERM</code> 然後如果真的超過時間，才會 <code class="language-plaintext highlighter-rouge">SIGKILL</code></p>

<p>原因在於，<code class="language-plaintext highlighter-rouge">sleep 86400</code> 在 Sidecar Container 裡面被覆寫為 pid 1<br />
pid 1 的 init process 要負責處理 <code class="language-plaintext highlighter-rouge">SIGTERM</code> 的訊號(以及通知 child process 終止)<br />
很明顯，單純的 sleep 並沒有處理這個訊號<br />
也因此他最終是被 <code class="language-plaintext highlighter-rouge">SIGKILL</code> 強制終止的</p>

<p>我們可以利用 <a href="https://man7.org/linux/man-pages/man1/trap.1p.html">trap</a> 來處理特定的訊號，以這個例子來說，就是 <code class="language-plaintext highlighter-rouge">SIGTERM</code><br />
然後將 <code class="language-plaintext highlighter-rouge">sleep</code> 指令放到 background process 並使用 <a href="https://man7.org/linux/man-pages/man2/wait.2.html">wait</a> 來攔截訊號</p>

<blockquote>
  <p>放到背景執行是因為，foreground process 會阻塞訊號直到完成</p>
</blockquote>

<p>所以改起來會是</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">trap</span> <span class="s1">'exit 0'</span> TERM<span class="p">;</span> <span class="nb">sleep </span>86400 &amp; <span class="nb">wait</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>這樣子，所有的 Sidecar Container 都能夠正常的結束</p>

<hr />

<p>以上，我們已經完全了解 Sidecar Container 的全部機制了</p>

<h1 id="comparison-with-different-container-types">Comparison with Different Container Types</h1>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Type</th>
      <th style="text-align: right">Application</th>
      <th style="text-align: right">Init</th>
      <th style="text-align: right">Sidecar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Definition location</td>
      <td style="text-align: right"><code class="language-plaintext highlighter-rouge">spec.containers</code></td>
      <td style="text-align: right"><code class="language-plaintext highlighter-rouge">spec.initContainers</code></td>
      <td style="text-align: right"><code class="language-plaintext highlighter-rouge">spec.containers</code> or <code class="language-plaintext highlighter-rouge">spec.initContainers</code></td>
    </tr>
    <tr>
      <td style="text-align: center">Lifecycle</td>
      <td style="text-align: right">Independent</td>
      <td style="text-align: right">Dependent</td>
      <td style="text-align: right">Independent</td>
    </tr>
    <tr>
      <td style="text-align: center">Probes</td>
      <td style="text-align: right">:heavy_check_mark:</td>
      <td style="text-align: right">:x:</td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: center">Share Resources</td>
      <td style="text-align: right">:heavy_check_mark:</td>
      <td style="text-align: right">:heavy_check_mark:</td>
      <td style="text-align: right">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td style="text-align: center">Communication</td>
      <td style="text-align: right">Bidirectional</td>
      <td style="text-align: right">Unidirectional</td>
      <td style="text-align: right">Bidirectional</td>
    </tr>
  </tbody>
</table>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://adil.medium.com/multi-container-patterns-in-kubernetes-adapter-ambassador-sidecar-40bddbe7c468">Multi-Container Patterns in Kubernetes: Adapter, Ambassador, Sidecar</a></li>
  <li><a href="https://learncloudnative.com/blog/2020-10-03-ambassador-pattern">Ambassador Container Pattern</a></li>
  <li><a href="https://learncloudnative.com/blog/2020-09-30-sidecar-container">Sidecar Container Pattern</a></li>
  <li><a href="https://medium.com/@techiemanoj4/multi-container-pod-design-patterns-4a085d376965">Multi-Container Pod Design Patterns</a></li>
  <li><a href="https://stackoverflow.com/questions/59451056/differences-between-sidecar-and-ambassador-and-adapter-pattern">Differences between Sidecar and Ambassador and Adapter pattern</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers">Sidecar Containers</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/">Container Lifecycle Hooks</a></li>
  <li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/">Attach Handlers to Container Lifecycle Events</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#termination-with-sidecars">Pod Lifecycle</a></li>
  <li><a href="https://komodor.com/learn/sigterm-signal-15-exit-code-143-linux-graceful-termination/">SIGTERM: Linux Graceful Termination | Exit Code 143, Signal 15</a></li>
  <li><a href="https://unix.stackexchange.com/questions/57940/trap-int-term-exit-really-necessary">“trap … INT TERM EXIT” really necessary?</a></li>
  <li><a href="https://stackoverflow.com/questions/78432948/cannot-trap-sigint-and-sigterm-when-using-sleep-infinity/78432970#78432970">Cannot trap SIGINT and SIGTERM when using “sleep infinity” [duplicate]</a></li>
  <li><a href="https://blog.csdn.net/qing101hua/article/details/93619508">shell中trap的使用</a></li>
  <li><a href="https://k3d.io/v5.8.3/faq/faq/">FAQ</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/containers/images/#imagepullpolicy-defaulting">Default image pull policy</a></li>
</ul>]]></content><author><name>Shawn Hsu</name><email>ambersun1019.shawn@gmail.com</email></author><category term="kubernetes" /><category term="sidecar" /><category term="container pattern" /><category term="ambassador" /><category term="adapter" /><category term="logging" /><category term="monitoring" /><category term="tcpdump" /><category term="init container" /><category term="liveness" /><category term="readiness" /><category term="probe" /><category term="lifecycle hook" /><category term="post start" /><category term="pre stop" /><category term="sigterm" /><category term="sigkill" /><category term="exit code" /><category term="signal" /><category term="trap" /><category term="wait" /><category term="sleep" /><category term="background process" /><category term="foreground process" /><category term="netshoot" /><category term="event" /><category term="killing event" /><category term="terminationGracePeriodSeconds" /><category term="feature gate" /><category term="image pull policy" /><summary type="html"><![CDATA[Kubernetes 1.28 之後引入了新版本的 Sidecar Container 的機制，本篇文章將會帶你深入了解如何利用 Sidecar Container 與 Lifecycle Hook 以建構複雜但優雅的架構，並以 Tcpdump 為例，探討 Kubernetes Event 與 Exit Code 是如何影響 Sidecar Container 的結束流程]]></summary></entry></feed>