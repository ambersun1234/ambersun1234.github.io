---
title: 資料庫 - 新手做 Data Migration 資料遷移
date: 2024-02-08
description: 隨著產品的不斷迭代，資料搬遷是一個不可避免的議題。本文將會介紹資料搬遷的一些基本觀念，以及一些可能會遇到的問題
categories: [database]
tags: [data migration, sql, prisma, nodejs, idempotent, transaction, postgresql, upsert, backward compatibility, on-premise, saas, golang, alembic, reversibility, atlas, checkpoint, kafka, kafka connect, cdc, change data capture, statement replication, logical log]
math: true
---

# Preface
資料搬遷，在現代軟體服務當中屬於較為常見的一種需求\
不論是單純的機器之間的搬資料抑或者是因應商業邏輯而需要做的資料搬遷\
都是屬於 Data Migration

本文將會專注在資料本身的 Migration\
也就是因應商業邏輯的調整

# Introduction to Data Migration
![](https://www.prisma.io/blog/posts/2020-12-migrate-production-workflow.png)
> ref: [Hassle-Free Database Migrations with Prisma Migrate](https://www.prisma.io/blog/prisma-migrate-ga-b5eno5g08d0b)

有的時候，你可能會需要針對資料庫的某個欄位做些微的更動\
比如說，增加 unique constraint 或者是設置 default value\
這些，其實就是資料搬遷的一種

以 [Prisma](https://www.prisma.io/) 來說\
每一次的搬遷，它都會新增一筆新的 entry\
針對該欄位的更新 sql 就會寫在裡面

> 各個語言其實都已經有不同的 Migration 工具\
> 如 Node.js 裡的 [Prisma](https://www.prisma.io/), Python 裡的 [Alembic](https://alembic.sqlalchemy.org/en/latest/) 以及 Golang 裡的 [golang-migrate](https://github.com/golang-migrate/migrate)

<hr>

不過這仍然是較為簡單的狀況\
真實世界可複雜的多\
商業邏輯的改變，資料搬遷的功會比想像中的多

比如說\
我們想要仿造 Youtube 的開啟小鈴鐺的功能，使用者可以自由切換要不要開啟通知\
因為我們已經有使用者正在使用我們的服務了\
所以針對 **舊有的使用者**，我們必須讓它也可以使用這個功能\
所以我們需要針對這些舊有用戶，幫他們新增預設的通知設定

> 新的使用者，因為初始化的時候已經做了，所以不需要包含在這次的搬遷內容裡面

# Preparation
既然你已經知道你要針對哪一個部份做資料搬遷了\
你需要做哪一些準備工作呢？

## Backup
因為這種商業邏輯的資料搬遷往往伴隨著一定程度的危險\
所以做好備份的工作是必要的

最壞的狀況就是，當資料搬遷出了大問題\
你已經沒辦法挽回的時候，至少還有一個拯救的辦法

不過要注意的是，當系統升級完成但搬遷卻失敗\
使用 backup 復原並不是一個好的辦法\
因為你需要考慮到回復會不會造成系統相容性的問題等等的\
有沒有 **向後相容**？ 它會不會造成現有服務運作異常\
這個問題值得思考

## Verify Business Requirement
除了技術方面，你還得要確認商業邏輯的部份\
他是不是符合公司的要求

如果條件允許，也必須提及此次系統更新可能的影響\
包含它是否商業上可行？ 會不會與未來的規劃有衝突等等的

# How to do Data Migration?
仔細想想其實也就兩種

1. 手動升級
2. 自動化升級

其中手動升級是較為不推薦的作法\
如果沒有適當的文件，它可能會難以維護\
甚至你可能會忘記為什麼這個欄位會是這個數值

自動化升級至少你還有 code 可以查看\
而自動化的部份，你可以單純寫 SQL 或者是使用類似 [Prisma](https://prisma.io) 這種工具幫你解決\
如果遇到複雜的商業邏輯的部份，則可能要寫個小程式執行

## Reversibility 
在資料搬遷的過程中，你必須要考慮到它是否可以被還原\
也就是說，如果搬遷失敗，你必須要能夠將資料還原到搬遷前的狀態

比如說，你新增了一個欄位(新增一個文章分類的欄位)，你也應該要考慮到他是否能夠在刪除的情況下正常運作\
所以理論上你需要有兩個 script 來處理這件事情

+ `up` script
    + 新增一個欄位以及必要的舊資料升級
+ `down` script
    + 刪除新增的欄位

你可能會好奇為什麼要有 down script\
萬一需要 rollback，整個 database 的狀態理應是 **乾淨的**\
以這個例子來說，新增的欄位必須要被剔除

像是 [alembic](https://alembic.sqlalchemy.org/en/latest/) 裡面 migration 的實作\
你可以看到說也是有兩個 script 來處理這件事情

```python
def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # ### end Alembic commands ###

def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # ### end Alembic commands ###
```

# Possible Issues
## Backward Compatibility
有的時候資料升級，你會遇到無法向後相容的部分\
也就是說新的資料格式沒辦法正確的套用到舊有的資料上\
倒也不是你資料錯誤導致，而是 **資料缺失** 造成的

導致說更新完的資料會沒辦法與新版的系統正確的匹配運作\
舉例來說，我目前碰到的狀況是我想要 "發文分類" 這個功能\
但是早期建立的文章並沒有任何欄位可以區分(比方說 `個人空間` 還是 `公開空間`)\
這樣的狀況你無從知道這些資料是屬於哪一個分類

無可避免的，這種時候各種做法都會有它的缺點
+ 全部搬遷到 個人空間/公開空間
+ 保留 NULL 值，更改處理資料邏輯

當然我們能做的，就是盡量將損失降到最低

## Data Loss
執行資料搬遷，我們絕對不希望它更改到其他不相干的部份\
但它仍然是可能會發生的，所以測試是必要的

針對你搬遷的部份，建立幾筆資料觀察它執行的結果\
在上到 production 之前，可以在 dev 以及 staging 環境測試\
我個人會推薦，在這些之前，也可以在本機進行測試

## Idempotent
最後也是最重要的一點，你的自動化搬遷的執行檔案\
它必須要滿足 `Idempotent` 的條件

何謂 Idempotent？ 就是你不管執行幾次，它得到的結果都要是一致的\
比如說上面我們提到想要實作使用者的通知設定功能\
你絕對不會希望一個使用者有多個相同設定

因此，在設計 migration script 的時候，他要執行的是 `upsert`\
若是寫入的資料不存在，寫入，若存在，則略過或更新部份值\
以 [PostgreSQL](https://www.postgresql.org/) 來說\
你可以使用
```sql
INSERT INTO (xxx) VALUES(yyy) ON CONFLICT(zzz) DO UPDATE SET id = EXCLUDED.id
```
當你寫入的資料，有比對到一模一樣的資料的時候，它就會選擇使用原本的 id\
而這個比對的基礎，是寫在 `ON CONFLICT` 裡面

注意到，一模一樣的資料的定義是，它必須擁有 unique constraint 進行保護\
有時候你要 upsert 的資料根本沒有 unique constraint\
這時候其實你別無選擇，你只能先 query 有沒有該筆資料的存在，然後在寫入\
當然這時候，使用 `transaction` 是相對比較好的選擇

> 有關 transaction 的討論，可以參考 [資料庫 - Transaction 與 Isolation \| Shawn Hsu](../../database/database-transaction)


## Long Migration Time
當搬遷的資料數量過於龐大\
花超過額外預期的時間是有可能會發生的

資料庫系統的更新，因為會佔用一定的連線數量，以及一定的 I/O\
系統的反應速度可能會變慢

### Off-peak Time
你可以選擇在半夜這種不會有太多使用者在線上的時候，執行系統升級

### Migration Checkpoint
或者是 migration 的檔案數量過多，導致執行時間需要拉長\
如果遭遇頻繁的資料庫遷移，這種事情是可能發生的\
一個解決方法是使用 `checkpoint` 的機制\
我們知道，migration 是基於目前 "資料庫的狀態" 往上疊加的\
所以 checkpoint 的概念是，我重設資料庫的狀態，然後以往的 migration 檔案因為狀態改變就不需要執行\
這樣就可以減少 migration 的執行時間

為了系統的可用性，我們通常會希望系統的 down time 越低越好\
盡可能的提高使用者體驗

<!-- ### SQL Statement Optimization -->
<!-- TODO -->

### Change Data Capture(CDC)
除了進一步優化 SQL 的部分，你也可以使用所謂 CDC 的機制\
簡單來說，如果資料過於龐大導致遷移時間過長，系統就沒辦法正確動作\
所以，一個想法是這樣，我假另一台 **額外的資料庫**，他長得跟原本的資料庫一模一樣\
那現在有兩台相同的機器了對吧 那我進行以下操作

+ `A db` 與 `A code` 執行 **舊版** schema 與 code，並且 **對外** 給使用者
+ `B db` 與 `B code` 執行 **新版** schema 與 code，一邊從 `A db` 同步資料(一開始是完整複製 A db)，一邊進行資料搬遷，並且 **不對外**

> 基本上此時此刻只有 A 在服務，B db 執行 migration 而 B code 則在一旁待命

當整個 migration 操作基本上都結束了之後(99% 之類的，對於高流量的系統來說可能無時無刻都有人在使用，所以假定 100% 是不現實的)，我們就可以將服務切換到 `B db` 與 `B code` 上(也就是 **Blue Green Deployment**，可參考 [Kubernetes 從零開始 - 部署策略 101 \| Shawn Hsu](../../kubernetes/kubernetes-scale#blue-green-deployment))\
達成 zero downtime 的資料搬遷

注意到，B 資料庫除了同步新寫入的資料以外，他還要處理原本的資料\
原本的資料好處理，他本來就在線上，但是 "同步新寫入的資料" 這件事情就有趣了\
也就是說你要有能力接收 source 的 `event` 並且將他推播到 target\
這就是 Change Data Capture 的機制

<hr>

在 [資料庫 - 初探分散式資料庫 \| Shawn Hsu](../../database/database-distributed-database) 裡面，我們有提到，分散式資料庫的架構下，資料的同步是相當困難的\
其中你可以使用 [Statement Replication](../../database/database-distributed-database#statement-based) 的機制來達成資料的同步\
但是由於自身的機制，它無法處理 **non deterministic function** 如 `NOW()` 或是 `RAND()` 等等的\
因此比較推薦使用 [Logical Log](../../database/database-distributed-database#logical-log) 的機制來達成資料的同步\
而 Logical Log 本身，就可以視為是 Change Data Capture 的資料來源

那這些 Event 資料屆時可以透過 [Apache Kafka](https://kafka.apache.org/) 以及 [Kafka Connect](https://kafka.apache.org/documentation/streams/developer-guide/connect.html) 來同步資料

> 有關 Kafka 的介紹，可以參考 [資料庫 - 從 Apache Kafka 認識 Message Queue \| Shawn Hsu](../../database/database-message-queue)

# On-premise vs. SAAS Migration
有些產品是落地的，資料並不在我們的控制之下\
在這種情況下，資料升級無疑是相當困難的

SAAS 的產品，我們可以直接存取到資料庫本身\
而我們很清楚服務內存在著什麼樣的資料\
升級失敗復原相對容易且容易掌控\
因為執行資料升級的會是開發服務本身的廠商

到了 On-premise 這裡，事情會完全不一樣\
客戶並不一定擁有足夠的知識能夠處理，甚至可以說是沒有這樣的知識\
支援是相對薄弱的，這時候如果升級失敗將會是一場災難\
若是遇到 [Backward Compatibility](#backward-compatibility) 的問題，無疑是雪上加霜

# References
+ [Hassle-Free Database Migrations with Prisma Migrate](https://www.prisma.io/blog/prisma-migrate-ga-b5eno5g08d0b)
+ [What is data migration?](https://www.ibm.com/topics/data-migration)
+ [Migrations](https://github.com/golang-migrate/migrate/blob/v4.18.3/MIGRATIONS.md)
+ [COSCUP 2025 - Zero‑Downtime Online Schema Migration in PostgreSQL](https://docs.google.com/presentation/d/1VSET3c0F683bgUaTA9UiBigPE5xhSA08ehAwV0Bvuqo/edit?fbclid=IwY2xjawMHvUVleHRuA2FlbQIxMQABHipwC4GYref-40imaC8M3zKYwyi1XBOh08HMitTFKh0cyf_KLybiFinfmM0d_aem_RJQsGFbjWYXTf09Xi9k8ww&slide=id.g287fa921f8d_0_1382#slide=id.g287fa921f8d_0_1382)
+ [[資料工程]獲取資料庫所有異動記錄 — Change Data Capture(1)](https://wuyiru.medium.com/%E8%B3%87%E6%96%99%E5%B7%A5%E7%A8%8B-%E7%8D%B2%E5%8F%96%E8%B3%87%E6%96%99%E5%BA%AB%E6%89%80%E6%9C%89%E7%95%B0%E5%8B%95%E8%A8%98%E9%8C%84-change-data-capture-1-c61ce7ec3d27)
